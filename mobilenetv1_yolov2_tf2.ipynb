{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.获取json_config_path和学习率alpha设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "json_config_path=\".\\configs.json\"\n",
    "alpha=0.75\n",
    "input_shape=(224,224,3)\n",
    "input_size=224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.获取两个需要的数据:         (1)config字典(读取自对应的json文件)        (2)保存Weight file的路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_training(config_file):  #传入:config_file->指定的config路径  传出:config字典(读取自对应的json文件), 保存Weight file的路径\n",
    "    with open(config_file,encoding='utf-8') as config_buffer: #打开config_file路径中的config文件\n",
    "        config = json.loads(config_buffer.read())  #读取文本,返回config字典 json.loads()->用来读取文本\n",
    "    dirname = config['train']['saved_folder'] #dirname获取保存Weight file的文件夹\n",
    "    if os.path.isdir(dirname): #如果路径存在\n",
    "        print(\"{} is already exists. Weight file in directory will be overwritten\".format(dirname))\n",
    "    else:\n",
    "        print(\"{} is created.\".format(dirname, dirname))\n",
    "        os.makedirs(dirname)   #创建文件夹\n",
    "    print(\"Weight file and Config file will be saved in \\\"{}\\\"\".format(dirname))\n",
    "    return config, os.path.join(dirname, \"weights.h5\") #返回config字典(读取自对应的json文件), 保存Weight file的路径\n",
    "\n",
    "config, weight_file = setup_training(json_config_path)  #传入:json_config_path->指定的config路径  传出:config字典(读取自对应的json文件), 保存Weight file的路径"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 3.定义DW卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers,backend,models,utils\n",
    "#初始卷积,正则化,relu6激活函数\n",
    "def _conv_block(inputs, filters, alpha, kernel=(3, 3), strides=(1, 1)):#初始化卷积层,输入img_input=(224x224x3),通道数,mobilenet学习率,步长\n",
    "    filters = int(filters * alpha)#利用alpha减少通道数\n",
    "    x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name='conv1_pad')(inputs)\n",
    "    x = layers.Conv2D(filters, kernel,\n",
    "                      padding='valid',\n",
    "                      use_bias=False,\n",
    "                      strides=strides,\n",
    "                      name='conv1')(x)\n",
    "    x = layers.BatchNormalization(axis=-1, name='conv1_bn')(x)\n",
    "    return layers.ReLU(6., name='conv1_relu')(x)\n",
    "\n",
    "\n",
    "\n",
    "#inputs->输入张量   pointwise_conv_filters->输出通道数  alpha->学习率  depth_multiplier->倍率因子 strides->步长\n",
    "#实际执行的操作时dw卷积->bn->relu6->1x1卷积->bn->relu6  输出通道数为pointwise_conv_filters*alpha\n",
    "def _depthwise_conv_block(inputs, pointwise_conv_filters, alpha,#input->输入张量\n",
    "                          depth_multiplier=1, strides=(1, 1), block_id=1):\n",
    "   \n",
    "    channel_axis = 1 if backend.image_data_format() == 'channels_first' else -1 #channel_axis-> -1 \n",
    "    pointwise_conv_filters = int(pointwise_conv_filters * alpha)\n",
    "\n",
    "    if strides == (1, 1):\n",
    "        x = inputs\n",
    "    else:\n",
    "        x = layers.ZeroPadding2D(((1, 1), (1, 1)),\n",
    "                                 name='conv_pad_%d' % block_id)(inputs)\n",
    "    x = layers.DepthwiseConv2D((3, 3),                                          #做dw卷积,strides=1时不改变维度,strides=2时降采样\n",
    "                               padding='same' if strides == (1, 1) else 'valid',#注意dw卷积不改变图像的通道数\n",
    "                               depth_multiplier=depth_multiplier,\n",
    "                               strides=strides,\n",
    "                               use_bias=False,\n",
    "                               name='conv_dw_%d' % block_id)(x)\n",
    "    x = layers.BatchNormalization(\n",
    "        axis=channel_axis, name='conv_dw_%d_bn' % block_id)(x)\n",
    "    x = layers.ReLU(6., name='conv_dw_%d_relu' % block_id)(x)\n",
    "\n",
    "    x = layers.Conv2D(pointwise_conv_filters, (1, 1),\n",
    "                      padding='same',\n",
    "                      use_bias=False,\n",
    "                      strides=(1, 1),\n",
    "                      name='conv_pw_%d' % block_id)(x)\n",
    "    x = layers.BatchNormalization(axis=channel_axis,\n",
    "                                  name='conv_pw_%d_bn' % block_id)(x)\n",
    "    return layers.ReLU(6., name='conv_pw_%d_relu' % block_id)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.创建mobilenet主干特征提取网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input = layers.Input(shape=input_shape)#定义输入层shape为224x224x3\n",
    "depth_multiplier=1\n",
    "#初始卷积,正则化,relu6激活函数\n",
    "#224x224x3\n",
    "x = _conv_block(img_input, 32, alpha, strides=(2, 2))#初始化卷积层,输入img_input=(224x224x3),通道数,mobilenet学习率,步长\n",
    "#112x112x(32xalpha)\n",
    "#实际执行的操作时dw卷积->bn->relu6->1x1卷积->bn->relu6  输出通道数为pointwise_conv_filters*alpha\n",
    "x = _depthwise_conv_block(x, 64, alpha, depth_multiplier, block_id=1)   #inputs->输入张量   pointwise_conv_filters->输出通道数  \n",
    "                                                                            # alpha->学习率  depth_multiplier->倍率因子 strides->步长\n",
    "#112x112x(64xalpha)  \n",
    "x = _depthwise_conv_block(x, 128, alpha, depth_multiplier,\n",
    "                              strides=(2, 2), block_id=2)\n",
    "#56x56x(128xalpha) \n",
    "x = _depthwise_conv_block(x, 128, alpha, depth_multiplier, block_id=3)\n",
    "    #56x56x(128xalpha) \n",
    "x = _depthwise_conv_block(x, 256, alpha, depth_multiplier,\n",
    "                              strides=(2, 2), block_id=4)\n",
    "    #28x28x(256xalpha) \n",
    "x = _depthwise_conv_block(x, 256, alpha, depth_multiplier, block_id=5)\n",
    "    #28x28x(256xalpha) \n",
    "x = _depthwise_conv_block(x, 512, alpha, depth_multiplier,\n",
    "                              strides=(2, 2), block_id=6)\n",
    "    #14x14x(512xalpha)  5次卷积块运算\n",
    "x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=7)\n",
    "x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=8)\n",
    "x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=9)\n",
    "x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=10)\n",
    "x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=11)\n",
    "    #14x14x(512xalpha)\n",
    "x = _depthwise_conv_block(x, 1024, alpha, depth_multiplier,\n",
    "                              strides=(2, 2), block_id=12)\n",
    "    #7x7x(1024xalpha)\n",
    "x = _depthwise_conv_block(x, 1024, alpha, depth_multiplier, block_id=13)\n",
    "    #7x7x(1024xalpha)\n",
    "\n",
    "inputs = img_input\n",
    "model = models.Model(inputs, x, name='mobilenet_%0.2f'%(alpha))#创建模型\n",
    "#  model->自己创建的模型对象(即为mobilenetv1,不进行pooling和拉直操作)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.定义一个mobilenet主干特征提取网络类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetFeature():\n",
    "    \"\"\"docstring for ClassName\"\"\"\n",
    "    def __init__(self):\n",
    "        self.feature_extractor = model\n",
    "\n",
    "    def normalize(self, image):#定义bn化函数\n",
    "        image = image / 255.\n",
    "        image = image - 0.5\n",
    "        image = image * 2.\n",
    "        return image\t\n",
    "\n",
    "    def get_input_size(self): #获取输入层的size\n",
    "        input_shape = self.feature_extractor.get_input_shape_at(0)\n",
    "        print(\"+++++++++\"+input_shape[1],input_shape[2])\n",
    "        return input_shape[1]\n",
    "\n",
    "    def get_output_size(self):#获取输出层的size\n",
    "        output_shape = self.feature_extractor.layers[-1].output_shape\n",
    "        return output_shape[1]\n",
    "\n",
    "feature_extractor=MobileNetFeature()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.定义一个完整的yolo网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Reshape, Conv2D, Input, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "np.random.seed(111)\n",
    "class YoloNetwork(object):\n",
    "    def __init__(self,\n",
    "                 feature_extractor,             #主干特征提取网络对象\n",
    "                 nb_classes,                    #获取要检测的类别数量\n",
    "                 nb_box):                       #获取先验框的数量\n",
    "        # 1. create full network\n",
    "        grid_size = feature_extractor.get_output_size()#获取到输出的栅格大小为7\n",
    "\n",
    "        # make the object detection layer\n",
    "        output_tensor = Conv2D(nb_box * (4 + 1 + nb_classes), (1,1), strides=(1,1),\n",
    "                               padding='same', \n",
    "                               name='detection_layer_{}'.format(nb_box * (4 + 1 + nb_classes)), \n",
    "                               kernel_initializer='lecun_normal')(feature_extractor.feature_extractor.output)   #kernel_initializer->卷积内核的初始化程序->LeCun正态分布\n",
    "        #再次经过一层卷积 7x7x(1024xalpha)->7x7*[nb_box*(4+1+nb_classes)]\n",
    "        output_tensor = Reshape((grid_size, grid_size, nb_box, 4 + 1 + nb_classes))(output_tensor)\n",
    "        #经过一次reshape操作    7x7*nb_box*(4+1+nb_classes)->7*7*nb_box*(4+1+nb_classes)\n",
    "        model = Model(feature_extractor.feature_extractor.input, output_tensor)    #定义一个模型,此为完整的yolov2网络\n",
    "\n",
    "        self._norm = feature_extractor.normalize#定义bn化函数\n",
    "        self._model = model\n",
    "        self._model.summary()\n",
    "        self._init_layer()#初始化权重设置\n",
    "\n",
    "    def _init_layer(self):\n",
    "        layer = self._model.layers[-2]#layer->获取最后的卷积层\n",
    "        weights = layer.get_weights() #以含有Numpy矩阵的列表形式返回层的权重\n",
    "        input_depth = weights[0].shape[-2] #获取mobilenet输出的通道数,为1024xalphaa\n",
    "        new_kernel = np.random.normal(size=weights[0].shape)/ input_depth#重新生成卷积核的权重\n",
    "        new_bias   = np.zeros_like(weights[1])#将conv层的bais置为0\n",
    "        layer.set_weights([new_kernel, new_bias])#设置权重\n",
    "\n",
    "    def load_weights(self, weight_path, by_name):#这个函数调用tf内置的load_weights函数加载权重\n",
    "        self._model.load_weights(weight_path, by_name=by_name)\n",
    "        \n",
    "    def get_grid_size(self):#获取栅格的大小\n",
    "        _, h, w, _, _ = self._model.layers[-1].output_shape\n",
    "        return h\n",
    "    def get_normalize_func(self):\n",
    "        return self._norm\n",
    "    def get_model(self, first_trainable_layer=None):\n",
    "        layer_names = [layer.name for layer in self._model.layers]\n",
    "        fixed_layers = []\n",
    "        if first_trainable_layer in layer_names:\n",
    "            for layer in self._model.layers:\n",
    "                if layer.name == first_trainable_layer:\n",
    "                    break\n",
    "                layer.trainable = False\n",
    "                fixed_layers.append(layer.name)\n",
    "\n",
    "        if fixed_layers != []:\n",
    "            print(\"The following layers do not update weights!!!\")\n",
    "            print(\"    \", fixed_layers)\n",
    "        return self._model        \n",
    "\n",
    "\n",
    "labels = config['model']['labels'] #获取config.json文件中的labels列表\n",
    "print(labels)\n",
    "anchors=config['model']['anchors'] #获取先验锚框列表\n",
    "n_classes = len(labels)  #n_classes->获取要检测的类别数量\n",
    "n_boxes = int(len(anchors)/2) #n_boxes->获取先验框的数量\n",
    "yolo_net = YoloNetwork(feature_extractor,   #主干特征提取网络对象\n",
    "                     n_classes,          #获取要检测的类别数量\n",
    "                     n_boxes)              #获取先验框的数量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自此,我们完成了整个YOLOv2网络的构建,并且得到了一个YoloNetwork对象yolo_net!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cell_grid(grid_size, batch_size):\n",
    "    x_pos = tf.cast(tf.range(grid_size), tf.float32)\n",
    "    y_pos = tf.cast(tf.range(grid_size), tf.float32)\n",
    "    xx, yy = tf.meshgrid(x_pos, y_pos)\n",
    "    xx = tf.expand_dims(xx, -1)\n",
    "    yy = tf.expand_dims(yy, -1)\n",
    "    \n",
    "    grid = tf.concat([xx, yy], axis=-1)         # (7, 7, 2)\n",
    "    grid = tf.expand_dims(grid, -2)             # (7, 7, 1, 2)\n",
    "    grid = tf.tile(grid, (1,1,5,1))             # (7, 7, 5, 2)\n",
    "    grid = tf.expand_dims(grid, 0)              # (1, 7, 7, 1, 2)\n",
    "    grid = tf.tile(grid, (batch_size,1,1,1,1))  # (N, 7, 7, 1, 2)\n",
    "    return grid\n",
    "\n",
    "\n",
    "def get_loss(coord_mask, conf_mask, class_mask, pred_tensor, true_box_xy, true_box_wh, true_box_conf, true_box_class):\n",
    "    nb_coord_box = tf.reduce_sum(tf.cast(coord_mask > 0.0, tf.float32))\n",
    "    nb_conf_box  = tf.reduce_sum(tf.cast(conf_mask  > 0.0, tf.float32))\n",
    "    nb_class_box = tf.reduce_sum(tf.cast(class_mask > 0.0, tf.float32))\n",
    "\n",
    "    pred_box_xy, pred_box_wh, pred_box_conf, pred_box_class = pred_tensor[..., :2], pred_tensor[..., 2:4], pred_tensor[..., 4], pred_tensor[..., 5:]\n",
    "    # true_box_xy, true_box_wh, true_box_conf, true_box_class = true_tensor[..., :2], true_tensor[..., 2:4], true_tensor[..., 4], true_tensor[..., 5]\n",
    "    true_box_class = tf.cast(true_box_class, tf.int64)\n",
    "    \n",
    "    loss_xy    = tf.reduce_sum(tf.square(true_box_xy-pred_box_xy)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
    "    loss_wh    = tf.reduce_sum(tf.square(true_box_wh-pred_box_wh)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
    "    loss_conf  = tf.reduce_sum(tf.square(true_box_conf-pred_box_conf) * conf_mask)  / (nb_conf_box  + 1e-6) / 2.\n",
    "    loss_class = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=true_box_class, logits=pred_box_class)\n",
    "    loss_class = tf.reduce_sum(loss_class * class_mask) / (nb_class_box + 1e-6)\n",
    "    loss = loss_xy + loss_wh + loss_conf + loss_class\n",
    "    return loss\n",
    "\n",
    "class _Activator(object):\n",
    "    \n",
    "    def __init__(self, anchors=[0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828]):\n",
    "        self._anchor_boxes = np.reshape(anchors, [1,1,1,-1,2])#利用anchors列表创建对象 5个锚框reshape->[1,1,1,5,2]\n",
    "        \n",
    "    def run(self, y_true, y_pred):\n",
    "        pred_box_xy, pred_box_wh, pred_box_conf, pred_box_class = self._activate_pred_tensor(y_pred)\n",
    "        true_box_xy, true_box_wh, true_box_conf, true_box_class = self._activate_true_tensor(y_true, pred_box_xy, pred_box_wh)\n",
    "\n",
    "        # concatenate pred tensor\n",
    "        pred_box_conf = tf.expand_dims(pred_box_conf, -1)\n",
    "        y_pred_activated = tf.concat([pred_box_xy, pred_box_wh, pred_box_conf, pred_box_class], axis=-1)\n",
    "\n",
    "        # concatenate true tensor\n",
    "        true_box_conf = tf.expand_dims(true_box_conf, -1)\n",
    "        true_box_class = tf.expand_dims(true_box_class, -1)\n",
    "        true_box_class = tf.cast(true_box_class, true_box_xy.dtype)\n",
    "        y_true_activated = tf.concat([true_box_xy, true_box_wh, true_box_conf, true_box_class], axis=-1)\n",
    "        return y_true_activated, y_pred_activated\n",
    "    \n",
    "    def _activate_pred_tensor(self, y_pred):\n",
    "        \"\"\"\n",
    "        # Args\n",
    "            y_pred : (N, 13, 13, 5, 6)\n",
    "            cell_grid : (N, 13, 13, 5, 2)\n",
    "        \n",
    "        # Returns\n",
    "            box_xy : (N, 13, 13, 5, 2)\n",
    "                1) sigmoid activation\n",
    "                2) grid offset added\n",
    "            box_wh : (N, 13, 13, 5, 2)\n",
    "                1) exponential activation\n",
    "                2) anchor box multiplied\n",
    "            box_conf : (N, 13, 13, 5, 1)\n",
    "                1) sigmoid activation\n",
    "            box_classes : (N, 13, 13, 5, nb_class)\n",
    "        \"\"\"\n",
    "        # bx = sigmoid(tx) + cx, by = sigmoid(ty) + cy\n",
    "        batch_size = tf.shape(y_pred)[0]\n",
    "        grid_size = tf.shape(y_pred)[1]\n",
    "        cell_grid = create_cell_grid(grid_size, batch_size)\n",
    "        \n",
    "        pred_box_xy = tf.sigmoid(y_pred[..., :2]) + cell_grid\n",
    "        pred_box_wh = tf.exp(y_pred[..., 2:4]) * self._anchor_boxes\n",
    "        pred_box_conf = tf.sigmoid(y_pred[..., 4])\n",
    "        pred_box_class = y_pred[..., 5:]\n",
    "        return pred_box_xy, pred_box_wh, pred_box_conf, pred_box_class\n",
    "    def _activate_true_tensor(self, y_true, pred_box_xy, pred_box_wh):\n",
    "        ### adjust x and y\n",
    "        true_box_xy = y_true[..., 0:2] # relative position to the containing cell\n",
    "        \n",
    "        ### adjust w and h\n",
    "        true_box_wh = y_true[..., 2:4] # number of cells accross, horizontally and vertically\n",
    "        \n",
    "        ### adjust confidence\n",
    "        true_wh_half = true_box_wh / 2.\n",
    "        true_mins    = true_box_xy - true_wh_half\n",
    "        true_maxes   = true_box_xy + true_wh_half\n",
    "        \n",
    "        pred_wh_half = pred_box_wh / 2.\n",
    "        pred_mins    = pred_box_xy - pred_wh_half\n",
    "        pred_maxes   = pred_box_xy + pred_wh_half       \n",
    "        \n",
    "        intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "        intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "        intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "        intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "        \n",
    "        true_areas = true_box_wh[..., 0] * true_box_wh[..., 1]\n",
    "        pred_areas = pred_box_wh[..., 0] * pred_box_wh[..., 1]\n",
    "    \n",
    "        union_areas = pred_areas + true_areas - intersect_areas\n",
    "        iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
    "        \n",
    "        true_box_conf = iou_scores * y_true[..., 4]\n",
    "        \n",
    "        ### adjust class probabilities\n",
    "        true_box_class = tf.argmax(y_true[..., 5:], -1)\n",
    "        \n",
    "        return true_box_xy, true_box_wh, true_box_conf, true_box_class\n",
    "\n",
    "class _Mask(object):\n",
    "    #n_classes->获取要检测的类别数量   #坐标损失的系数=1  #分类损失系数=1   #有对象时的置信度损失=5  #无对象的损失系数=1\n",
    "    def __init__(self, nb_class=1, coord_scale=1.0, class_scale=1.0, object_scale=5.0, no_object_scale=1.0):\n",
    "        self._nb_class = nb_class\n",
    "        self._coord_scale = coord_scale\n",
    "        self._class_scale = class_scale\n",
    "        self._object_scale = object_scale\n",
    "        self._no_object_scale = no_object_scale\n",
    "        \n",
    "    def create_coord_mask(self, y_true):\n",
    "        \"\"\" Simply the position of the ground truth boxes (the predictors)\n",
    "\n",
    "        # Args\n",
    "            y_true : Tensor, shape of (None, grid, grid, nb_box, 4+1+n_classes)\n",
    "        \n",
    "        # Returns\n",
    "            mask : Tensor, shape of (None, grid, grid, nb_box, 1)\n",
    "        \"\"\"\n",
    "        #     BOX 별 confidence value 를 mask value 로 사용\n",
    "        # [1 13 13 5 1]\n",
    "        BOX_IDX_CONFIDENCE=4\n",
    "        mask = tf.expand_dims(y_true[..., BOX_IDX_CONFIDENCE], axis=-1) * self._coord_scale\n",
    "        return mask\n",
    "    \n",
    "    def create_class_mask(self, y_true, true_box_class):\n",
    "        \"\"\" Simply the position of the ground truth boxes (the predictors)\n",
    "\n",
    "        # Args\n",
    "            y_true : Tensor, shape of (None, grid, grid, nb_box, 4+1+n_classes)\n",
    "            true_box_class : Tensor, shape of (None, grid, grid, nb_box)\n",
    "                indicate class index per boxes\n",
    "        \n",
    "        # Returns\n",
    "            mask : Tensor, shape of (None, grid, grid, nb_box)\n",
    "        \"\"\"\n",
    "        class_wt = np.ones(self._nb_class, dtype='float32')\n",
    "        mask = y_true[..., 4] * tf.gather(class_wt, true_box_class) * self._class_scale\n",
    "        return mask\n",
    "    \n",
    "    def create_conf_mask(self, y_true, pred_tensor, batch_size):\n",
    "        ### confidence mask: penelize predictors + penalize boxes with low IOU\n",
    "        # penalize the confidence of the boxes, which have IOU with some ground truth box < 0.6\n",
    "        pred_box_xy, pred_box_wh = pred_tensor[..., :2], pred_tensor[..., 2:4]\n",
    "        \n",
    "        true_boxes = y_true[..., :4]\n",
    "        true_boxes = tf.reshape(true_boxes, [batch_size, -1, 4])\n",
    "        true_boxes = tf.expand_dims(true_boxes, 1)\n",
    "        true_boxes = tf.expand_dims(true_boxes, 1)\n",
    "        true_boxes = tf.expand_dims(true_boxes, 1)\n",
    "        \n",
    "        true_xy = true_boxes[..., 0:2]\n",
    "        true_wh = true_boxes[..., 2:4]\n",
    "        \n",
    "        true_wh_half = true_wh / 2.\n",
    "        true_mins    = true_xy - true_wh_half\n",
    "        true_maxes   = true_xy + true_wh_half\n",
    "        \n",
    "        pred_xy = tf.expand_dims(pred_box_xy, 4)\n",
    "        pred_wh = tf.expand_dims(pred_box_wh, 4)\n",
    "        \n",
    "        pred_wh_half = pred_wh / 2.\n",
    "        pred_mins    = pred_xy - pred_wh_half\n",
    "        pred_maxes   = pred_xy + pred_wh_half    \n",
    "        \n",
    "        intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "        intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "        intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "        intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "        \n",
    "        true_areas = true_wh[..., 0] * true_wh[..., 1]\n",
    "        pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n",
    "\n",
    "        union_areas = pred_areas + true_areas - intersect_areas\n",
    "        iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
    "\n",
    "        best_ious = tf.reduce_max(iou_scores, axis=4)\n",
    "        # 1) confidence mask (N, 13, 13, 5)\n",
    "        conf_mask  = tf.zeros(tf.shape(y_true)[:4])\n",
    "        conf_mask = conf_mask + tf.cast(best_ious < 0.6, tf.float32) * (1 - y_true[..., 4]) * self._no_object_scale\n",
    "        \n",
    "        # penalize the confidence of the boxes, which are reponsible for corresponding ground truth box\n",
    "        conf_mask = conf_mask + y_true[..., 4] * self._object_scale\n",
    "        return conf_mask\n",
    "\n",
    "\n",
    "class YoloLoss(object):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 grid_size=13,  #获取栅格的大小->7\n",
    "                 nb_class=1,    #n_classes->获取要检测的类别数量\n",
    "                 anchors=[0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828],#获取先验框\n",
    "                 coord_scale=1.0,#坐标损失的系数=1\n",
    "                 class_scale=1.0,#分类损失系数=1  \n",
    "                 object_scale=5.0, #有对象时的置信度损失=5\n",
    "                 no_object_scale=1.0):#无对象的损失系数=1\n",
    "        \"\"\"\n",
    "        # Args\n",
    "            grid_size : int\n",
    "            batch_size : int\n",
    "            anchors : list of floats\n",
    "            nb_box : int\n",
    "            nb_class : int\n",
    "            true_boxes : Tensor instance\n",
    "        \"\"\"\n",
    "        self.grid_size = grid_size #获取栅格大小\n",
    "        self.anchors = anchors     #获取anchors列表\n",
    "        self.nb_box = int(len(anchors)/2)#获取锚框的数量\n",
    "        self.nb_class = nb_class       #获取要检测的类别数量\n",
    "\n",
    "        self.coord_scale = coord_scale#坐标损失的系数=1\n",
    "\n",
    "        # Todo : create method를 따로 만들어서 주입받자.\n",
    "        self._activator = _Activator(self.anchors)#5个锚框reshape->[1,1,1,5,2]\n",
    "        self._mask = _Mask(nb_class, coord_scale, class_scale, object_scale, no_object_scale)\n",
    "        #n_classes->获取要检测的类别数量   #坐标损失的系数=1  #分类损失系数=1   #有对象时的置信度损失=5  #无对象的损失系数=1\n",
    "\n",
    "    def custom_loss(self, batch_size):\n",
    "        \"\"\"\n",
    "        # Args\n",
    "            y_true : (N, 13, 13, 5, 6)\n",
    "            y_pred : (N, 13, 13, 5, 6)\n",
    "        \n",
    "        \"\"\"\n",
    "        def loss_func(y_true, y_pred):\n",
    "            # 1. activate prediction & truth tensor\n",
    "            true_tensor, pred_tensor = self._activator.run(y_true, y_pred)\n",
    "            true_box_xy, true_box_wh, true_box_conf, true_box_class = true_tensor[..., :2], true_tensor[..., 2:4], true_tensor[..., 4], true_tensor[..., 5]\n",
    "            true_box_class = tf.cast(true_box_class, tf.int64)\n",
    "\n",
    "            # 2. mask\n",
    "            coord_mask = self._mask.create_coord_mask(y_true)\n",
    "            class_mask = self._mask.create_class_mask(y_true, true_box_class)\n",
    "            conf_mask = self._mask.create_conf_mask(y_true, pred_tensor, batch_size)\n",
    "            \n",
    "            \"\"\"\n",
    "            Finalize the loss\n",
    "            \"\"\"\n",
    "            loss = get_loss(coord_mask, conf_mask, class_mask, pred_tensor, true_box_xy, true_box_wh, true_box_conf, true_box_class)\n",
    "            return loss\n",
    "        return loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#返回一个设置好权重,完整的mobilenetv1-yolo网络\n",
    "yolo_loss = YoloLoss(yolo_net.get_grid_size(),  #获取栅格的大小->7\n",
    "                    n_classes,                     #n_classes->获取要检测的类别数量\n",
    "                    anchors,                       #获取先验框\n",
    "                    config['model']['coord_scale'],     #坐标损失的系数=1\n",
    "                    config['model']['class_scale'],     #分类损失系数=1\n",
    "                    config['model']['object_scale'],    #有对象时的置信度损失=5\n",
    "                    config['model']['no_object_scale']) #无对象的损失系数=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_minmax(centroid_boxes):\n",
    "    centroid_boxes = centroid_boxes.astype(np.float)\n",
    "    minmax_boxes = np.zeros_like(centroid_boxes)\n",
    "    \n",
    "    cx = centroid_boxes[:,0]\n",
    "    cy = centroid_boxes[:,1]\n",
    "    w = centroid_boxes[:,2]\n",
    "    h = centroid_boxes[:,3]\n",
    "    \n",
    "    minmax_boxes[:,0] = cx - w/2\n",
    "    minmax_boxes[:,1] = cy - h/2\n",
    "    minmax_boxes[:,2] = cx + w/2\n",
    "    minmax_boxes[:,3] = cy + h/2\n",
    "    return minmax_boxes\n",
    "\n",
    "\n",
    "def centroid_box_iou(box1, box2):\n",
    "    def _interval_overlap(interval_a, interval_b):\n",
    "        x1, x2 = interval_a\n",
    "        x3, x4 = interval_b\n",
    "    \n",
    "        if x3 < x1:\n",
    "            if x4 < x1:\n",
    "                return 0\n",
    "            else:\n",
    "                return min(x2,x4) - x1\n",
    "        else:\n",
    "            if x2 < x3:\n",
    "                return 0\n",
    "            else:\n",
    "                return min(x2,x4) - x3\n",
    "    \n",
    "    _, _, w1, h1 = box1.reshape(-1,)\n",
    "    _, _, w2, h2 = box2.reshape(-1,)\n",
    "    x1_min, y1_min, x1_max, y1_max = to_minmax(box1.reshape(-1,4)).reshape(-1,)\n",
    "    x2_min, y2_min, x2_max, y2_max = to_minmax(box2.reshape(-1,4)).reshape(-1,)\n",
    "            \n",
    "    intersect_w = _interval_overlap([x1_min, x1_max], [x2_min, x2_max])\n",
    "    intersect_h = _interval_overlap([y1_min, y1_max], [y2_min, y2_max])\n",
    "    intersect = intersect_w * intersect_h\n",
    "    union = w1 * h1 + w2 * h2 - intersect\n",
    "    \n",
    "    return float(intersect) / union\n",
    "\n",
    "\n",
    "class BoundBox:\n",
    "    def __init__(self, x, y, w, h, c = None, classes = None):\n",
    "        self.x     = x\n",
    "        self.y     = y\n",
    "        self.w     = w\n",
    "        self.h     = h\n",
    "        \n",
    "        self.c     = c\n",
    "        self.classes = classes\n",
    "\n",
    "    def get_label(self):\n",
    "        return np.argmax(self.classes)\n",
    "    \n",
    "    def get_score(self):\n",
    "        return self.classes[self.get_label()]\n",
    "    \n",
    "    def iou(self, bound_box):\n",
    "        b1 = self.as_centroid()\n",
    "        b2 = bound_box.as_centroid()\n",
    "        return centroid_box_iou(b1, b2)\n",
    "\n",
    "    def as_centroid(self):\n",
    "        return np.array([self.x, self.y, self.w, self.h])\n",
    "\n",
    "def nms_boxes(boxes, n_classes, nms_threshold=0.3, obj_threshold=0.3):\n",
    "    \"\"\"\n",
    "    # Args\n",
    "        boxes : list of BoundBox\n",
    "    \n",
    "    # Returns\n",
    "        boxes : list of BoundBox\n",
    "            non maximum supressed BoundBox instances\n",
    "    \"\"\"\n",
    "    # suppress non-maximal boxes\n",
    "    for c in range(n_classes):\n",
    "        sorted_indices = list(reversed(np.argsort([box.classes[c] for box in boxes])))\n",
    "\n",
    "        for i in range(len(sorted_indices)):\n",
    "            index_i = sorted_indices[i]\n",
    "            \n",
    "            if boxes[index_i].classes[c] == 0: \n",
    "                continue\n",
    "            else:\n",
    "                for j in range(i+1, len(sorted_indices)):\n",
    "                    index_j = sorted_indices[j]\n",
    "\n",
    "                    if boxes[index_i].iou(boxes[index_j]) >= nms_threshold:\n",
    "                        boxes[index_j].classes[c] = 0\n",
    "    # remove the boxes which are less likely than a obj_threshold\n",
    "    boxes = [box for box in boxes if box.get_score() > obj_threshold]\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def boxes_to_array(bound_boxes):\n",
    "    \"\"\"\n",
    "    # Args\n",
    "        boxes : list of BoundBox instances\n",
    "    \n",
    "    # Returns\n",
    "        centroid_boxes : (N, 4)\n",
    "        probs : (N, nb_classes)\n",
    "    \"\"\"\n",
    "    centroid_boxes = []\n",
    "    probs = []\n",
    "    for box in bound_boxes:\n",
    "        centroid_boxes.append([box.x, box.y, box.w, box.h])\n",
    "        probs.append(box.classes)\n",
    "    return np.array(centroid_boxes), np.array(probs)\n",
    "\n",
    "class YoloDecoder(object):\n",
    "\n",
    "    #传入先验框\n",
    "    def __init__(self,\n",
    "                 anchors = [0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828],\n",
    "                 nms_threshold=0.2):\n",
    "        self._anchors = anchors\n",
    "        self._nms_threshold = nms_threshold#nms抑制的阈值\n",
    "\n",
    "    def run(self, netout, obj_threshold=0.3):\n",
    "        \"\"\"Convert Yolo network output to bounding box\n",
    "        \n",
    "        # Args\n",
    "            netout : 4d-array, shape of (grid_h, grid_w, num of boxes per grid, 5 + n_classes)\n",
    "                YOLO neural network output array\n",
    "        \n",
    "        # Returns\n",
    "            boxes : array, shape of (N, 4)\n",
    "                coordinate scale is normalized [0, 1]\n",
    "            probs : array, shape of (N, nb_classes)\n",
    "        \"\"\"\n",
    "        grid_h, grid_w, nb_box = netout.shape[:3]\n",
    "\n",
    "        boxes = []\n",
    "        \n",
    "        # decode the output by the network\n",
    "        netout[..., 4]  = _sigmoid(netout[..., 4])\n",
    "        netout[..., 5:] = netout[..., 4][..., np.newaxis] * _softmax(netout[..., 5:])\n",
    "        netout[..., 5:] *= netout[..., 5:] > obj_threshold\n",
    "        \n",
    "        for row in range(grid_h):\n",
    "            for col in range(grid_w):\n",
    "                for b in range(nb_box):\n",
    "                    # from 4th element onwards are confidence and class classes\n",
    "                    classes = netout[row,col,b,5:]\n",
    "                    \n",
    "                    if np.sum(classes) > 0:\n",
    "                        # first 4 elements are x, y, w, and h\n",
    "                        x, y, w, h = netout[row,col,b,:4]\n",
    "\n",
    "                        x = (col + _sigmoid(x)) / grid_w # center position, unit: image width\n",
    "                        y = (row + _sigmoid(y)) / grid_h # center position, unit: image height\n",
    "                        w = self._anchors[2 * b + 0] * np.exp(w) / grid_w # unit: image width\n",
    "                        h = self._anchors[2 * b + 1] * np.exp(h) / grid_h # unit: image height\n",
    "                        confidence = netout[row,col,b,4]\n",
    "                        box = BoundBox(x, y, w, h, confidence, classes)\n",
    "                        boxes.append(box)\n",
    "        \n",
    "        boxes = nms_boxes(boxes, len(classes), self._nms_threshold, obj_threshold)\n",
    "        boxes, probs = boxes_to_array(boxes)\n",
    "        return boxes, probs\n",
    "\n",
    "def _sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "def _softmax(x, axis=-1, t=-100.):\n",
    "    x = x - np.max(x)\n",
    "    if np.min(x) < t:\n",
    "        x = x/np.min(x)*t\n",
    "    e_x = np.exp(x)\n",
    "    return e_x / e_x.sum(axis, keepdims=True)\n",
    "\n",
    "\n",
    "yolo_decoder = YoloDecoder(anchors) #传入先验框"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Annotation(object):\n",
    "    \"\"\"\n",
    "    # Attributes\n",
    "        fname : image file path\n",
    "        labels : list of strings\n",
    "        boxes : Boxes instance\n",
    "    \"\"\"\n",
    "    def __init__(self, filename):#传入xml对应的img路径,获得一个annotation类\n",
    "        self.fname = filename\n",
    "        self.labels = []\n",
    "        self.boxes = None\n",
    "\n",
    "    def add_object(self, x1, y1, x2, y2, name):#传入锚框的4个点和标签,添加Annotation类的labels成员和boxes成员,labels为列表,boxes的维度是[n,4]\n",
    "        self.labels.append(name)\n",
    "        if self.boxes is None:\n",
    "            self.boxes = np.array([x1, y1, x2, y2]).reshape(-1,4)\n",
    "        else:\n",
    "            box = np.array([x1, y1, x2, y2]).reshape(-1,4)\n",
    "            self.boxes = np.concatenate([self.boxes, box])#横向拼接\n",
    "\n",
    "class Annotations(object):\n",
    "    def __init__(self, label_namings):#送入  labels_naming\n",
    "        self._components = []\n",
    "        self._label_namings = label_namings\n",
    "\n",
    "    def n_classes(self):\n",
    "        return len(self._label_namings)\n",
    "\n",
    "    def add(self, annotation):#传入annotation成员,将annotation成员添加至_components成员的列表中\n",
    "        self._components.append(annotation)\n",
    "\n",
    "    def shuffle(self):\n",
    "        np.random.shuffle(self._components)\n",
    "    \n",
    "    def fname(self, i):\n",
    "        index = self._valid_index(i)\n",
    "        return self._components[index].fname\n",
    "    \n",
    "    def boxes(self, i):\n",
    "        index = self._valid_index(i)\n",
    "        return self._components[index].boxes\n",
    "\n",
    "    def labels(self, i):\n",
    "        \"\"\"\n",
    "        # Returns\n",
    "            labels : list of strings\n",
    "        \"\"\"\n",
    "        index = self._valid_index(i)\n",
    "        return self._components[index].labels\n",
    "\n",
    "    def code_labels(self, i):\n",
    "        \"\"\"\n",
    "        # Returns\n",
    "            code_labels : list of int\n",
    "        \"\"\"\n",
    "        str_labels = self.labels(i)\n",
    "        labels = []\n",
    "        for label in str_labels:\n",
    "            labels.append(self._label_namings.index(label))\n",
    "        return labels\n",
    "\n",
    "    def _valid_index(self, i):\n",
    "        valid_index = i % len(self._components)\n",
    "        return valid_index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._components)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self._components[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree.ElementTree import parse\n",
    "class PascalVocXmlParser(object):\n",
    "    \"\"\"Parse annotation for 1-annotation file \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get_fname(self, annotation_file):#传入xml标签对应的文件路径,返回最后的文件名.jpg\n",
    "        \"\"\"\n",
    "        # Args\n",
    "            annotation_file : str\n",
    "                annotation file including directory path\n",
    "        \n",
    "        # Returns\n",
    "            filename : str\n",
    "        \"\"\"\n",
    "\n",
    "        root = self._root_tag(annotation_file)#传入xml标签对应的文件路径,返回xml文件解析后的根节点\n",
    "        #print(os.path.splitext(os.path.basename(annotation_file))[0]+os.path.splitext(root.find(\"filename\").text)[1])\n",
    "\n",
    "        return os.path.splitext(os.path.basename(annotation_file))[0]+os.path.splitext(root.find(\"filename\").text)[1]\n",
    "        # root.find(\"filename\").text->在目录中查找filename文件 .text获取内容   os.path.splitext(path)->将对应路径的文件名和后缀名分割\n",
    "        #os.path.basename(annotation_file)->返回path最后的文件名\n",
    "    def _root_tag(self, fname):#传入xml标签对应的文件路径\n",
    "        tree = parse(fname)  #ET.parse('country_data.xml')  ->解析xml文件\n",
    "        root = tree.getroot()#获取根节点\n",
    "        return root\n",
    "\n",
    "    def _tree(self, fname):\n",
    "        tree = parse(fname)\n",
    "        return tree\n",
    "    def get_width(self, annotation_file):\n",
    "        \"\"\"\n",
    "        # Args\n",
    "            annotation_file : str\n",
    "                annotation file including directory path\n",
    "        \n",
    "        # Returns\n",
    "            width : int\n",
    "        \"\"\"\n",
    "        tree = self._tree(annotation_file)\n",
    "        for elem in tree.iter():\n",
    "            if 'width' in elem.tag:\n",
    "                return int(elem.text)\n",
    "\n",
    "    def get_height(self, annotation_file):\n",
    "        \"\"\"\n",
    "        # Args\n",
    "            annotation_file : str\n",
    "                annotation file including directory path\n",
    "        \n",
    "        # Returns\n",
    "            height : int\n",
    "        \"\"\"\n",
    "        tree = self._tree(annotation_file)\n",
    "        for elem in tree.iter():\n",
    "            if 'height' in elem.tag:\n",
    "                return int(elem.text)\n",
    "\n",
    "    def get_labels(self, annotation_file):#传入xml标签对应的文件路径，返回xml里包含的labels标签列表\n",
    "        \"\"\"\n",
    "        # Args\n",
    "            annotation_file : str\n",
    "                annotation file including directory path\n",
    "        \n",
    "        # Returns\n",
    "            labels : list of strs\n",
    "        \"\"\"\n",
    "\n",
    "        root = self._root_tag(annotation_file)#传入xml标签对应的文件路径,返回根节点\n",
    "        labels = []\n",
    "        obj_tags = root.findall(\"object\")#寻找所有object对象\n",
    "        for t in obj_tags:\n",
    "            labels.append(t.find(\"name\").text)\n",
    "        return labels\n",
    "    \n",
    "    def get_boxes(self, annotation_file):#传入xml标签对应的文件路径，以[[xmin,ymin,xmax,ymax],[xmin,ymin,xmax,ymax]...]的格式返回找到的锚框坐标\n",
    "        \"\"\"\n",
    "        # Args\n",
    "            annotation_file : str\n",
    "                annotation file including directory path\n",
    "        \n",
    "        # Returns\n",
    "            bbs : 2d-array, shape of (N, 4)\n",
    "                (x1, y1, x2, y2)-ordered\n",
    "        \"\"\"\n",
    "        root = self._root_tag(annotation_file)#获取根节点\n",
    "        bbs = []\n",
    "        obj_tags = root.findall(\"object\")#寻找所有对象\n",
    "        for t in obj_tags:\n",
    "            box_tag = t.find(\"bndbox\")#寻找所有锚框类\n",
    "            x1 = box_tag.find(\"xmin\").text\n",
    "            y1 = box_tag.find(\"ymin\").text\n",
    "            x2 = box_tag.find(\"xmax\").text\n",
    "            y2 = box_tag.find(\"ymax\").text\n",
    "            box = np.array([int(float(x1)), int(float(y1)), int(float(x2)), int(float(y2))])\n",
    "            bbs.append(box)\n",
    "        bbs = np.array(bbs)#以[[xmin,ymin,xmax,ymax],[xmin,ymin,xmax,ymax]...]的格式返回找到的锚框坐标\n",
    "        print(bbs)\n",
    "        return bbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_annotation(ann_dir, img_dir, labels_naming=[], is_only_detect=False):\n",
    "    #ann_dir->xml标签对应的文件夹  img_dir->图片对应的文件夹  labels_naming  is_only_detect->0,不仅仅为了检测\n",
    "    #返回一个Annotations对象,将annotation成员添加至_components成员的列表中\n",
    "    #Annotation类的labels成员和boxes成员,labels为一个xml文件中每一个锚框对应得label,boxes的维度是[n,4]\n",
    "    \"\"\"\n",
    "    # Args\n",
    "        ann_dir : str\n",
    "        img_dir : str\n",
    "        labels_naming : list of strings\n",
    "    \n",
    "    # Returns\n",
    "        all_imgs : list of dict\n",
    "    \"\"\"\n",
    "    parser = PascalVocXmlParser()#定义一个解析xml类\n",
    "    \n",
    "    if is_only_detect:\n",
    "        annotations = Annotations([\"object\"])\n",
    "    else:\n",
    "        annotations = Annotations(labels_naming)#送入  labels_naming,返回一个Annotations类\n",
    "    for ann in sorted(os.listdir(ann_dir)):#返回xml标签对应的文件夹包含的 文件名字列表  sorted()->对list进行排序\n",
    "        annotation_file = os.path.join(ann_dir, ann)#获得xml标签对应的文件路径\n",
    "        fname = parser.get_fname(annotation_file)#传入xml标签对应的文件路径,返回最后的文件名.jpg\n",
    "\n",
    "        annotation = Annotation(os.path.join(img_dir, fname))#传入xml对应的img路径,获得一个annotation类\n",
    "\n",
    "        labels = parser.get_labels(annotation_file)#传入xml标签对应的文件路径,返回xml里包含的labels标签列表\n",
    "        boxes = parser.get_boxes(annotation_file)#传入xml标签对应的文件路径，以[[xmin,ymin,xmax,ymax],[xmin,ymin,xmax,ymax]...]的格式返回找到的锚框坐标\n",
    "        \n",
    "        for label, box in zip(labels, boxes):\n",
    "            x1, y1, x2, y2 = box\n",
    "            if is_only_detect:\n",
    "                annotation.add_object(x1, y1, x2, y2, name=\"object\")\n",
    "            else:\n",
    "                if label in labels_naming:\n",
    "                    annotation.add_object(x1, y1, x2, y2, name=label)#传入锚框的4个点和标签,添加Annotation类的labels成员和boxes成员,labels为列表,boxes的维度是[n,4]\n",
    "                    \n",
    "        if annotation.boxes is not None:\n",
    "            annotations.add(annotation)#传入annotation成员,将annotation成员添加至_components成员的列表中\n",
    "                        \n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_annotations(labels,#标签列表\n",
    "                          img_folder,#图片对应的文件夹\n",
    "                          ann_folder,#xml标签对应的文件夹\n",
    "                          valid_img_folder = \"\",#图片对应的文件夹\n",
    "                          valid_ann_folder = \"\",#xml标签对应的文件夹\n",
    "                          is_only_detect=False):#不仅仅是为了检测\n",
    "#返回两个Annotations对象,将annotation成员添加至_components成员的列表中,_label_namings成员记录标签列表\n",
    "#Annotation类的labels成员和boxes成员,labels为列表,boxes的维度是[n,4],filename成员保存的是xml对应的img路径\n",
    "#两个Annotations对象对应的分别是train_anns,train_anns\n",
    "    \"\"\"\n",
    "    # Args\n",
    "        labels : list of strings\n",
    "            [\"raccoon\", \"human\", ...]\n",
    "        img_folder : str\n",
    "        ann_folder : str\n",
    "        valid_img_folder : str\n",
    "        valid_ann_folder : str\n",
    "\n",
    "    # Returns\n",
    "        train_anns : Annotations instance\n",
    "        valid_anns : Annotations instance\n",
    "    \"\"\"\n",
    "    # parse annotations of the training set\n",
    "    train_anns = parse_annotation(ann_folder,#xml标签对应的文件夹\n",
    "                                     img_folder,#图片对应的文件夹\n",
    "                                     labels,#标签列表\n",
    "                                     is_only_detect)#不仅仅是为了检测\n",
    "    #返回一个Annotations对象,将annotation成员添加至_components成员的列表中,_label_namings[]成员存放的是标签列表\n",
    "    #Annotation类的labels成员和boxes成员,labels为一个xml文件中每一个锚框对应得label,boxes的维度是[n,4]\n",
    "\n",
    "\n",
    "    if os.path.exists(valid_ann_folder):#如果valid_ann_folder存在的话,就同样获得Annotations对象\n",
    "        valid_anns = parse_annotation(valid_ann_folder,\n",
    "                                         valid_img_folder,\n",
    "                                         labels,\n",
    "                                         is_only_detect)\n",
    "    else:#否则将训练集2,8分\n",
    "        train_valid_split = int(0.8*len(train_anns))\n",
    "        train_anns.shuffle()\n",
    "        \n",
    "        # Todo : Hard coding\n",
    "        valid_anns = Annotations(train_anns._label_namings)\n",
    "        valid_anns._components = train_anns._components[train_valid_split:]\n",
    "        train_anns._components = train_anns._components[:train_valid_split]\n",
    "    \n",
    "    return train_anns, valid_anns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pyecharts.options as opts\n",
    "import warnings\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from pyecharts.charts import Line\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "def save_tflite(model,num,w_name,alpha,anchors,label,i):\n",
    "\n",
    "    output_layer=\"detection_layer_\"+str(num)+\"/BiasAdd\"\n",
    "    model.save(i+\"/yolov2.h5\", include_optimizer=False)\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    converter = tf.compat.v1.lite.TFLiteConverter.from_keras_model_file(i+\"/yolov2.h5\",\n",
    "                                        output_arrays=[output_layer])\n",
    "    \n",
    "    tfmodel = converter.convert()\n",
    "    file = open (i+\"/yolov2.tflite\" , \"wb\")\n",
    "    file.write(tfmodel)\n",
    "    anchorstxt=open(i+\"/anchors.txt\",\"w\")\n",
    "    anchorstxt.write(str(anchors).replace(\"[\",\"\").replace(\"]\",\"\"))\n",
    "    anchorstxt.close()\n",
    "    lable=open(i+\"/lable.txt\",\"w\")\n",
    "    lable.write(str(label).replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\"))\n",
    "    lable.close()\n",
    "    os.startfile(os.getcwd()+\"/\"+i)\n",
    "\n",
    "def time_():\n",
    "    now_time=time.strftime('%m-%d-%H-%M-%S',time.localtime(time.time()))\n",
    "    return now_time\n",
    "\n",
    "def _print_time(process_time):\n",
    "    if process_time < 60:\n",
    "        print(\"{:d}-seconds to train\".format(int(process_time)))\n",
    "    else:\n",
    "        print(\"{:d}-mins to train\".format(int(process_time/60)))\n",
    "\n",
    "class CheckpointPB(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, filepath, monitor='val_loss', verbose=0,\n",
    "                 save_best_only=False, save_weights_only=False,\n",
    "                 mode='auto', period=1):\n",
    "        super(CheckpointPB, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.verbose = verbose\n",
    "        self.filepath = filepath\n",
    "        self.save_best_only = save_best_only\n",
    "        self.save_weights_only = save_weights_only\n",
    "        self.period = period\n",
    "        self.epochs_since_last_save = 0\n",
    "\n",
    "        if mode not in ['auto', 'min', 'max']:\n",
    "            warnings.warn('ModelCheckpoint mode %s is unknown, '\n",
    "                          'fallback to auto mode.' % (mode),\n",
    "                          RuntimeWarning)\n",
    "            mode = 'auto'\n",
    "\n",
    "        if mode == 'min':\n",
    "            self.monitor_op = np.less\n",
    "            self.best = np.Inf\n",
    "        elif mode == 'max':\n",
    "            self.monitor_op = np.greater\n",
    "            self.best = -np.Inf\n",
    "        else:\n",
    "            if 'acc' in self.monitor or self.monitor.startswith('fmeasure'):\n",
    "                self.monitor_op = np.greater\n",
    "                self.best = -np.Inf\n",
    "            else:\n",
    "                self.monitor_op = np.less\n",
    "                self.best = np.Inf\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        self.epochs_since_last_save += 1\n",
    "        if self.epochs_since_last_save >= self.period:\n",
    "            self.epochs_since_last_save = 0\n",
    "            filepath = self.filepath.format(epoch=epoch + 1, **logs)\n",
    "            if self.save_best_only:\n",
    "                current = logs.get(self.monitor)\n",
    "                if current is None:\n",
    "                    warnings.warn('Can save best model only with %s available, '\n",
    "                                  'skipping.' % (self.monitor), RuntimeWarning)\n",
    "                else:\n",
    "                    if self.monitor_op(current, self.best):\n",
    "                        if self.verbose > 0:\n",
    "                            print('\\nEpoch %05d: %s improved from %0.5f to %0.5f,'\n",
    "                                  ' saving model to %s'\n",
    "                                  % (epoch + 1, self.monitor, self.best,\n",
    "                                     current, filepath))\n",
    "                        self.best = current\n",
    "                        if self.save_weights_only:\n",
    "                            self.model.save_weights(filepath, overwrite=True)\n",
    "                        else:\n",
    "                            self.model.save(filepath, overwrite=True)\n",
    "                            save_tflite(self.model)\n",
    "                    else:\n",
    "                        if self.verbose > 0:\n",
    "                            print('\\nEpoch %05d: %s did not improve from %0.5f' %\n",
    "                                  (epoch + 1, self.monitor, self.best))\n",
    "            else:\n",
    "                if self.verbose > 0:\n",
    "                    print('\\nEpoch %05d: saving model to %s' % (epoch + 1, filepath))\n",
    "                if self.save_weights_only:\n",
    "                    self.model.save_weights(filepath, overwrite=True)\n",
    "                else:\n",
    "                    self.model.save(filepath, overwrite=True)\n",
    "\n",
    "def _create_callbacks(saved_weights_name):\n",
    "    # Make a few callbacks\n",
    "    early_stop = EarlyStopping(monitor='val_loss', \n",
    "                       min_delta=0.001, \n",
    "                       patience=20, \n",
    "                       mode='min', \n",
    "                       verbose=1,\n",
    "                       restore_best_weights=True)\n",
    "    checkpoint = CheckpointPB(saved_weights_name, \n",
    "                                 monitor='val_loss', \n",
    "                                 verbose=1, \n",
    "                                 save_best_only=True, \n",
    "                                 mode='min', \n",
    "                                 period=1)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.00001, verbose=1)\n",
    "    callbacks = [early_stop,reduce_lr]\n",
    "    return callbacks\n",
    "\n",
    "\n",
    "def train(model,\n",
    "         loss_func,\n",
    "         train_batch_gen,\n",
    "         valid_batch_gen,\n",
    "         learning_rate = 1e-4,\n",
    "         nb_epoch = 300,\n",
    "         saved_weights_name = 'best_weights.h5',\n",
    "         class_num=1,\n",
    "         anchors=[0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828],\n",
    "         w_name=\"\",\n",
    "         alpha=0.75,\n",
    "         lable=\"\"\n",
    "         ):\n",
    "    \"\"\"A function that performs training on a general keras model.\n",
    "\n",
    "    # Args\n",
    "        model : tensorflow.keras.models.Model instance\n",
    "        loss_func : function\n",
    "            refer to https://keras.io/losses/\n",
    "\n",
    "        train_batch_gen : tensorflow.keras.utils.Sequence instance\n",
    "        valid_batch_gen : tensorflow.keras.utils.Sequence instance\n",
    "        learning_rate : float\n",
    "        saved_weights_name : str\n",
    "    \"\"\"\n",
    "    # 1. create optimizer\n",
    "    optimizer = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    \n",
    "    # 2. create loss function\n",
    "    model.compile(loss=loss_func,\n",
    "                  optimizer=optimizer)\n",
    "    \n",
    "    # 4. training\n",
    "    train_start = time.time()\n",
    "    try:\n",
    "        history=model.fit_generator(generator = train_batch_gen,\n",
    "                        steps_per_epoch  = len(train_batch_gen), \n",
    "                        epochs           = nb_epoch,\n",
    "                        validation_data  = valid_batch_gen,\n",
    "                        validation_steps = len(valid_batch_gen),\n",
    "                        callbacks        = _create_callbacks(saved_weights_name),                        \n",
    "                        verbose          = 1,\n",
    "                        workers          = 3,\n",
    "                        max_queue_size   = 8)\n",
    "\n",
    "        # history=model.fit(x_train)\n",
    "        print(history.history)\n",
    "        \n",
    "        plt.figure(\"loss\")\n",
    "        plt.grid()\n",
    "        num1=1\n",
    "        num2=0\n",
    "        num3=3\n",
    "        num4=4\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('loss')\n",
    "        plt.legend(['train', 'test'], loc='upper right')\n",
    "        i=\"./Model_file\"+\"/yolov2物体识别_\"+w_name+\"_\"+str(alpha)+\"-\"+time_()\n",
    "        os.mkdir(i)\n",
    "\n",
    "        plt.savefig(i+'/Loss.jpg')\n",
    "        plt.show()\n",
    "        loss_=[]\n",
    "        loss_val=[]\n",
    "        for o in history.history['loss']:\n",
    "            loss_.append(round(o,4))\n",
    "        for o in history.history['val_loss']:\n",
    "            loss_val.append(round(o,4))\n",
    "        c = (\n",
    "            Line()\n",
    "            .add_xaxis(range(1,len(loss_)+1))\n",
    "            .add_yaxis(\"Train\",loss_, is_smooth=True,linestyle_opts=opts.LineStyleOpts(width=3),is_symbol_show=False,color=\"#2196F3\")\n",
    "            .add_yaxis(\"Test\", loss_val, is_smooth=True,linestyle_opts=opts.LineStyleOpts(width=3),is_symbol_show=False,color=\"#F9A825\")\n",
    "            .set_global_opts(title_opts=opts.TitleOpts(title=\"Loss损失率\"),\n",
    "                            toolbox_opts=opts.ToolboxOpts(is_show=True,orient=\"vertical\",pos_left=\"right\",feature=opts.ToolBoxFeatureOpts(save_as_image=opts.ToolBoxFeatureSaveAsImageOpts(background_color=\"#fff\"),\n",
    "                                                                                                                                            magic_type=opts.ToolBoxFeatureMagicTypeOpts(is_show=False),\n",
    "                                                                                                                                            data_zoom=opts.ToolBoxFeatureDataZoomOpts(is_show=False),\n",
    "                                                                                                                                            data_view=opts.ToolBoxFeatureSaveAsImageOpts(is_show=False),\n",
    "                                                                                                                                            brush=opts.ToolBoxFeatureBrushOpts(type_='rect')),\n",
    "                                                                                                                                            ),\n",
    "                            datazoom_opts=opts.DataZoomOpts(is_show=True,range_end=100,range_start=0,filter_mode=\"none\"),\n",
    "                            tooltip_opts=opts.TooltipOpts(is_show=True),\n",
    "                            legend_opts=opts.LegendOpts(legend_icon=\"circle\"),\n",
    "                            axispointer_opts=opts.AxisPointerOpts(is_show=True))\n",
    "            .set_series_opts(splitline_opts=opts.SplitLineOpts(is_show=True))\n",
    "            .render(i+\"/Loss.html\")\n",
    "        )\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        save_tflite(model,class_num,w_name,alpha,anchors,lable,i)\n",
    "        raise\n",
    "\n",
    "    _print_time(time.time() - train_start)\n",
    "    save_tflite(model,class_num,w_name,alpha,anchors,lable,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from imgaug import augmenters as iaa\n",
    "def _create_augment_pipeline():\n",
    "    \n",
    "    ### augmentors by https://github.com/aleju/imgaug\n",
    "    sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "\n",
    "    # Define our sequence of augmentation steps that will be applied to every image\n",
    "    # All augmenters with per_channel=0.5 will sample one value _per image_\n",
    "    # in 50% of all cases. In all other cases they will sample new values\n",
    "    # _per channel_.\n",
    "    aug_pipe = iaa.Sequential(\n",
    "        [\n",
    "            # apply the following augmenters to most images\n",
    "            #iaa.Fliplr(0.5), # horizontally flip 50% of all images\n",
    "            #iaa.Flipud(0.2), # vertically flip 20% of all images\n",
    "            #sometimes(iaa.Crop(percent=(0, 0.1))), # crop images by 0-10% of their height/width\n",
    "            #sometimes(iaa.Affine(\n",
    "                #scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)}, # scale images to 80-120% of their size, individually per axis\n",
    "                #translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)}, # translate by -20 to +20 percent (per axis)\n",
    "                #rotate=(-5, 5), # rotate by -45 to +45 degrees\n",
    "                #shear=(-5, 5), # shear by -16 to +16 degrees\n",
    "                #order=[0, 1], # use nearest neighbour or bilinear interpolation (fast)\n",
    "                #cval=(0, 255), # if mode is constant, use a cval between 0 and 255\n",
    "                #mode=ia.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
    "            #)),\n",
    "            # execute 0 to 5 of the following (less important) augmenters per image\n",
    "            # don't execute all of them, as that would often be way too strong\n",
    "            iaa.SomeOf((0, 5),\n",
    "                [\n",
    "                    #sometimes(iaa.Superpixels(p_replace=(0, 1.0), n_segments=(20, 200))), # convert images into their superpixel representation\n",
    "                    iaa.OneOf([\n",
    "                        iaa.GaussianBlur((0, 3.0)), # blur images with a sigma between 0 and 3.0\n",
    "                        iaa.AverageBlur(k=(2, 7)), # blur image using local means with kernel sizes between 2 and 7\n",
    "                        iaa.MedianBlur(k=(3, 11)), # blur image using local medians with kernel sizes between 2 and 7\n",
    "                    ]),\n",
    "                    iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5)), # sharpen images\n",
    "                    #iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)), # emboss images\n",
    "                    # search either for all edges or for directed edges\n",
    "                    #sometimes(iaa.OneOf([\n",
    "                    #    iaa.EdgeDetect(alpha=(0, 0.7)),\n",
    "                    #    iaa.DirectedEdgeDetect(alpha=(0, 0.7), direction=(0.0, 1.0)),\n",
    "                    #])),\n",
    "                    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5), # add gaussian noise to images\n",
    "                    iaa.OneOf([\n",
    "                        iaa.Dropout((0.01, 0.1), per_channel=0.5), # randomly remove up to 10% of the pixels\n",
    "                        #iaa.CoarseDropout((0.03, 0.15), size_percent=(0.02, 0.05), per_channel=0.2),\n",
    "                    ]),\n",
    "                    #iaa.Invert(0.05, per_channel=True), # invert color channels\n",
    "                    iaa.Add((-10, 10), per_channel=0.5), # change brightness of images (by -10 to 10 of original value)\n",
    "                    iaa.Multiply((0.5, 1.5), per_channel=0.5), # change brightness of images (50-150% of original value)\n",
    "                    iaa.ContrastNormalization((0.5, 2.0), per_channel=0.5), # improve or worsen the contrast\n",
    "                    #iaa.Grayscale(alpha=(0.0, 1.0)),\n",
    "                    #sometimes(iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)), # move pixels locally around (with random strengths)\n",
    "                    #sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05))) # sometimes move parts of the image around\n",
    "                ],\n",
    "                random_order=True\n",
    "            )\n",
    "        ],\n",
    "        random_order=True\n",
    "    )\n",
    "    return aug_pipe\n",
    "\n",
    "\n",
    "def make_jitter_on_image(image, boxes):\n",
    "    h, w, _ = image.shape\n",
    "\n",
    "    ### scale the image\n",
    "    scale = np.random.uniform() / 10. + 1.\n",
    "    image = cv2.resize(image, (0,0), fx = scale, fy = scale)\n",
    "\n",
    "    ### translate the image\n",
    "    max_offx = (scale-1.) * w\n",
    "    max_offy = (scale-1.) * h\n",
    "    offx = int(np.random.uniform() * max_offx)\n",
    "    offy = int(np.random.uniform() * max_offy)\n",
    "    \n",
    "    image = image[offy : (offy + h), offx : (offx + w)]\n",
    "\n",
    "    ### flip the image\n",
    "    #flip = np.random.binomial(1, .5)\n",
    "    #if flip > 0.5:\n",
    "    #    image = cv2.flip(image, 1)\n",
    "    #    is_flip = True\n",
    "    #else:\n",
    "    #    is_flip = False\n",
    "\n",
    "    aug_pipe = _create_augment_pipeline()\n",
    "    image = aug_pipe.augment_image(image)\n",
    "    \n",
    "    # fix object's position and size\n",
    "    new_boxes = []\n",
    "    for box in boxes:\n",
    "        x1,y1,x2,y2 = box\n",
    "        x1 = int(x1 * scale - offx)\n",
    "        x2 = int(x2 * scale - offx)\n",
    "        \n",
    "        y1 = int(y1 * scale - offy)\n",
    "        y2 = int(y2 * scale - offy)\n",
    "\n",
    "    #    if is_flip:\n",
    "    #        xmin = x1\n",
    "    #        x1 = w - x2\n",
    "    #        x2 = w - xmin\n",
    "        new_boxes.append([x1,y1,x2,y2])\n",
    "    return image, np.array(new_boxes)\n",
    "\n",
    "\n",
    "def resize_image(image, boxes, desired_w, desired_h):\n",
    "    h, w, _ = image.shape\n",
    "    \n",
    "    # resize the image to standard size\n",
    "    image = cv2.resize(image, (desired_h, desired_w))\n",
    "    image = image[:,:,::-1]\n",
    "\n",
    "    # fix object's position and size\n",
    "    new_boxes = []\n",
    "    for box in boxes:\n",
    "        x1,y1,x2,y2 = box\n",
    "        x1 = int(x1 * float(desired_w) / w)\n",
    "        x1 = max(min(x1, desired_w - 1), 0)\n",
    "        x2 = int(x2 * float(desired_w) / w)\n",
    "        x2 = max(min(x2, desired_w - 1), 0)\n",
    "        \n",
    "        y1 = int(y1 * float(desired_h) / h)\n",
    "        y1 = max(min(y1, desired_h - 1), 0)\n",
    "        y2 = int(y2 * float(desired_h) / h)\n",
    "        y2 = max(min(y2, desired_h - 1), 0)\n",
    "\n",
    "        new_boxes.append([x1,y1,x2,y2])\n",
    "    return image, np.array(new_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgAugment(object):\n",
    "    def __init__(self, w, h, jitter):\n",
    "        \"\"\"\n",
    "        # Args\n",
    "            desired_w : int\n",
    "            desired_h : int\n",
    "            jitter : bool\n",
    "        \"\"\"\n",
    "        self._jitter = jitter\n",
    "        self._w = w\n",
    "        self._h = h\n",
    "        \n",
    "    def imread(self, img_file, boxes):\n",
    "        \"\"\"\n",
    "        # Args\n",
    "            img_file : str\n",
    "            boxes : array, shape of (N, 4)\n",
    "        \n",
    "        # Returns\n",
    "            image : 3d-array, shape of (h, w, 3)\n",
    "            boxes_ : array, same shape of boxes\n",
    "                jittered & resized bounding box\n",
    "        \"\"\"\n",
    "        # 1. read image file\n",
    "        image = cv2.imread(img_file)\n",
    "        if image is None:\n",
    "            print(\"Image Path: \" + img_file)\n",
    "            raise ValueError\n",
    "    \n",
    "        # 2. make jitter on image\n",
    "        boxes_ = np.copy(boxes)\n",
    "        if self._jitter:\n",
    "            image, boxes_ = make_jitter_on_image(image, boxes_)\n",
    "    \n",
    "        # 3. resize image            \n",
    "        image, boxes_ = resize_image(image, boxes_, self._w, self._h)\n",
    "        return image, boxes_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_centroid(minmax_boxes):\n",
    "    \"\"\"\n",
    "    minmax_boxes : (N, 4)\n",
    "    \"\"\"\n",
    "    minmax_boxes = minmax_boxes.astype(np.float)\n",
    "    centroid_boxes = np.zeros_like(minmax_boxes)\n",
    "    \n",
    "    x1 = minmax_boxes[:,0]\n",
    "    y1 = minmax_boxes[:,1]\n",
    "    x2 = minmax_boxes[:,2]\n",
    "    y2 = minmax_boxes[:,3]\n",
    "    \n",
    "    centroid_boxes[:,0] = (x1 + x2) / 2\n",
    "    centroid_boxes[:,1] = (y1 + y2) / 2\n",
    "    centroid_boxes[:,2] = x2 - x1\n",
    "    centroid_boxes[:,3] = y2 - y1\n",
    "    return centroid_boxes\n",
    "\n",
    "def create_anchor_boxes(anchors):\n",
    "    \"\"\"\n",
    "    # Args\n",
    "        anchors : list of floats\n",
    "    # Returns\n",
    "        boxes : array, shape of (len(anchors)/2, 4)\n",
    "            centroid-type\n",
    "    \"\"\"\n",
    "    boxes = []\n",
    "    n_boxes = int(len(anchors)/2)\n",
    "    for i in range(n_boxes):\n",
    "        boxes.append(np.array([0, 0, anchors[2*i], anchors[2*i+1]]))\n",
    "    return np.array(boxes)\n",
    "\n",
    "\n",
    "def find_match_box(centroid_box, centroid_boxes):\n",
    "    \"\"\"Find the index of the boxes with the largest overlap among the N-boxes.\n",
    "\n",
    "    # Args\n",
    "        box : array, shape of (1, 4)\n",
    "        boxes : array, shape of (N, 4)\n",
    "    \n",
    "    # Return\n",
    "        match_index : int\n",
    "    \"\"\"\n",
    "    match_index = -1\n",
    "    max_iou     = -1\n",
    "    \n",
    "    for i, box in enumerate(centroid_boxes):\n",
    "        iou = centroid_box_iou(centroid_box, box)\n",
    "        \n",
    "        if max_iou < iou:\n",
    "            match_index = i\n",
    "            max_iou     = iou\n",
    "    return match_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _YoloBox(object):\n",
    "    \n",
    "    def __init__(self, input_size, grid_size):\n",
    "        self._input_size = input_size\n",
    "        self._grid_size = grid_size\n",
    "\n",
    "    def trans(self, boxes):\n",
    "        \"\"\"\n",
    "        # Args\n",
    "            boxes : array, shape of (N, 4)\n",
    "                (x1, y1, x2, y2)-ordered & input image size scale coordinate\n",
    "        \n",
    "        # Returns\n",
    "            norm_boxes : array, same shape of boxes\n",
    "                (cx, cy, w, h)-ordered & rescaled to grid-size\n",
    "        \"\"\"\n",
    "        # 1. minimax box -> centroid box\n",
    "        centroid_boxes = to_centroid(boxes).astype(np.float32)\n",
    "        # 2. image scale -> grid scale\n",
    "        norm_boxes = centroid_boxes * (self._grid_size / self._input_size)\n",
    "        return norm_boxes\n",
    "\n",
    "\n",
    "class _NetinGen(object):\n",
    "    def __init__(self, input_size, norm):\n",
    "        self._input_size = input_size\n",
    "        self._norm = self._set_norm(norm)\n",
    "    \n",
    "    def run(self, image):\n",
    "        return self._norm(image)\n",
    "    \n",
    "    def _set_norm(self, norm):\n",
    "        if norm is None:\n",
    "            return lambda x: x\n",
    "        else:\n",
    "            return norm\n",
    "\n",
    "\n",
    "class _NetoutGen(object):\n",
    "    def __init__(self,\n",
    "                 grid_size,\n",
    "                 nb_classes,\n",
    "                 anchors=[0.57273, 0.677385,\n",
    "                          1.87446, 2.06253,\n",
    "                          3.33843, 5.47434,\n",
    "                          7.88282, 3.52778,\n",
    "                          9.77052, 9.16828]):\n",
    "        self._anchors = create_anchor_boxes(anchors)\n",
    "        self._tensor_shape = self._set_tensor_shape(grid_size, nb_classes)\n",
    "\n",
    "    def run(self, norm_boxes, labels):\n",
    "        \"\"\"\n",
    "        # Args\n",
    "            norm_boxes : array, shape of (N, 4)\n",
    "                scale normalized boxes\n",
    "            labels : list of integers\n",
    "            y_shape : tuple (grid_size, grid_size, nb_boxes, 4+1+nb_classes)\n",
    "        \"\"\"\n",
    "        y = np.zeros(self._tensor_shape)\n",
    "        \n",
    "        # loop over objects in one image\n",
    "        for norm_box, label in zip(norm_boxes, labels):\n",
    "            best_anchor = self._find_anchor_idx(norm_box)\n",
    "\n",
    "            # assign ground truth x, y, w, h, confidence and class probs to y_batch\n",
    "            y += self._generate_y(best_anchor, label, norm_box)\n",
    "        return y\n",
    "\n",
    "    def _set_tensor_shape(self, grid_size, nb_classes):\n",
    "        nb_boxes = len(self._anchors)\n",
    "        return (grid_size, grid_size, nb_boxes, 4+1+nb_classes)\n",
    "\n",
    "    def _find_anchor_idx(self, norm_box):\n",
    "        _, _, center_w, center_h = norm_box\n",
    "        shifted_box = np.array([0, 0, center_w, center_h])\n",
    "        return find_match_box(shifted_box, self._anchors)\n",
    "    \n",
    "    def _generate_y(self, best_anchor, obj_indx, box):\n",
    "        y = np.zeros(self._tensor_shape)\n",
    "        grid_x, grid_y, _, _ = box.astype(int)\n",
    "        y[grid_y, grid_x, best_anchor, 0:4] = box\n",
    "        y[grid_y, grid_x, best_anchor, 4  ] = 1.\n",
    "        y[grid_y, grid_x, best_anchor, 5+obj_indx] = 1\n",
    "        return y\n",
    "        \n",
    "from tensorflow.keras.utils import Sequence\n",
    "class BatchGenerator(Sequence):\n",
    "    def __init__(self,\n",
    "                 netin_gen,\n",
    "                 netout_gen,\n",
    "                 yolo_box,\n",
    "                 img_aug,\n",
    "                 annotations,\n",
    "                 batch_size,\n",
    "                 repeat_times):\n",
    "        \"\"\"\n",
    "        # Args\n",
    "            annotations : Annotations instance\n",
    "        \n",
    "        \"\"\"\n",
    "        self._netin_gen = netin_gen\n",
    "        self._netout_gen = netout_gen\n",
    "        self._img_aug = img_aug\n",
    "        self._yolo_box = yolo_box\n",
    "\n",
    "        self._batch_size = min(batch_size, len(annotations)*repeat_times)\n",
    "        self._repeat_times = repeat_times\n",
    "        self.annotations = annotations\n",
    "        self.counter = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(len(self.annotations) * self._repeat_times /self._batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        # Args\n",
    "            idx : batch index\n",
    "        \"\"\"\n",
    "        x_batch = []\n",
    "        y_batch= []\n",
    "        for i in range(self._batch_size):\n",
    "            # 1. get input file & its annotation\n",
    "            fname = self.annotations.fname(self._batch_size*idx + i)\n",
    "            boxes = self.annotations.boxes(self._batch_size*idx + i)\n",
    "            labels = self.annotations.code_labels(self._batch_size*idx + i)\n",
    "            \n",
    "            # 2. read image in fixed size\n",
    "            img, boxes = self._img_aug.imread(fname, boxes)\n",
    "\n",
    "            # 3. grid scaling centroid boxes\n",
    "            norm_boxes = self._yolo_box.trans(boxes)\n",
    "            \n",
    "            # 4. generate x_batch\n",
    "            x_batch.append(self._netin_gen.run(img))\n",
    "            y_batch.append(self._netout_gen.run(norm_boxes, labels))\n",
    "\n",
    "        x_batch = np.array(x_batch)\n",
    "        y_batch = np.array(y_batch)\n",
    "        self.counter += 1\n",
    "        return x_batch, y_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.annotations.shuffle()\n",
    "        self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch_generator(annotations, \n",
    "                           input_size=416,\n",
    "                           grid_size=13,\n",
    "                           batch_size=8,\n",
    "                           anchors=[0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828],\n",
    "                           repeat_times=1,\n",
    "                           jitter=True, \n",
    "                           norm=None):\n",
    "    \"\"\"\n",
    "    # Args\n",
    "        annotations : Annotations instance in utils.annotataion module\n",
    "    \n",
    "    # Return \n",
    "        worker : BatchGenerator instance\n",
    "    \"\"\"\n",
    "\n",
    "    img_aug = ImgAugment(input_size, input_size, jitter)\n",
    "    yolo_box = _YoloBox(input_size, grid_size)\n",
    "    netin_gen = _NetinGen(input_size, norm)\n",
    "    netout_gen = _NetoutGen(grid_size, annotations.n_classes(), anchors)\n",
    "    worker = BatchGenerator(netin_gen,\n",
    "                            netout_gen,\n",
    "                            yolo_box,\n",
    "                            img_aug,\n",
    "                            annotations,\n",
    "                            batch_size,\n",
    "                            repeat_times)\n",
    "    return worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO(object): \n",
    "    def __init__(self,\n",
    "                 yolo_network,#yolo_network->一个完整的yolo网络类\n",
    "                 yolo_loss,#yolo_loss->损失函数类\n",
    "                 yolo_decoder,#yolo_decoder->yolo网络解码类\n",
    "                 labels,#labels->标签列表\n",
    "                 input_size = 416#input_size->输入图片size\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        # Args\n",
    "            feature_extractor : BaseFeatureExtractor instance\n",
    "        \"\"\"\n",
    "        self._yolo_network = yolo_network#一个完整的yolo网络类\n",
    "        self._yolo_loss = yolo_loss#损失函数类\n",
    "        self._yolo_decoder = yolo_decoder#yolo网络解码类\n",
    "        \n",
    "        self._labels = labels           #标签列表\n",
    "        # Batch를 생성할 때만 사용한다.\n",
    "        self._input_size = input_size   #输入图片size\n",
    "\n",
    "    def load_weights(self, weight_path, by_name=False):\n",
    "        if os.path.exists(weight_path):\n",
    "            print(\"Loading pre-trained weights in\", weight_path)\n",
    "            self._yolo_network.load_weights(weight_path, by_name=by_name)\n",
    "        else:\n",
    "            print(\"Fail to load pre-trained weights. Make sure weight file path.\")\n",
    "\n",
    "    def predict(self, image, threshold=0.3):\n",
    "        \"\"\"\n",
    "        # Args\n",
    "            image : 3d-array (BGR ordered)\n",
    "        \n",
    "        # Returns\n",
    "            boxes : array, shape of (N, 4)\n",
    "            probs : array, shape of (N, nb_classes)\n",
    "        \"\"\"\n",
    "        def _to_original_scale(boxes):\n",
    "            height, width = image.shape[:2]\n",
    "            minmax_boxes = to_minmax(boxes)\n",
    "            minmax_boxes[:,0] *= width\n",
    "            minmax_boxes[:,2] *= width\n",
    "            minmax_boxes[:,1] *= height\n",
    "            minmax_boxes[:,3] *= height\n",
    "            return minmax_boxes.astype(np.int)\n",
    "\n",
    "        netout = self._yolo_network.forward(image)\n",
    "        boxes, probs = self._yolo_decoder.run(netout, threshold)\n",
    "        \n",
    "        if len(boxes) > 0:\n",
    "            boxes = _to_original_scale(boxes)\n",
    "            return boxes, probs\n",
    "        else:\n",
    "            return [], []\n",
    "\n",
    "    def train(self,\n",
    "              img_folder,#图片对应的文件夹\n",
    "              ann_folder,#xml标签对应的文件夹\n",
    "              nb_epoch,#训练的epoch\n",
    "              saved_weights_name,#保存.h5文件权重的文件夹  config['train']['saved_folder']/weights.h5\n",
    "              batch_size=8,#每次训练喂入网络的batch\n",
    "              jitter=True,#训练的抖动=1？\n",
    "              learning_rate=1e-4, #学习率=0.0005\n",
    "              train_times=1,#训练次数=5？\n",
    "              valid_times=1,#有效次数=5?\n",
    "              valid_img_folder=\"\",#图片对应的文件夹\n",
    "              valid_ann_folder=\"\",#xml标签对应的文件夹\n",
    "              first_trainable_layer=None,#\"\"\n",
    "              is_only_detect=False,#为0,不只只是检测\n",
    "              class_num=1,#5x(4+1+分类数),即yolo网络最后输出的大小\n",
    "              anchors=[0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828],#锚框列表\n",
    "              w_name=\"\",#算法名字=mobilenet\n",
    "              alpha=0.75,#mobilenet的学习率\n",
    "              lable=\"\"#标签列表\n",
    "              ):\n",
    "\n",
    "        # 1. get annotations        \n",
    "        train_annotations, valid_annotations = get_train_annotations(self._labels,#标签列表\n",
    "                                                                     img_folder,#图片对应的文件夹\n",
    "                                                                     ann_folder,#xml标签对应的文件夹\n",
    "                                                                     valid_img_folder,#图片对应的文件夹\n",
    "                                                                     valid_ann_folder,#xml标签对应的文件夹\n",
    "                                                                     is_only_detect)#为0,不只只是检测\n",
    "        #返回两个Annotations对象,将annotation成员添加至_components成员的列表中,_label_namings[]成员存放的是标签列表\n",
    "         #Annotation类的labels成员和boxes成员,labels为一个xml文件中每一个锚框对应得label,boxes的维度是[n,4]\n",
    "        #两个Annotations对象对应的分别是train_anns,train_anns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # 1. get batch generator\n",
    "        train_batch_generator = self._get_batch_generator(train_annotations, batch_size, train_times, jitter=jitter)\n",
    "        #train_annsAnnotations对象,每次训练喂入网络的batch,\n",
    "        valid_batch_generator = self._get_batch_generator(valid_annotations, batch_size, valid_times, jitter=False)\n",
    "        \n",
    "        # 2. To train model get keras model instance & loss function\n",
    "        model = self._yolo_network.get_model(first_trainable_layer)\n",
    "        loss = self._get_loss_func(batch_size)\n",
    "        \n",
    "        # 3. Run training loop\n",
    "        train(model,\n",
    "                loss,\n",
    "                train_batch_generator,\n",
    "                valid_batch_generator,\n",
    "                learning_rate      = learning_rate, \n",
    "                nb_epoch           = nb_epoch,\n",
    "                saved_weights_name = saved_weights_name,\n",
    "                class_num=class_num,\n",
    "                anchors=anchors,\n",
    "                w_name=w_name,\n",
    "                alpha=alpha,\n",
    "                lable=lable\n",
    "                )\n",
    "\n",
    "    def _get_loss_func(self, batch_size):\n",
    "        return self._yolo_loss.custom_loss(batch_size)\n",
    "\n",
    "    def _get_batch_generator(self, annotations, batch_size, repeat_times=1, jitter=True):\n",
    "        \"\"\"\n",
    "        # Args\n",
    "            annotations : Annotations instance\n",
    "            batch_size : int\n",
    "            jitter : bool\n",
    "        \n",
    "        # Returns\n",
    "            batch_generator : BatchGenerator instance\n",
    "        \"\"\"\n",
    "        batch_generator = create_batch_generator(annotations,\n",
    "                                                 self._input_size,\n",
    "                                                 self._yolo_network.get_grid_size(),\n",
    "                                                 batch_size,\n",
    "                                                 self._yolo_loss.anchors,\n",
    "                                                 repeat_times,\n",
    "                                                 jitter=jitter,\n",
    "                                                 norm=self._yolo_network.get_normalize_func())\n",
    "        return batch_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = YOLO(yolo_net, yolo_loss, yolo_decoder, labels, input_size)#传入yolo_network->一个完整的yolo网络类 yolo_loss->损失函数类 yolo_decoder->yolo网络解码类 labels->标签列表 input_size->输入图片size\n",
    "   # 2. Load the pretrained weights (if any) \n",
    "if alpha==1.0:\n",
    "        weights='mobilenet_1_0_224_tf_no_top.h5'\n",
    "elif alpha==0.75:\n",
    "        weights='mobilenet_7_5_224_tf_no_top.h5'\n",
    "elif alpha==0.5:\n",
    "        weights='mobilenet_5_0_224_tf_no_top.h5'\n",
    "elif alpha==0.25:\n",
    "        weights='mobilenet_2_5_224_tf_no_top.h5'\n",
    "yolo.load_weights(weights, by_name=True)#传入权重文件的路径\n",
    "\n",
    "    #这时候yolo网络已经成功加载预权重\n",
    "\n",
    "with warnings.catch_warnings():#忽略下面部分的waring\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "        # 3. actual training \n",
    "    yolo.train(config['train']['train_image_folder'],#图片对应的文件夹\n",
    "                config['train']['train_annot_folder'],#xml标签对应的文件夹\n",
    "                config['train']['actual_epoch'],      #训练的epoch\n",
    "                weight_file,                          #保存.h5文件权重的文件夹  config['train']['saved_folder']/weights.h5\n",
    "                config[\"train\"][\"batch_size\"],        #每次训练喂入网络的batch\n",
    "                config[\"train\"][\"jitter\"],            #训练的抖动=1？\n",
    "                config['train']['learning_rate'],     #学习率=0.0005\n",
    "                config['train']['train_times'],       #训练次数=5？\n",
    "                config['train']['valid_times'],       #有效次数=5?\n",
    "                config['train']['train_image_folder'],#图片对应的文件夹\n",
    "                config['train']['train_annot_folder'],#xml标签对应的文件夹\n",
    "                config['train']['first_trainable_layer'],#\"\"\n",
    "                config['train']['is_only_detect'],      #为0,不只只是检测\n",
    "                (len(config['model'][\"labels\"])+5)*5, #5x(4+1+分类数),即yolo网络最后输出的大小\n",
    "                config['model']['anchors'],             #锚框列表\n",
    "                w_name=config['model']['architecture'], #算法名字=mobilenet\n",
    "                alpha=alpha,                           #mobilenet的学习率\n",
    "                lable=config['model']['labels']         #标签列表\n",
    "                )\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cf69bd2bff1868ea2575ae05d66f26a3bd574af473be1af5287e2ad3e28ce2c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
