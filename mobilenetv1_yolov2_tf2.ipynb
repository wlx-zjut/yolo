{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.获取json_config_path和学习率alpha设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import argparse #argparse是python用于解析命令行参数和选项的标准模块\n",
    "import os\n",
    "import json\n",
    "\n",
    "json_config_path=\".\\configs.json\"\n",
    "alpha=0.75\n",
    "input_shape=(224,224,3)\n",
    "input_size=224\n",
    "\n",
    "if os.path.exists(json_config_path)==False: #如果设置路径中不存在\n",
    "    print(\"没有找到配置文件,请重新选择.\")\n",
    "else:\n",
    "    f = open(json_config_path, \"r\",encoding='utf-8') #打开路径中的config文件\n",
    "    setting = json.load(f) #加载json文件 json.load()->读取文件 返回类似字典"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.获取两个需要的数据:         (1)config字典(读取自对应的json文件)        (2)保存Weight file的路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test is already exists. Weight file in directory will be overwritten\n",
      "Weight file and Config file will be saved in \"test\"\n"
     ]
    }
   ],
   "source": [
    "import shutil   #作为os模块的补充,提供了复制,移动,删除,压缩,解压等操作\n",
    "\n",
    "def setup_training(config_file):  #传入:config_file->指定的config路径  传出:config字典(读取自对应的json文件), 保存Weight file的路径\n",
    "    with open(config_file,encoding='utf-8') as config_buffer: #打开config_file路径中的config文件\n",
    "        config = json.loads(config_buffer.read())  #读取文本,返回config字典 json.loads()->用来读取文本\n",
    "    dirname = config['train']['saved_folder'] #dirname获取保存Weight file的文件夹\n",
    "    if os.path.isdir(dirname): #如果路径存在\n",
    "        print(\"{} is already exists. Weight file in directory will be overwritten\".format(dirname))\n",
    "    else:\n",
    "        print(\"{} is created.\".format(dirname, dirname))\n",
    "        os.makedirs(dirname)   #创建文件夹\n",
    "    print(\"Weight file and Config file will be saved in \\\"{}\\\"\".format(dirname))\n",
    "    # shutil.copyfile(config_file, os.path.join(dirname, \"config.json\")) #复制文件,前->后,将config_file文件复制到  (保存Weight file的文件夹)\\test路径下\n",
    "    return config, os.path.join(dirname, \"weights.h5\") #返回config字典(读取自对应的json文件), 保存Weight file的路径\n",
    "\n",
    "config, weight_file = setup_training(json_config_path)  #传入:json_config_path->指定的config路径  传出:config字典(读取自对应的json文件), 保存Weight file的路径"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 3.定义DW卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers,backend,models,utils\n",
    "#初始卷积,正则化,relu6激活函数\n",
    "def _conv_block(inputs, filters, alpha, kernel=(3, 3), strides=(1, 1)):#初始化卷积层,输入img_input=(224x224x3),通道数,mobilenet学习率,步长\n",
    "    filters = int(filters * alpha)#利用alpha减少通道数\n",
    "    x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name='conv1_pad')(inputs)\n",
    "    x = layers.Conv2D(filters, kernel,\n",
    "                      padding='valid',\n",
    "                      use_bias=False,\n",
    "                      strides=strides,\n",
    "                      name='conv1')(x)\n",
    "    x = layers.BatchNormalization(axis=-1, name='conv1_bn')(x)\n",
    "    return layers.ReLU(6., name='conv1_relu')(x)\n",
    "\n",
    "\n",
    "\n",
    "#inputs->输入张量   pointwise_conv_filters->输出通道数  alpha->学习率  depth_multiplier->倍率因子 strides->步长\n",
    "#实际执行的操作时dw卷积->bn->relu6->1x1卷积->bn->relu6  输出通道数为pointwise_conv_filters*alpha\n",
    "def _depthwise_conv_block(inputs, pointwise_conv_filters, alpha,#input->输入张量\n",
    "                          depth_multiplier=1, strides=(1, 1), block_id=1):\n",
    "   \n",
    "    channel_axis = 1 if backend.image_data_format() == 'channels_first' else -1 #channel_axis-> -1 \n",
    "    pointwise_conv_filters = int(pointwise_conv_filters * alpha)\n",
    "\n",
    "    if strides == (1, 1):\n",
    "        x = inputs\n",
    "    else:\n",
    "        x = layers.ZeroPadding2D(((1, 1), (1, 1)),\n",
    "                                 name='conv_pad_%d' % block_id)(inputs)\n",
    "    x = layers.DepthwiseConv2D((3, 3),                                          #做dw卷积,strides=1时不改变维度,strides=2时降采样\n",
    "                               padding='same' if strides == (1, 1) else 'valid',#注意dw卷积不改变图像的通道数\n",
    "                               depth_multiplier=depth_multiplier,\n",
    "                               strides=strides,\n",
    "                               use_bias=False,\n",
    "                               name='conv_dw_%d' % block_id)(x)\n",
    "    x = layers.BatchNormalization(\n",
    "        axis=channel_axis, name='conv_dw_%d_bn' % block_id)(x)\n",
    "    x = layers.ReLU(6., name='conv_dw_%d_relu' % block_id)(x)\n",
    "\n",
    "    x = layers.Conv2D(pointwise_conv_filters, (1, 1),\n",
    "                      padding='same',\n",
    "                      use_bias=False,\n",
    "                      strides=(1, 1),\n",
    "                      name='conv_pw_%d' % block_id)(x)\n",
    "    x = layers.BatchNormalization(axis=channel_axis,\n",
    "                                  name='conv_pw_%d_bn' % block_id)(x)\n",
    "    return layers.ReLU(6., name='conv_pw_%d_relu' % block_id)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.创建mobilenet主干特征提取网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input = layers.Input(shape=input_shape)#定义输入层shape为224x224x3\n",
    "depth_multiplier=1\n",
    "#初始卷积,正则化,relu6激活函数\n",
    "#224x224x3\n",
    "x = _conv_block(img_input, 32, alpha, strides=(2, 2))#初始化卷积层,输入img_input=(224x224x3),通道数,mobilenet学习率,步长\n",
    "#112x112x(32xalpha)\n",
    "#实际执行的操作时dw卷积->bn->relu6->1x1卷积->bn->relu6  输出通道数为pointwise_conv_filters*alpha\n",
    "x = _depthwise_conv_block(x, 64, alpha, depth_multiplier, block_id=1)   #inputs->输入张量   pointwise_conv_filters->输出通道数  \n",
    "                                                                            # alpha->学习率  depth_multiplier->倍率因子 strides->步长\n",
    "#112x112x(64xalpha)  \n",
    "x = _depthwise_conv_block(x, 128, alpha, depth_multiplier,\n",
    "                              strides=(2, 2), block_id=2)\n",
    "#56x56x(128xalpha) \n",
    "x = _depthwise_conv_block(x, 128, alpha, depth_multiplier, block_id=3)\n",
    "    #56x56x(128xalpha) \n",
    "x = _depthwise_conv_block(x, 256, alpha, depth_multiplier,\n",
    "                              strides=(2, 2), block_id=4)\n",
    "    #28x28x(256xalpha) \n",
    "x = _depthwise_conv_block(x, 256, alpha, depth_multiplier, block_id=5)\n",
    "    #28x28x(256xalpha) \n",
    "x = _depthwise_conv_block(x, 512, alpha, depth_multiplier,\n",
    "                              strides=(2, 2), block_id=6)\n",
    "    #14x14x(512xalpha)  5次卷积块运算\n",
    "x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=7)\n",
    "x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=8)\n",
    "x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=9)\n",
    "x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=10)\n",
    "x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=11)\n",
    "    #14x14x(512xalpha)\n",
    "x = _depthwise_conv_block(x, 1024, alpha, depth_multiplier,\n",
    "                              strides=(2, 2), block_id=12)\n",
    "    #7x7x(1024xalpha)\n",
    "x = _depthwise_conv_block(x, 1024, alpha, depth_multiplier, block_id=13)\n",
    "    #7x7x(1024xalpha)\n",
    "\n",
    "inputs = img_input\n",
    "model = models.Model(inputs, x, name='mobilenet_%0.2f'%(alpha))#创建模型\n",
    "#  model->自己创建的模型对象(即为mobilenetv1,不进行pooling和拉直操作)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.定义一个mobilenet主干特征提取网络类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetFeature():\n",
    "    \"\"\"docstring for ClassName\"\"\"\n",
    "    def __init__(self):\n",
    "        self.feature_extractor = model\n",
    "\n",
    "    def normalize(self, image):#定义bn化函数\n",
    "        image = image / 255.\n",
    "        image = image - 0.5\n",
    "        image = image * 2.\n",
    "        return image\t\n",
    "\n",
    "    def get_input_size(self): #获取输入层的size\n",
    "        input_shape = self.feature_extractor.get_input_shape_at(0)\n",
    "        print(\"+++++++++\"+input_shape[1],input_shape[2])\n",
    "        return input_shape[1]\n",
    "\n",
    "    def get_output_size(self):#获取输出层的size\n",
    "        output_shape = self.feature_extractor.layers[-1].output_shape\n",
    "        return output_shape[1]\n",
    "\n",
    "feature_extractor=MobileNetFeature()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.定义一个完整的yolo网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Un_Masks', 'Masks']\n",
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 226, 226, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 24)      648       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 24)      96        \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 112, 112, 24)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 24)      216       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 24)      96        \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 112, 112, 24)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 48)      1152      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 48)      192       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 112, 112, 48)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 114, 114, 48)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 48)        432       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 48)        192       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 56, 56, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 96)        4608      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 56, 56, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 96)        864       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 56, 56, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 96)        9216      \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 56, 56, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 58, 58, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 96)        864       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 28, 28, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 192)       18432     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 192)       768       \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 28, 28, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 192)       1728      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 192)       768       \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 28, 28, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 192)       36864     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 192)       768       \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 28, 28, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 30, 30, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 192)       1728      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 192)       768       \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 14, 14, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 384)       73728     \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 14, 14, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 384)       3456      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 14, 14, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 384)       147456    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 14, 14, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 384)       3456      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 14, 14, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 384)       147456    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 14, 14, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 384)       3456      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 14, 14, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 384)       147456    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 14, 14, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 384)       3456      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 14, 14, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 384)       147456    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 14, 14, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 384)       3456      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 14, 14, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 384)       147456    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 14, 14, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 16, 16, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 384)         3456      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 384)         1536      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 7, 7, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 768)         294912    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 768)         3072      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 7, 7, 768)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 768)         6912      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 768)         3072      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 7, 7, 768)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 768)         589824    \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 768)         3072      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 7, 7, 768)         0         \n",
      "_________________________________________________________________\n",
      "detection_layer_35 (Conv2D)  (None, 7, 7, 35)          26915     \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 5, 7)        0         \n",
      "=================================================================\n",
      "Total params: 1,859,891\n",
      "Trainable params: 1,843,475\n",
      "Non-trainable params: 16,416\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Reshape, Conv2D, Input, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "np.random.seed(111)\n",
    "class YoloNetwork(object):\n",
    "    def __init__(self,\n",
    "                 feature_extractor,             #主干特征提取网络对象\n",
    "                 nb_classes,                    #获取要检测的类别数量\n",
    "                 nb_box):                       #获取先验框的数量\n",
    "        # 1. create full network\n",
    "        grid_size = feature_extractor.get_output_size()#获取到输出的栅格大小为7\n",
    "\n",
    "        # make the object detection layer\n",
    "        output_tensor = Conv2D(nb_box * (4 + 1 + nb_classes), (1,1), strides=(1,1),\n",
    "                               padding='same', \n",
    "                               name='detection_layer_{}'.format(nb_box * (4 + 1 + nb_classes)), \n",
    "                               kernel_initializer='lecun_normal')(feature_extractor.feature_extractor.output)   #kernel_initializer->卷积内核的初始化程序->LeCun正态分布\n",
    "        #再次经过一层卷积 7x7x(1024xalpha)->7x7*[nb_box*(4+1+nb_classes)]\n",
    "        output_tensor = Reshape((grid_size, grid_size, nb_box, 4 + 1 + nb_classes))(output_tensor)\n",
    "        #经过一次reshape操作    7x7*nb_box*(4+1+nb_classes)->7*7*nb_box*(4+1+nb_classes)\n",
    "        model = Model(feature_extractor.feature_extractor.input, output_tensor)    #定义一个模型,此为完整的yolov2网络\n",
    "\n",
    "        self._norm = feature_extractor.normalize#定义bn化函数\n",
    "        self._model = model\n",
    "        self._model.summary()\n",
    "        self._init_layer()#初始化权重设置\n",
    "\n",
    "    def _init_layer(self):\n",
    "        layer = self._model.layers[-2]#layer->获取最后的卷积层\n",
    "        weights = layer.get_weights() #以含有Numpy矩阵的列表形式返回层的权重\n",
    "        input_depth = weights[0].shape[-2] #获取mobilenet输出的通道数,为1024xalphaa\n",
    "        new_kernel = np.random.normal(size=weights[0].shape)/ input_depth#重新生成卷积核的权重\n",
    "        new_bias   = np.zeros_like(weights[1])#将conv层的bais置为0\n",
    "        layer.set_weights([new_kernel, new_bias])#设置权重\n",
    "\n",
    "    def load_weights(self, weight_path, by_name):#这个函数调用tf内置的load_weights函数加载权重\n",
    "        self._model.load_weights(weight_path, by_name=by_name)\n",
    "        \n",
    "    def get_grid_size(self):#获取栅格的大小\n",
    "        _, h, w, _, _ = self._model.layers[-1].output_shape\n",
    "        return h\n",
    "    def get_normalize_func(self):\n",
    "        return self._norm\n",
    "    def get_model(self, first_trainable_layer=None):\n",
    "        layer_names = [layer.name for layer in self._model.layers]\n",
    "        fixed_layers = []\n",
    "        if first_trainable_layer in layer_names:\n",
    "            for layer in self._model.layers:\n",
    "                if layer.name == first_trainable_layer:\n",
    "                    break\n",
    "                layer.trainable = False\n",
    "                fixed_layers.append(layer.name)\n",
    "\n",
    "        if fixed_layers != []:\n",
    "            print(\"The following layers do not update weights!!!\")\n",
    "            print(\"    \", fixed_layers)\n",
    "        return self._model        \n",
    "\n",
    "\n",
    "labels = config['model']['labels'] #获取config.json文件中的labels列表\n",
    "print(labels)\n",
    "anchors=config['model']['anchors'] #获取先验锚框列表\n",
    "n_classes = len(labels)  #n_classes->获取要检测的类别数量\n",
    "n_boxes = int(len(anchors)/2) #n_boxes->获取先验框的数量\n",
    "yolo_net = YoloNetwork(feature_extractor,   #主干特征提取网络对象\n",
    "                     n_classes,          #获取要检测的类别数量\n",
    "                     n_boxes)              #获取先验框的数量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自此,我们完成了整个YOLOv2网络的构建,并且得到了一个YoloNetwork对象yolo_net!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cell_grid(grid_size, batch_size):\n",
    "    x_pos = tf.cast(tf.range(grid_size), tf.float32)\n",
    "    y_pos = tf.cast(tf.range(grid_size), tf.float32)\n",
    "    xx, yy = tf.meshgrid(x_pos, y_pos)\n",
    "    xx = tf.expand_dims(xx, -1)\n",
    "    yy = tf.expand_dims(yy, -1)\n",
    "    \n",
    "    grid = tf.concat([xx, yy], axis=-1)         # (7, 7, 2)\n",
    "    grid = tf.expand_dims(grid, -2)             # (7, 7, 1, 2)\n",
    "    grid = tf.tile(grid, (1,1,5,1))             # (7, 7, 5, 2)\n",
    "    grid = tf.expand_dims(grid, 0)              # (1, 7, 7, 1, 2)\n",
    "    grid = tf.tile(grid, (batch_size,1,1,1,1))  # (N, 7, 7, 1, 2)\n",
    "    return grid\n",
    "\n",
    "\n",
    "def get_loss(coord_mask, conf_mask, class_mask, pred_tensor, true_box_xy, true_box_wh, true_box_conf, true_box_class):\n",
    "    nb_coord_box = tf.reduce_sum(tf.cast(coord_mask > 0.0, tf.float32))\n",
    "    nb_conf_box  = tf.reduce_sum(tf.cast(conf_mask  > 0.0, tf.float32))\n",
    "    nb_class_box = tf.reduce_sum(tf.cast(class_mask > 0.0, tf.float32))\n",
    "\n",
    "    pred_box_xy, pred_box_wh, pred_box_conf, pred_box_class = pred_tensor[..., :2], pred_tensor[..., 2:4], pred_tensor[..., 4], pred_tensor[..., 5:]\n",
    "    # true_box_xy, true_box_wh, true_box_conf, true_box_class = true_tensor[..., :2], true_tensor[..., 2:4], true_tensor[..., 4], true_tensor[..., 5]\n",
    "    true_box_class = tf.cast(true_box_class, tf.int64)\n",
    "    \n",
    "    loss_xy    = tf.reduce_sum(tf.square(true_box_xy-pred_box_xy)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
    "    loss_wh    = tf.reduce_sum(tf.square(true_box_wh-pred_box_wh)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
    "    loss_conf  = tf.reduce_sum(tf.square(true_box_conf-pred_box_conf) * conf_mask)  / (nb_conf_box  + 1e-6) / 2.\n",
    "    loss_class = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=true_box_class, logits=pred_box_class)\n",
    "    loss_class = tf.reduce_sum(loss_class * class_mask) / (nb_class_box + 1e-6)\n",
    "    loss = loss_xy + loss_wh + loss_conf + loss_class\n",
    "    return loss\n",
    "\n",
    "class _Activator(object):\n",
    "    \n",
    "    def __init__(self, anchors=[0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828]):\n",
    "        self._anchor_boxes = np.reshape(anchors, [1,1,1,-1,2])#利用anchors列表创建对象 5个锚框reshape->[1,1,1,5,2]\n",
    "        \n",
    "    def run(self, y_true, y_pred):\n",
    "        pred_box_xy, pred_box_wh, pred_box_conf, pred_box_class = self._activate_pred_tensor(y_pred)\n",
    "        true_box_xy, true_box_wh, true_box_conf, true_box_class = self._activate_true_tensor(y_true, pred_box_xy, pred_box_wh)\n",
    "\n",
    "        # concatenate pred tensor\n",
    "        pred_box_conf = tf.expand_dims(pred_box_conf, -1)\n",
    "        y_pred_activated = tf.concat([pred_box_xy, pred_box_wh, pred_box_conf, pred_box_class], axis=-1)\n",
    "\n",
    "        # concatenate true tensor\n",
    "        true_box_conf = tf.expand_dims(true_box_conf, -1)\n",
    "        true_box_class = tf.expand_dims(true_box_class, -1)\n",
    "        true_box_class = tf.cast(true_box_class, true_box_xy.dtype)\n",
    "        y_true_activated = tf.concat([true_box_xy, true_box_wh, true_box_conf, true_box_class], axis=-1)\n",
    "        return y_true_activated, y_pred_activated\n",
    "    \n",
    "    def _activate_pred_tensor(self, y_pred):\n",
    "        \"\"\"\n",
    "        # Args\n",
    "            y_pred : (N, 13, 13, 5, 6)\n",
    "            cell_grid : (N, 13, 13, 5, 2)\n",
    "        \n",
    "        # Returns\n",
    "            box_xy : (N, 13, 13, 5, 2)\n",
    "                1) sigmoid activation\n",
    "                2) grid offset added\n",
    "            box_wh : (N, 13, 13, 5, 2)\n",
    "                1) exponential activation\n",
    "                2) anchor box multiplied\n",
    "            box_conf : (N, 13, 13, 5, 1)\n",
    "                1) sigmoid activation\n",
    "            box_classes : (N, 13, 13, 5, nb_class)\n",
    "        \"\"\"\n",
    "        # bx = sigmoid(tx) + cx, by = sigmoid(ty) + cy\n",
    "        batch_size = tf.shape(y_pred)[0]\n",
    "        grid_size = tf.shape(y_pred)[1]\n",
    "        cell_grid = create_cell_grid(grid_size, batch_size)\n",
    "        \n",
    "        pred_box_xy = tf.sigmoid(y_pred[..., :2]) + cell_grid\n",
    "        pred_box_wh = tf.exp(y_pred[..., 2:4]) * self._anchor_boxes\n",
    "        pred_box_conf = tf.sigmoid(y_pred[..., 4])\n",
    "        pred_box_class = y_pred[..., 5:]\n",
    "        return pred_box_xy, pred_box_wh, pred_box_conf, pred_box_class\n",
    "    def _activate_true_tensor(self, y_true, pred_box_xy, pred_box_wh):\n",
    "        ### adjust x and y\n",
    "        true_box_xy = y_true[..., 0:2] # relative position to the containing cell\n",
    "        \n",
    "        ### adjust w and h\n",
    "        true_box_wh = y_true[..., 2:4] # number of cells accross, horizontally and vertically\n",
    "        \n",
    "        ### adjust confidence\n",
    "        true_wh_half = true_box_wh / 2.\n",
    "        true_mins    = true_box_xy - true_wh_half\n",
    "        true_maxes   = true_box_xy + true_wh_half\n",
    "        \n",
    "        pred_wh_half = pred_box_wh / 2.\n",
    "        pred_mins    = pred_box_xy - pred_wh_half\n",
    "        pred_maxes   = pred_box_xy + pred_wh_half       \n",
    "        \n",
    "        intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "        intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "        intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "        intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "        \n",
    "        true_areas = true_box_wh[..., 0] * true_box_wh[..., 1]\n",
    "        pred_areas = pred_box_wh[..., 0] * pred_box_wh[..., 1]\n",
    "    \n",
    "        union_areas = pred_areas + true_areas - intersect_areas\n",
    "        iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
    "        \n",
    "        true_box_conf = iou_scores * y_true[..., 4]\n",
    "        \n",
    "        ### adjust class probabilities\n",
    "        true_box_class = tf.argmax(y_true[..., 5:], -1)\n",
    "        \n",
    "        return true_box_xy, true_box_wh, true_box_conf, true_box_class\n",
    "\n",
    "class _Mask(object):\n",
    "    #n_classes->获取要检测的类别数量   #坐标损失的系数=1  #分类损失系数=1   #有对象时的置信度损失=5  #无对象的损失系数=1\n",
    "    def __init__(self, nb_class=1, coord_scale=1.0, class_scale=1.0, object_scale=5.0, no_object_scale=1.0):\n",
    "        self._nb_class = nb_class\n",
    "        self._coord_scale = coord_scale\n",
    "        self._class_scale = class_scale\n",
    "        self._object_scale = object_scale\n",
    "        self._no_object_scale = no_object_scale\n",
    "        \n",
    "    def create_coord_mask(self, y_true):\n",
    "        \"\"\" Simply the position of the ground truth boxes (the predictors)\n",
    "\n",
    "        # Args\n",
    "            y_true : Tensor, shape of (None, grid, grid, nb_box, 4+1+n_classes)\n",
    "        \n",
    "        # Returns\n",
    "            mask : Tensor, shape of (None, grid, grid, nb_box, 1)\n",
    "        \"\"\"\n",
    "        #     BOX 별 confidence value 를 mask value 로 사용\n",
    "        # [1 13 13 5 1]\n",
    "        BOX_IDX_CONFIDENCE=4\n",
    "        mask = tf.expand_dims(y_true[..., BOX_IDX_CONFIDENCE], axis=-1) * self._coord_scale\n",
    "        return mask\n",
    "    \n",
    "    def create_class_mask(self, y_true, true_box_class):\n",
    "        \"\"\" Simply the position of the ground truth boxes (the predictors)\n",
    "\n",
    "        # Args\n",
    "            y_true : Tensor, shape of (None, grid, grid, nb_box, 4+1+n_classes)\n",
    "            true_box_class : Tensor, shape of (None, grid, grid, nb_box)\n",
    "                indicate class index per boxes\n",
    "        \n",
    "        # Returns\n",
    "            mask : Tensor, shape of (None, grid, grid, nb_box)\n",
    "        \"\"\"\n",
    "        class_wt = np.ones(self._nb_class, dtype='float32')\n",
    "        mask = y_true[..., 4] * tf.gather(class_wt, true_box_class) * self._class_scale\n",
    "        return mask\n",
    "    \n",
    "    def create_conf_mask(self, y_true, pred_tensor, batch_size):\n",
    "        ### confidence mask: penelize predictors + penalize boxes with low IOU\n",
    "        # penalize the confidence of the boxes, which have IOU with some ground truth box < 0.6\n",
    "        pred_box_xy, pred_box_wh = pred_tensor[..., :2], pred_tensor[..., 2:4]\n",
    "        \n",
    "        true_boxes = y_true[..., :4]\n",
    "        true_boxes = tf.reshape(true_boxes, [batch_size, -1, 4])\n",
    "        true_boxes = tf.expand_dims(true_boxes, 1)\n",
    "        true_boxes = tf.expand_dims(true_boxes, 1)\n",
    "        true_boxes = tf.expand_dims(true_boxes, 1)\n",
    "        \n",
    "        true_xy = true_boxes[..., 0:2]\n",
    "        true_wh = true_boxes[..., 2:4]\n",
    "        \n",
    "        true_wh_half = true_wh / 2.\n",
    "        true_mins    = true_xy - true_wh_half\n",
    "        true_maxes   = true_xy + true_wh_half\n",
    "        \n",
    "        pred_xy = tf.expand_dims(pred_box_xy, 4)\n",
    "        pred_wh = tf.expand_dims(pred_box_wh, 4)\n",
    "        \n",
    "        pred_wh_half = pred_wh / 2.\n",
    "        pred_mins    = pred_xy - pred_wh_half\n",
    "        pred_maxes   = pred_xy + pred_wh_half    \n",
    "        \n",
    "        intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "        intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "        intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "        intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "        \n",
    "        true_areas = true_wh[..., 0] * true_wh[..., 1]\n",
    "        pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n",
    "\n",
    "        union_areas = pred_areas + true_areas - intersect_areas\n",
    "        iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
    "\n",
    "        best_ious = tf.reduce_max(iou_scores, axis=4)\n",
    "        # 1) confidence mask (N, 13, 13, 5)\n",
    "        conf_mask  = tf.zeros(tf.shape(y_true)[:4])\n",
    "        conf_mask = conf_mask + tf.cast(best_ious < 0.6, tf.float32) * (1 - y_true[..., 4]) * self._no_object_scale\n",
    "        \n",
    "        # penalize the confidence of the boxes, which are reponsible for corresponding ground truth box\n",
    "        conf_mask = conf_mask + y_true[..., 4] * self._object_scale\n",
    "        return conf_mask\n",
    "\n",
    "\n",
    "class YoloLoss(object):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 grid_size=13,  #获取栅格的大小->7\n",
    "                 nb_class=1,    #n_classes->获取要检测的类别数量\n",
    "                 anchors=[0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828],#获取先验框\n",
    "                 coord_scale=1.0,#坐标损失的系数=1\n",
    "                 class_scale=1.0,#分类损失系数=1  \n",
    "                 object_scale=5.0, #有对象时的置信度损失=5\n",
    "                 no_object_scale=1.0):#无对象的损失系数=1\n",
    "        \"\"\"\n",
    "        # Args\n",
    "            grid_size : int\n",
    "            batch_size : int\n",
    "            anchors : list of floats\n",
    "            nb_box : int\n",
    "            nb_class : int\n",
    "            true_boxes : Tensor instance\n",
    "        \"\"\"\n",
    "        self.grid_size = grid_size #获取栅格大小\n",
    "        self.anchors = anchors     #获取anchors列表\n",
    "        self.nb_box = int(len(anchors)/2)#获取锚框的数量\n",
    "        self.nb_class = nb_class       #获取要检测的类别数量\n",
    "\n",
    "        self.coord_scale = coord_scale#坐标损失的系数=1\n",
    "\n",
    "        # Todo : create method를 따로 만들어서 주입받자.\n",
    "        self._activator = _Activator(self.anchors)#5个锚框reshape->[1,1,1,5,2]\n",
    "        self._mask = _Mask(nb_class, coord_scale, class_scale, object_scale, no_object_scale)\n",
    "        #n_classes->获取要检测的类别数量   #坐标损失的系数=1  #分类损失系数=1   #有对象时的置信度损失=5  #无对象的损失系数=1\n",
    "\n",
    "    def custom_loss(self, batch_size):\n",
    "        \"\"\"\n",
    "        # Args\n",
    "            y_true : (N, 13, 13, 5, 6)\n",
    "            y_pred : (N, 13, 13, 5, 6)\n",
    "        \n",
    "        \"\"\"\n",
    "        def loss_func(y_true, y_pred):\n",
    "            # 1. activate prediction & truth tensor\n",
    "            true_tensor, pred_tensor = self._activator.run(y_true, y_pred)\n",
    "            true_box_xy, true_box_wh, true_box_conf, true_box_class = true_tensor[..., :2], true_tensor[..., 2:4], true_tensor[..., 4], true_tensor[..., 5]\n",
    "            true_box_class = tf.cast(true_box_class, tf.int64)\n",
    "\n",
    "            # 2. mask\n",
    "            coord_mask = self._mask.create_coord_mask(y_true)\n",
    "            class_mask = self._mask.create_class_mask(y_true, true_box_class)\n",
    "            conf_mask = self._mask.create_conf_mask(y_true, pred_tensor, batch_size)\n",
    "            \n",
    "            \"\"\"\n",
    "            Finalize the loss\n",
    "            \"\"\"\n",
    "            loss = get_loss(coord_mask, conf_mask, class_mask, pred_tensor, true_box_xy, true_box_wh, true_box_conf, true_box_class)\n",
    "            return loss\n",
    "        return loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#返回一个设置好权重,完整的mobilenetv1-yolo网络\n",
    "yolo_loss = YoloLoss(yolo_net.get_grid_size(),  #获取栅格的大小->7\n",
    "                    n_classes,                     #n_classes->获取要检测的类别数量\n",
    "                    anchors,                       #获取先验框\n",
    "                    config['model']['coord_scale'],     #坐标损失的系数=1\n",
    "                    config['model']['class_scale'],     #分类损失系数=1\n",
    "                    config['model']['object_scale'],    #有对象时的置信度损失=5\n",
    "                    config['model']['no_object_scale']) #无对象的损失系数=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_minmax(centroid_boxes):\n",
    "    centroid_boxes = centroid_boxes.astype(np.float)\n",
    "    minmax_boxes = np.zeros_like(centroid_boxes)\n",
    "    \n",
    "    cx = centroid_boxes[:,0]\n",
    "    cy = centroid_boxes[:,1]\n",
    "    w = centroid_boxes[:,2]\n",
    "    h = centroid_boxes[:,3]\n",
    "    \n",
    "    minmax_boxes[:,0] = cx - w/2\n",
    "    minmax_boxes[:,1] = cy - h/2\n",
    "    minmax_boxes[:,2] = cx + w/2\n",
    "    minmax_boxes[:,3] = cy + h/2\n",
    "    return minmax_boxes\n",
    "\n",
    "\n",
    "def centroid_box_iou(box1, box2):\n",
    "    def _interval_overlap(interval_a, interval_b):\n",
    "        x1, x2 = interval_a\n",
    "        x3, x4 = interval_b\n",
    "    \n",
    "        if x3 < x1:\n",
    "            if x4 < x1:\n",
    "                return 0\n",
    "            else:\n",
    "                return min(x2,x4) - x1\n",
    "        else:\n",
    "            if x2 < x3:\n",
    "                return 0\n",
    "            else:\n",
    "                return min(x2,x4) - x3\n",
    "    \n",
    "    _, _, w1, h1 = box1.reshape(-1,)\n",
    "    _, _, w2, h2 = box2.reshape(-1,)\n",
    "    x1_min, y1_min, x1_max, y1_max = to_minmax(box1.reshape(-1,4)).reshape(-1,)\n",
    "    x2_min, y2_min, x2_max, y2_max = to_minmax(box2.reshape(-1,4)).reshape(-1,)\n",
    "            \n",
    "    intersect_w = _interval_overlap([x1_min, x1_max], [x2_min, x2_max])\n",
    "    intersect_h = _interval_overlap([y1_min, y1_max], [y2_min, y2_max])\n",
    "    intersect = intersect_w * intersect_h\n",
    "    union = w1 * h1 + w2 * h2 - intersect\n",
    "    \n",
    "    return float(intersect) / union\n",
    "\n",
    "\n",
    "class BoundBox:\n",
    "    def __init__(self, x, y, w, h, c = None, classes = None):\n",
    "        self.x     = x\n",
    "        self.y     = y\n",
    "        self.w     = w\n",
    "        self.h     = h\n",
    "        \n",
    "        self.c     = c\n",
    "        self.classes = classes\n",
    "\n",
    "    def get_label(self):\n",
    "        return np.argmax(self.classes)\n",
    "    \n",
    "    def get_score(self):\n",
    "        return self.classes[self.get_label()]\n",
    "    \n",
    "    def iou(self, bound_box):\n",
    "        b1 = self.as_centroid()\n",
    "        b2 = bound_box.as_centroid()\n",
    "        return centroid_box_iou(b1, b2)\n",
    "\n",
    "    def as_centroid(self):\n",
    "        return np.array([self.x, self.y, self.w, self.h])\n",
    "\n",
    "def nms_boxes(boxes, n_classes, nms_threshold=0.3, obj_threshold=0.3):\n",
    "    \"\"\"\n",
    "    # Args\n",
    "        boxes : list of BoundBox\n",
    "    \n",
    "    # Returns\n",
    "        boxes : list of BoundBox\n",
    "            non maximum supressed BoundBox instances\n",
    "    \"\"\"\n",
    "    # suppress non-maximal boxes\n",
    "    for c in range(n_classes):\n",
    "        sorted_indices = list(reversed(np.argsort([box.classes[c] for box in boxes])))\n",
    "\n",
    "        for i in range(len(sorted_indices)):\n",
    "            index_i = sorted_indices[i]\n",
    "            \n",
    "            if boxes[index_i].classes[c] == 0: \n",
    "                continue\n",
    "            else:\n",
    "                for j in range(i+1, len(sorted_indices)):\n",
    "                    index_j = sorted_indices[j]\n",
    "\n",
    "                    if boxes[index_i].iou(boxes[index_j]) >= nms_threshold:\n",
    "                        boxes[index_j].classes[c] = 0\n",
    "    # remove the boxes which are less likely than a obj_threshold\n",
    "    boxes = [box for box in boxes if box.get_score() > obj_threshold]\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def boxes_to_array(bound_boxes):\n",
    "    \"\"\"\n",
    "    # Args\n",
    "        boxes : list of BoundBox instances\n",
    "    \n",
    "    # Returns\n",
    "        centroid_boxes : (N, 4)\n",
    "        probs : (N, nb_classes)\n",
    "    \"\"\"\n",
    "    centroid_boxes = []\n",
    "    probs = []\n",
    "    for box in bound_boxes:\n",
    "        centroid_boxes.append([box.x, box.y, box.w, box.h])\n",
    "        probs.append(box.classes)\n",
    "    return np.array(centroid_boxes), np.array(probs)\n",
    "\n",
    "class YoloDecoder(object):\n",
    "\n",
    "    #传入先验框\n",
    "    def __init__(self,\n",
    "                 anchors = [0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828],\n",
    "                 nms_threshold=0.2):\n",
    "        self._anchors = anchors\n",
    "        self._nms_threshold = nms_threshold#nms抑制的阈值\n",
    "\n",
    "    def run(self, netout, obj_threshold=0.3):\n",
    "        \"\"\"Convert Yolo network output to bounding box\n",
    "        \n",
    "        # Args\n",
    "            netout : 4d-array, shape of (grid_h, grid_w, num of boxes per grid, 5 + n_classes)\n",
    "                YOLO neural network output array\n",
    "        \n",
    "        # Returns\n",
    "            boxes : array, shape of (N, 4)\n",
    "                coordinate scale is normalized [0, 1]\n",
    "            probs : array, shape of (N, nb_classes)\n",
    "        \"\"\"\n",
    "        grid_h, grid_w, nb_box = netout.shape[:3]\n",
    "\n",
    "        boxes = []\n",
    "        \n",
    "        # decode the output by the network\n",
    "        netout[..., 4]  = _sigmoid(netout[..., 4])\n",
    "        netout[..., 5:] = netout[..., 4][..., np.newaxis] * _softmax(netout[..., 5:])\n",
    "        netout[..., 5:] *= netout[..., 5:] > obj_threshold\n",
    "        \n",
    "        for row in range(grid_h):\n",
    "            for col in range(grid_w):\n",
    "                for b in range(nb_box):\n",
    "                    # from 4th element onwards are confidence and class classes\n",
    "                    classes = netout[row,col,b,5:]\n",
    "                    \n",
    "                    if np.sum(classes) > 0:\n",
    "                        # first 4 elements are x, y, w, and h\n",
    "                        x, y, w, h = netout[row,col,b,:4]\n",
    "\n",
    "                        x = (col + _sigmoid(x)) / grid_w # center position, unit: image width\n",
    "                        y = (row + _sigmoid(y)) / grid_h # center position, unit: image height\n",
    "                        w = self._anchors[2 * b + 0] * np.exp(w) / grid_w # unit: image width\n",
    "                        h = self._anchors[2 * b + 1] * np.exp(h) / grid_h # unit: image height\n",
    "                        confidence = netout[row,col,b,4]\n",
    "                        box = BoundBox(x, y, w, h, confidence, classes)\n",
    "                        boxes.append(box)\n",
    "        \n",
    "        boxes = nms_boxes(boxes, len(classes), self._nms_threshold, obj_threshold)\n",
    "        boxes, probs = boxes_to_array(boxes)\n",
    "        return boxes, probs\n",
    "\n",
    "def _sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "def _softmax(x, axis=-1, t=-100.):\n",
    "    x = x - np.max(x)\n",
    "    if np.min(x) < t:\n",
    "        x = x/np.min(x)*t\n",
    "    e_x = np.exp(x)\n",
    "    return e_x / e_x.sum(axis, keepdims=True)\n",
    "\n",
    "\n",
    "yolo_decoder = YoloDecoder(anchors) #传入先验框"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Annotation(object):\n",
    "    \"\"\"\n",
    "    # Attributes\n",
    "        fname : image file path\n",
    "        labels : list of strings\n",
    "        boxes : Boxes instance\n",
    "    \"\"\"\n",
    "    def __init__(self, filename):#传入xml对应的img路径,获得一个annotation类\n",
    "        self.fname = filename\n",
    "        self.labels = []\n",
    "        self.boxes = None\n",
    "\n",
    "    def add_object(self, x1, y1, x2, y2, name):#传入锚框的4个点和标签,添加Annotation类的labels成员和boxes成员,labels为列表,boxes的维度是[n,4]\n",
    "        self.labels.append(name)\n",
    "        if self.boxes is None:\n",
    "            self.boxes = np.array([x1, y1, x2, y2]).reshape(-1,4)\n",
    "        else:\n",
    "            box = np.array([x1, y1, x2, y2]).reshape(-1,4)\n",
    "            self.boxes = np.concatenate([self.boxes, box])#横向拼接\n",
    "\n",
    "class Annotations(object):\n",
    "    def __init__(self, label_namings):#送入  labels_naming\n",
    "        self._components = []\n",
    "        self._label_namings = label_namings\n",
    "\n",
    "    def n_classes(self):\n",
    "        return len(self._label_namings)\n",
    "\n",
    "    def add(self, annotation):#传入annotation成员,将annotation成员添加至_components成员的列表中\n",
    "        self._components.append(annotation)\n",
    "\n",
    "    def shuffle(self):\n",
    "        np.random.shuffle(self._components)\n",
    "    \n",
    "    def fname(self, i):\n",
    "        index = self._valid_index(i)\n",
    "        return self._components[index].fname\n",
    "    \n",
    "    def boxes(self, i):\n",
    "        index = self._valid_index(i)\n",
    "        return self._components[index].boxes\n",
    "\n",
    "    def labels(self, i):\n",
    "        \"\"\"\n",
    "        # Returns\n",
    "            labels : list of strings\n",
    "        \"\"\"\n",
    "        index = self._valid_index(i)\n",
    "        return self._components[index].labels\n",
    "\n",
    "    def code_labels(self, i):\n",
    "        \"\"\"\n",
    "        # Returns\n",
    "            code_labels : list of int\n",
    "        \"\"\"\n",
    "        str_labels = self.labels(i)\n",
    "        labels = []\n",
    "        for label in str_labels:\n",
    "            labels.append(self._label_namings.index(label))\n",
    "        return labels\n",
    "\n",
    "    def _valid_index(self, i):\n",
    "        valid_index = i % len(self._components)\n",
    "        return valid_index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._components)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self._components[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree.ElementTree import parse\n",
    "class PascalVocXmlParser(object):\n",
    "    \"\"\"Parse annotation for 1-annotation file \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get_fname(self, annotation_file):#传入xml标签对应的文件路径,返回最后的文件名.jpg\n",
    "        \"\"\"\n",
    "        # Args\n",
    "            annotation_file : str\n",
    "                annotation file including directory path\n",
    "        \n",
    "        # Returns\n",
    "            filename : str\n",
    "        \"\"\"\n",
    "\n",
    "        root = self._root_tag(annotation_file)#传入xml标签对应的文件路径,返回xml文件解析后的根节点\n",
    "        #print(os.path.splitext(os.path.basename(annotation_file))[0]+os.path.splitext(root.find(\"filename\").text)[1])\n",
    "\n",
    "        return os.path.splitext(os.path.basename(annotation_file))[0]+os.path.splitext(root.find(\"filename\").text)[1]\n",
    "        # root.find(\"filename\").text->在目录中查找filename文件 .text获取内容   os.path.splitext(path)->将对应路径的文件名和后缀名分割\n",
    "        #os.path.basename(annotation_file)->返回path最后的文件名\n",
    "    def _root_tag(self, fname):#传入xml标签对应的文件路径\n",
    "        tree = parse(fname)  #ET.parse('country_data.xml')  ->解析xml文件\n",
    "        root = tree.getroot()#获取根节点\n",
    "        return root\n",
    "\n",
    "    def _tree(self, fname):\n",
    "        tree = parse(fname)\n",
    "        return tree\n",
    "    def get_width(self, annotation_file):\n",
    "        \"\"\"\n",
    "        # Args\n",
    "            annotation_file : str\n",
    "                annotation file including directory path\n",
    "        \n",
    "        # Returns\n",
    "            width : int\n",
    "        \"\"\"\n",
    "        tree = self._tree(annotation_file)\n",
    "        for elem in tree.iter():\n",
    "            if 'width' in elem.tag:\n",
    "                return int(elem.text)\n",
    "\n",
    "    def get_height(self, annotation_file):\n",
    "        \"\"\"\n",
    "        # Args\n",
    "            annotation_file : str\n",
    "                annotation file including directory path\n",
    "        \n",
    "        # Returns\n",
    "            height : int\n",
    "        \"\"\"\n",
    "        tree = self._tree(annotation_file)\n",
    "        for elem in tree.iter():\n",
    "            if 'height' in elem.tag:\n",
    "                return int(elem.text)\n",
    "\n",
    "    def get_labels(self, annotation_file):#传入xml标签对应的文件路径，返回xml里包含的labels标签列表\n",
    "        \"\"\"\n",
    "        # Args\n",
    "            annotation_file : str\n",
    "                annotation file including directory path\n",
    "        \n",
    "        # Returns\n",
    "            labels : list of strs\n",
    "        \"\"\"\n",
    "\n",
    "        root = self._root_tag(annotation_file)#传入xml标签对应的文件路径,返回根节点\n",
    "        labels = []\n",
    "        obj_tags = root.findall(\"object\")#寻找所有object对象\n",
    "        for t in obj_tags:\n",
    "            labels.append(t.find(\"name\").text)\n",
    "        return labels\n",
    "    \n",
    "    def get_boxes(self, annotation_file):#传入xml标签对应的文件路径，以[[xmin,ymin,xmax,ymax],[xmin,ymin,xmax,ymax]...]的格式返回找到的锚框坐标\n",
    "        \"\"\"\n",
    "        # Args\n",
    "            annotation_file : str\n",
    "                annotation file including directory path\n",
    "        \n",
    "        # Returns\n",
    "            bbs : 2d-array, shape of (N, 4)\n",
    "                (x1, y1, x2, y2)-ordered\n",
    "        \"\"\"\n",
    "        root = self._root_tag(annotation_file)#获取根节点\n",
    "        bbs = []\n",
    "        obj_tags = root.findall(\"object\")#寻找所有对象\n",
    "        for t in obj_tags:\n",
    "            box_tag = t.find(\"bndbox\")#寻找所有锚框类\n",
    "            x1 = box_tag.find(\"xmin\").text\n",
    "            y1 = box_tag.find(\"ymin\").text\n",
    "            x2 = box_tag.find(\"xmax\").text\n",
    "            y2 = box_tag.find(\"ymax\").text\n",
    "            box = np.array([int(float(x1)), int(float(y1)), int(float(x2)), int(float(y2))])\n",
    "            bbs.append(box)\n",
    "        bbs = np.array(bbs)#以[[xmin,ymin,xmax,ymax],[xmin,ymin,xmax,ymax]...]的格式返回找到的锚框坐标\n",
    "        print(bbs)\n",
    "        return bbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_annotation(ann_dir, img_dir, labels_naming=[], is_only_detect=False):\n",
    "    #ann_dir->xml标签对应的文件夹  img_dir->图片对应的文件夹  labels_naming  is_only_detect->0,不仅仅为了检测\n",
    "    #返回一个Annotations对象,将annotation成员添加至_components成员的列表中\n",
    "    #Annotation类的labels成员和boxes成员,labels为一个xml文件中每一个锚框对应得label,boxes的维度是[n,4]\n",
    "    \"\"\"\n",
    "    # Args\n",
    "        ann_dir : str\n",
    "        img_dir : str\n",
    "        labels_naming : list of strings\n",
    "    \n",
    "    # Returns\n",
    "        all_imgs : list of dict\n",
    "    \"\"\"\n",
    "    parser = PascalVocXmlParser()#定义一个解析xml类\n",
    "    \n",
    "    if is_only_detect:\n",
    "        annotations = Annotations([\"object\"])\n",
    "    else:\n",
    "        annotations = Annotations(labels_naming)#送入  labels_naming,返回一个Annotations类\n",
    "    for ann in sorted(os.listdir(ann_dir)):#返回xml标签对应的文件夹包含的 文件名字列表  sorted()->对list进行排序\n",
    "        annotation_file = os.path.join(ann_dir, ann)#获得xml标签对应的文件路径\n",
    "        fname = parser.get_fname(annotation_file)#传入xml标签对应的文件路径,返回最后的文件名.jpg\n",
    "\n",
    "        annotation = Annotation(os.path.join(img_dir, fname))#传入xml对应的img路径,获得一个annotation类\n",
    "\n",
    "        labels = parser.get_labels(annotation_file)#传入xml标签对应的文件路径,返回xml里包含的labels标签列表\n",
    "        boxes = parser.get_boxes(annotation_file)#传入xml标签对应的文件路径，以[[xmin,ymin,xmax,ymax],[xmin,ymin,xmax,ymax]...]的格式返回找到的锚框坐标\n",
    "        \n",
    "        for label, box in zip(labels, boxes):\n",
    "            x1, y1, x2, y2 = box\n",
    "            if is_only_detect:\n",
    "                annotation.add_object(x1, y1, x2, y2, name=\"object\")\n",
    "            else:\n",
    "                if label in labels_naming:\n",
    "                    annotation.add_object(x1, y1, x2, y2, name=label)#传入锚框的4个点和标签,添加Annotation类的labels成员和boxes成员,labels为列表,boxes的维度是[n,4]\n",
    "                    \n",
    "        if annotation.boxes is not None:\n",
    "            annotations.add(annotation)#传入annotation成员,将annotation成员添加至_components成员的列表中\n",
    "                        \n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_annotations(labels,#标签列表\n",
    "                          img_folder,#图片对应的文件夹\n",
    "                          ann_folder,#xml标签对应的文件夹\n",
    "                          valid_img_folder = \"\",#图片对应的文件夹\n",
    "                          valid_ann_folder = \"\",#xml标签对应的文件夹\n",
    "                          is_only_detect=False):#不仅仅是为了检测\n",
    "#返回两个Annotations对象,将annotation成员添加至_components成员的列表中,_label_namings成员记录标签列表\n",
    "#Annotation类的labels成员和boxes成员,labels为列表,boxes的维度是[n,4],filename成员保存的是xml对应的img路径\n",
    "#两个Annotations对象对应的分别是train_anns,train_anns\n",
    "    \"\"\"\n",
    "    # Args\n",
    "        labels : list of strings\n",
    "            [\"raccoon\", \"human\", ...]\n",
    "        img_folder : str\n",
    "        ann_folder : str\n",
    "        valid_img_folder : str\n",
    "        valid_ann_folder : str\n",
    "\n",
    "    # Returns\n",
    "        train_anns : Annotations instance\n",
    "        valid_anns : Annotations instance\n",
    "    \"\"\"\n",
    "    # parse annotations of the training set\n",
    "    train_anns = parse_annotation(ann_folder,#xml标签对应的文件夹\n",
    "                                     img_folder,#图片对应的文件夹\n",
    "                                     labels,#标签列表\n",
    "                                     is_only_detect)#不仅仅是为了检测\n",
    "    #返回一个Annotations对象,将annotation成员添加至_components成员的列表中,_label_namings[]成员存放的是标签列表\n",
    "    #Annotation类的labels成员和boxes成员,labels为一个xml文件中每一个锚框对应得label,boxes的维度是[n,4]\n",
    "\n",
    "\n",
    "    if os.path.exists(valid_ann_folder):#如果valid_ann_folder存在的话,就同样获得Annotations对象\n",
    "        valid_anns = parse_annotation(valid_ann_folder,\n",
    "                                         valid_img_folder,\n",
    "                                         labels,\n",
    "                                         is_only_detect)\n",
    "    else:#否则将训练集2,8分\n",
    "        train_valid_split = int(0.8*len(train_anns))\n",
    "        train_anns.shuffle()\n",
    "        \n",
    "        # Todo : Hard coding\n",
    "        valid_anns = Annotations(train_anns._label_namings)\n",
    "        valid_anns._components = train_anns._components[train_valid_split:]\n",
    "        train_anns._components = train_anns._components[:train_valid_split]\n",
    "    \n",
    "    return train_anns, valid_anns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pyecharts.options as opts\n",
    "import warnings\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from pyecharts.charts import Line\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "def save_tflite(model,num,w_name,alpha,anchors,label,i):\n",
    "\n",
    "    output_layer=\"detection_layer_\"+str(num)+\"/BiasAdd\"\n",
    "    model.save(i+\"/yolov2.h5\", include_optimizer=False)\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    converter = tf.compat.v1.lite.TFLiteConverter.from_keras_model_file(i+\"/yolov2.h5\",\n",
    "                                        output_arrays=[output_layer])\n",
    "    \n",
    "    tfmodel = converter.convert()\n",
    "    file = open (i+\"/yolov2.tflite\" , \"wb\")\n",
    "    file.write(tfmodel)\n",
    "    anchorstxt=open(i+\"/anchors.txt\",\"w\")\n",
    "    anchorstxt.write(str(anchors).replace(\"[\",\"\").replace(\"]\",\"\"))\n",
    "    anchorstxt.close()\n",
    "    lable=open(i+\"/lable.txt\",\"w\")\n",
    "    lable.write(str(label).replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\"))\n",
    "    lable.close()\n",
    "    os.startfile(os.getcwd()+\"/\"+i)\n",
    "\n",
    "def time_():\n",
    "    now_time=time.strftime('%m-%d-%H-%M-%S',time.localtime(time.time()))\n",
    "    return now_time\n",
    "\n",
    "def _print_time(process_time):\n",
    "    if process_time < 60:\n",
    "        print(\"{:d}-seconds to train\".format(int(process_time)))\n",
    "    else:\n",
    "        print(\"{:d}-mins to train\".format(int(process_time/60)))\n",
    "\n",
    "class CheckpointPB(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, filepath, monitor='val_loss', verbose=0,\n",
    "                 save_best_only=False, save_weights_only=False,\n",
    "                 mode='auto', period=1):\n",
    "        super(CheckpointPB, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.verbose = verbose\n",
    "        self.filepath = filepath\n",
    "        self.save_best_only = save_best_only\n",
    "        self.save_weights_only = save_weights_only\n",
    "        self.period = period\n",
    "        self.epochs_since_last_save = 0\n",
    "\n",
    "        if mode not in ['auto', 'min', 'max']:\n",
    "            warnings.warn('ModelCheckpoint mode %s is unknown, '\n",
    "                          'fallback to auto mode.' % (mode),\n",
    "                          RuntimeWarning)\n",
    "            mode = 'auto'\n",
    "\n",
    "        if mode == 'min':\n",
    "            self.monitor_op = np.less\n",
    "            self.best = np.Inf\n",
    "        elif mode == 'max':\n",
    "            self.monitor_op = np.greater\n",
    "            self.best = -np.Inf\n",
    "        else:\n",
    "            if 'acc' in self.monitor or self.monitor.startswith('fmeasure'):\n",
    "                self.monitor_op = np.greater\n",
    "                self.best = -np.Inf\n",
    "            else:\n",
    "                self.monitor_op = np.less\n",
    "                self.best = np.Inf\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        self.epochs_since_last_save += 1\n",
    "        if self.epochs_since_last_save >= self.period:\n",
    "            self.epochs_since_last_save = 0\n",
    "            filepath = self.filepath.format(epoch=epoch + 1, **logs)\n",
    "            if self.save_best_only:\n",
    "                current = logs.get(self.monitor)\n",
    "                if current is None:\n",
    "                    warnings.warn('Can save best model only with %s available, '\n",
    "                                  'skipping.' % (self.monitor), RuntimeWarning)\n",
    "                else:\n",
    "                    if self.monitor_op(current, self.best):\n",
    "                        if self.verbose > 0:\n",
    "                            print('\\nEpoch %05d: %s improved from %0.5f to %0.5f,'\n",
    "                                  ' saving model to %s'\n",
    "                                  % (epoch + 1, self.monitor, self.best,\n",
    "                                     current, filepath))\n",
    "                        self.best = current\n",
    "                        if self.save_weights_only:\n",
    "                            self.model.save_weights(filepath, overwrite=True)\n",
    "                        else:\n",
    "                            self.model.save(filepath, overwrite=True)\n",
    "                            save_tflite(self.model)\n",
    "                    else:\n",
    "                        if self.verbose > 0:\n",
    "                            print('\\nEpoch %05d: %s did not improve from %0.5f' %\n",
    "                                  (epoch + 1, self.monitor, self.best))\n",
    "            else:\n",
    "                if self.verbose > 0:\n",
    "                    print('\\nEpoch %05d: saving model to %s' % (epoch + 1, filepath))\n",
    "                if self.save_weights_only:\n",
    "                    self.model.save_weights(filepath, overwrite=True)\n",
    "                else:\n",
    "                    self.model.save(filepath, overwrite=True)\n",
    "\n",
    "def _create_callbacks(saved_weights_name):\n",
    "    # Make a few callbacks\n",
    "    early_stop = EarlyStopping(monitor='val_loss', \n",
    "                       min_delta=0.001, \n",
    "                       patience=20, \n",
    "                       mode='min', \n",
    "                       verbose=1,\n",
    "                       restore_best_weights=True)\n",
    "    checkpoint = CheckpointPB(saved_weights_name, \n",
    "                                 monitor='val_loss', \n",
    "                                 verbose=1, \n",
    "                                 save_best_only=True, \n",
    "                                 mode='min', \n",
    "                                 period=1)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.00001, verbose=1)\n",
    "    callbacks = [early_stop,reduce_lr]\n",
    "    return callbacks\n",
    "\n",
    "\n",
    "def train(model,\n",
    "         loss_func,\n",
    "         train_batch_gen,\n",
    "         valid_batch_gen,\n",
    "         learning_rate = 1e-4,\n",
    "         nb_epoch = 300,\n",
    "         saved_weights_name = 'best_weights.h5',\n",
    "         class_num=1,\n",
    "         anchors=[0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828],\n",
    "         w_name=\"\",\n",
    "         alpha=0.75,\n",
    "         lable=\"\"\n",
    "         ):\n",
    "    \"\"\"A function that performs training on a general keras model.\n",
    "\n",
    "    # Args\n",
    "        model : tensorflow.keras.models.Model instance\n",
    "        loss_func : function\n",
    "            refer to https://keras.io/losses/\n",
    "\n",
    "        train_batch_gen : tensorflow.keras.utils.Sequence instance\n",
    "        valid_batch_gen : tensorflow.keras.utils.Sequence instance\n",
    "        learning_rate : float\n",
    "        saved_weights_name : str\n",
    "    \"\"\"\n",
    "    # 1. create optimizer\n",
    "    optimizer = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    \n",
    "    # 2. create loss function\n",
    "    model.compile(loss=loss_func,\n",
    "                  optimizer=optimizer)\n",
    "    \n",
    "    # 4. training\n",
    "    train_start = time.time()\n",
    "    try:\n",
    "        history=model.fit_generator(generator = train_batch_gen,\n",
    "                        steps_per_epoch  = len(train_batch_gen), \n",
    "                        epochs           = nb_epoch,\n",
    "                        validation_data  = valid_batch_gen,\n",
    "                        validation_steps = len(valid_batch_gen),\n",
    "                        callbacks        = _create_callbacks(saved_weights_name),                        \n",
    "                        verbose          = 1,\n",
    "                        workers          = 3,\n",
    "                        max_queue_size   = 8)\n",
    "\n",
    "        # history=model.fit(x_train)\n",
    "        print(history.history)\n",
    "        \n",
    "        plt.figure(\"loss\")\n",
    "        plt.grid()\n",
    "        num1=1\n",
    "        num2=0\n",
    "        num3=3\n",
    "        num4=4\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('loss')\n",
    "        plt.legend(['train', 'test'], loc='upper right')\n",
    "        i=\"./Model_file\"+\"/yolov2物体识别_\"+w_name+\"_\"+str(alpha)+\"-\"+time_()\n",
    "        os.mkdir(i)\n",
    "\n",
    "        plt.savefig(i+'/Loss.jpg')\n",
    "        plt.show()\n",
    "        loss_=[]\n",
    "        loss_val=[]\n",
    "        for o in history.history['loss']:\n",
    "            loss_.append(round(o,4))\n",
    "        for o in history.history['val_loss']:\n",
    "            loss_val.append(round(o,4))\n",
    "        c = (\n",
    "            Line()\n",
    "            .add_xaxis(range(1,len(loss_)+1))\n",
    "            .add_yaxis(\"Train\",loss_, is_smooth=True,linestyle_opts=opts.LineStyleOpts(width=3),is_symbol_show=False,color=\"#2196F3\")\n",
    "            .add_yaxis(\"Test\", loss_val, is_smooth=True,linestyle_opts=opts.LineStyleOpts(width=3),is_symbol_show=False,color=\"#F9A825\")\n",
    "            .set_global_opts(title_opts=opts.TitleOpts(title=\"Loss损失率\"),\n",
    "                            toolbox_opts=opts.ToolboxOpts(is_show=True,orient=\"vertical\",pos_left=\"right\",feature=opts.ToolBoxFeatureOpts(save_as_image=opts.ToolBoxFeatureSaveAsImageOpts(background_color=\"#fff\"),\n",
    "                                                                                                                                            magic_type=opts.ToolBoxFeatureMagicTypeOpts(is_show=False),\n",
    "                                                                                                                                            data_zoom=opts.ToolBoxFeatureDataZoomOpts(is_show=False),\n",
    "                                                                                                                                            data_view=opts.ToolBoxFeatureSaveAsImageOpts(is_show=False),\n",
    "                                                                                                                                            brush=opts.ToolBoxFeatureBrushOpts(type_='rect')),\n",
    "                                                                                                                                            ),\n",
    "                            datazoom_opts=opts.DataZoomOpts(is_show=True,range_end=100,range_start=0,filter_mode=\"none\"),\n",
    "                            tooltip_opts=opts.TooltipOpts(is_show=True),\n",
    "                            legend_opts=opts.LegendOpts(legend_icon=\"circle\"),\n",
    "                            axispointer_opts=opts.AxisPointerOpts(is_show=True))\n",
    "            .set_series_opts(splitline_opts=opts.SplitLineOpts(is_show=True))\n",
    "            .render(i+\"/Loss.html\")\n",
    "        )\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        save_tflite(model,class_num,w_name,alpha,anchors,lable,i)\n",
    "        raise\n",
    "\n",
    "    _print_time(time.time() - train_start)\n",
    "    save_tflite(model,class_num,w_name,alpha,anchors,lable,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from imgaug import augmenters as iaa\n",
    "def _create_augment_pipeline():\n",
    "    \n",
    "    ### augmentors by https://github.com/aleju/imgaug\n",
    "    sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "\n",
    "    # Define our sequence of augmentation steps that will be applied to every image\n",
    "    # All augmenters with per_channel=0.5 will sample one value _per image_\n",
    "    # in 50% of all cases. In all other cases they will sample new values\n",
    "    # _per channel_.\n",
    "    aug_pipe = iaa.Sequential(\n",
    "        [\n",
    "            # apply the following augmenters to most images\n",
    "            #iaa.Fliplr(0.5), # horizontally flip 50% of all images\n",
    "            #iaa.Flipud(0.2), # vertically flip 20% of all images\n",
    "            #sometimes(iaa.Crop(percent=(0, 0.1))), # crop images by 0-10% of their height/width\n",
    "            #sometimes(iaa.Affine(\n",
    "                #scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)}, # scale images to 80-120% of their size, individually per axis\n",
    "                #translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)}, # translate by -20 to +20 percent (per axis)\n",
    "                #rotate=(-5, 5), # rotate by -45 to +45 degrees\n",
    "                #shear=(-5, 5), # shear by -16 to +16 degrees\n",
    "                #order=[0, 1], # use nearest neighbour or bilinear interpolation (fast)\n",
    "                #cval=(0, 255), # if mode is constant, use a cval between 0 and 255\n",
    "                #mode=ia.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
    "            #)),\n",
    "            # execute 0 to 5 of the following (less important) augmenters per image\n",
    "            # don't execute all of them, as that would often be way too strong\n",
    "            iaa.SomeOf((0, 5),\n",
    "                [\n",
    "                    #sometimes(iaa.Superpixels(p_replace=(0, 1.0), n_segments=(20, 200))), # convert images into their superpixel representation\n",
    "                    iaa.OneOf([\n",
    "                        iaa.GaussianBlur((0, 3.0)), # blur images with a sigma between 0 and 3.0\n",
    "                        iaa.AverageBlur(k=(2, 7)), # blur image using local means with kernel sizes between 2 and 7\n",
    "                        iaa.MedianBlur(k=(3, 11)), # blur image using local medians with kernel sizes between 2 and 7\n",
    "                    ]),\n",
    "                    iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5)), # sharpen images\n",
    "                    #iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)), # emboss images\n",
    "                    # search either for all edges or for directed edges\n",
    "                    #sometimes(iaa.OneOf([\n",
    "                    #    iaa.EdgeDetect(alpha=(0, 0.7)),\n",
    "                    #    iaa.DirectedEdgeDetect(alpha=(0, 0.7), direction=(0.0, 1.0)),\n",
    "                    #])),\n",
    "                    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5), # add gaussian noise to images\n",
    "                    iaa.OneOf([\n",
    "                        iaa.Dropout((0.01, 0.1), per_channel=0.5), # randomly remove up to 10% of the pixels\n",
    "                        #iaa.CoarseDropout((0.03, 0.15), size_percent=(0.02, 0.05), per_channel=0.2),\n",
    "                    ]),\n",
    "                    #iaa.Invert(0.05, per_channel=True), # invert color channels\n",
    "                    iaa.Add((-10, 10), per_channel=0.5), # change brightness of images (by -10 to 10 of original value)\n",
    "                    iaa.Multiply((0.5, 1.5), per_channel=0.5), # change brightness of images (50-150% of original value)\n",
    "                    iaa.ContrastNormalization((0.5, 2.0), per_channel=0.5), # improve or worsen the contrast\n",
    "                    #iaa.Grayscale(alpha=(0.0, 1.0)),\n",
    "                    #sometimes(iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)), # move pixels locally around (with random strengths)\n",
    "                    #sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05))) # sometimes move parts of the image around\n",
    "                ],\n",
    "                random_order=True\n",
    "            )\n",
    "        ],\n",
    "        random_order=True\n",
    "    )\n",
    "    return aug_pipe\n",
    "\n",
    "\n",
    "def make_jitter_on_image(image, boxes):\n",
    "    h, w, _ = image.shape\n",
    "\n",
    "    ### scale the image\n",
    "    scale = np.random.uniform() / 10. + 1.\n",
    "    image = cv2.resize(image, (0,0), fx = scale, fy = scale)\n",
    "\n",
    "    ### translate the image\n",
    "    max_offx = (scale-1.) * w\n",
    "    max_offy = (scale-1.) * h\n",
    "    offx = int(np.random.uniform() * max_offx)\n",
    "    offy = int(np.random.uniform() * max_offy)\n",
    "    \n",
    "    image = image[offy : (offy + h), offx : (offx + w)]\n",
    "\n",
    "    ### flip the image\n",
    "    #flip = np.random.binomial(1, .5)\n",
    "    #if flip > 0.5:\n",
    "    #    image = cv2.flip(image, 1)\n",
    "    #    is_flip = True\n",
    "    #else:\n",
    "    #    is_flip = False\n",
    "\n",
    "    aug_pipe = _create_augment_pipeline()\n",
    "    image = aug_pipe.augment_image(image)\n",
    "    \n",
    "    # fix object's position and size\n",
    "    new_boxes = []\n",
    "    for box in boxes:\n",
    "        x1,y1,x2,y2 = box\n",
    "        x1 = int(x1 * scale - offx)\n",
    "        x2 = int(x2 * scale - offx)\n",
    "        \n",
    "        y1 = int(y1 * scale - offy)\n",
    "        y2 = int(y2 * scale - offy)\n",
    "\n",
    "    #    if is_flip:\n",
    "    #        xmin = x1\n",
    "    #        x1 = w - x2\n",
    "    #        x2 = w - xmin\n",
    "        new_boxes.append([x1,y1,x2,y2])\n",
    "    return image, np.array(new_boxes)\n",
    "\n",
    "\n",
    "def resize_image(image, boxes, desired_w, desired_h):\n",
    "    h, w, _ = image.shape\n",
    "    \n",
    "    # resize the image to standard size\n",
    "    image = cv2.resize(image, (desired_h, desired_w))\n",
    "    image = image[:,:,::-1]\n",
    "\n",
    "    # fix object's position and size\n",
    "    new_boxes = []\n",
    "    for box in boxes:\n",
    "        x1,y1,x2,y2 = box\n",
    "        x1 = int(x1 * float(desired_w) / w)\n",
    "        x1 = max(min(x1, desired_w - 1), 0)\n",
    "        x2 = int(x2 * float(desired_w) / w)\n",
    "        x2 = max(min(x2, desired_w - 1), 0)\n",
    "        \n",
    "        y1 = int(y1 * float(desired_h) / h)\n",
    "        y1 = max(min(y1, desired_h - 1), 0)\n",
    "        y2 = int(y2 * float(desired_h) / h)\n",
    "        y2 = max(min(y2, desired_h - 1), 0)\n",
    "\n",
    "        new_boxes.append([x1,y1,x2,y2])\n",
    "    return image, np.array(new_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgAugment(object):\n",
    "    def __init__(self, w, h, jitter):\n",
    "        \"\"\"\n",
    "        # Args\n",
    "            desired_w : int\n",
    "            desired_h : int\n",
    "            jitter : bool\n",
    "        \"\"\"\n",
    "        self._jitter = jitter\n",
    "        self._w = w\n",
    "        self._h = h\n",
    "        \n",
    "    def imread(self, img_file, boxes):\n",
    "        \"\"\"\n",
    "        # Args\n",
    "            img_file : str\n",
    "            boxes : array, shape of (N, 4)\n",
    "        \n",
    "        # Returns\n",
    "            image : 3d-array, shape of (h, w, 3)\n",
    "            boxes_ : array, same shape of boxes\n",
    "                jittered & resized bounding box\n",
    "        \"\"\"\n",
    "        # 1. read image file\n",
    "        image = cv2.imread(img_file)\n",
    "        if image is None:\n",
    "            print(\"Image Path: \" + img_file)\n",
    "            raise ValueError\n",
    "    \n",
    "        # 2. make jitter on image\n",
    "        boxes_ = np.copy(boxes)\n",
    "        if self._jitter:\n",
    "            image, boxes_ = make_jitter_on_image(image, boxes_)\n",
    "    \n",
    "        # 3. resize image            \n",
    "        image, boxes_ = resize_image(image, boxes_, self._w, self._h)\n",
    "        return image, boxes_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_centroid(minmax_boxes):\n",
    "    \"\"\"\n",
    "    minmax_boxes : (N, 4)\n",
    "    \"\"\"\n",
    "    minmax_boxes = minmax_boxes.astype(np.float)\n",
    "    centroid_boxes = np.zeros_like(minmax_boxes)\n",
    "    \n",
    "    x1 = minmax_boxes[:,0]\n",
    "    y1 = minmax_boxes[:,1]\n",
    "    x2 = minmax_boxes[:,2]\n",
    "    y2 = minmax_boxes[:,3]\n",
    "    \n",
    "    centroid_boxes[:,0] = (x1 + x2) / 2\n",
    "    centroid_boxes[:,1] = (y1 + y2) / 2\n",
    "    centroid_boxes[:,2] = x2 - x1\n",
    "    centroid_boxes[:,3] = y2 - y1\n",
    "    return centroid_boxes\n",
    "\n",
    "def create_anchor_boxes(anchors):\n",
    "    \"\"\"\n",
    "    # Args\n",
    "        anchors : list of floats\n",
    "    # Returns\n",
    "        boxes : array, shape of (len(anchors)/2, 4)\n",
    "            centroid-type\n",
    "    \"\"\"\n",
    "    boxes = []\n",
    "    n_boxes = int(len(anchors)/2)\n",
    "    for i in range(n_boxes):\n",
    "        boxes.append(np.array([0, 0, anchors[2*i], anchors[2*i+1]]))\n",
    "    return np.array(boxes)\n",
    "\n",
    "\n",
    "def find_match_box(centroid_box, centroid_boxes):\n",
    "    \"\"\"Find the index of the boxes with the largest overlap among the N-boxes.\n",
    "\n",
    "    # Args\n",
    "        box : array, shape of (1, 4)\n",
    "        boxes : array, shape of (N, 4)\n",
    "    \n",
    "    # Return\n",
    "        match_index : int\n",
    "    \"\"\"\n",
    "    match_index = -1\n",
    "    max_iou     = -1\n",
    "    \n",
    "    for i, box in enumerate(centroid_boxes):\n",
    "        iou = centroid_box_iou(centroid_box, box)\n",
    "        \n",
    "        if max_iou < iou:\n",
    "            match_index = i\n",
    "            max_iou     = iou\n",
    "    return match_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _YoloBox(object):\n",
    "    \n",
    "    def __init__(self, input_size, grid_size):\n",
    "        self._input_size = input_size\n",
    "        self._grid_size = grid_size\n",
    "\n",
    "    def trans(self, boxes):\n",
    "        \"\"\"\n",
    "        # Args\n",
    "            boxes : array, shape of (N, 4)\n",
    "                (x1, y1, x2, y2)-ordered & input image size scale coordinate\n",
    "        \n",
    "        # Returns\n",
    "            norm_boxes : array, same shape of boxes\n",
    "                (cx, cy, w, h)-ordered & rescaled to grid-size\n",
    "        \"\"\"\n",
    "        # 1. minimax box -> centroid box\n",
    "        centroid_boxes = to_centroid(boxes).astype(np.float32)\n",
    "        # 2. image scale -> grid scale\n",
    "        norm_boxes = centroid_boxes * (self._grid_size / self._input_size)\n",
    "        return norm_boxes\n",
    "\n",
    "\n",
    "class _NetinGen(object):\n",
    "    def __init__(self, input_size, norm):\n",
    "        self._input_size = input_size\n",
    "        self._norm = self._set_norm(norm)\n",
    "    \n",
    "    def run(self, image):\n",
    "        return self._norm(image)\n",
    "    \n",
    "    def _set_norm(self, norm):\n",
    "        if norm is None:\n",
    "            return lambda x: x\n",
    "        else:\n",
    "            return norm\n",
    "\n",
    "\n",
    "class _NetoutGen(object):\n",
    "    def __init__(self,\n",
    "                 grid_size,\n",
    "                 nb_classes,\n",
    "                 anchors=[0.57273, 0.677385,\n",
    "                          1.87446, 2.06253,\n",
    "                          3.33843, 5.47434,\n",
    "                          7.88282, 3.52778,\n",
    "                          9.77052, 9.16828]):\n",
    "        self._anchors = create_anchor_boxes(anchors)\n",
    "        self._tensor_shape = self._set_tensor_shape(grid_size, nb_classes)\n",
    "\n",
    "    def run(self, norm_boxes, labels):\n",
    "        \"\"\"\n",
    "        # Args\n",
    "            norm_boxes : array, shape of (N, 4)\n",
    "                scale normalized boxes\n",
    "            labels : list of integers\n",
    "            y_shape : tuple (grid_size, grid_size, nb_boxes, 4+1+nb_classes)\n",
    "        \"\"\"\n",
    "        y = np.zeros(self._tensor_shape)\n",
    "        \n",
    "        # loop over objects in one image\n",
    "        for norm_box, label in zip(norm_boxes, labels):\n",
    "            best_anchor = self._find_anchor_idx(norm_box)\n",
    "\n",
    "            # assign ground truth x, y, w, h, confidence and class probs to y_batch\n",
    "            y += self._generate_y(best_anchor, label, norm_box)\n",
    "        return y\n",
    "\n",
    "    def _set_tensor_shape(self, grid_size, nb_classes):\n",
    "        nb_boxes = len(self._anchors)\n",
    "        return (grid_size, grid_size, nb_boxes, 4+1+nb_classes)\n",
    "\n",
    "    def _find_anchor_idx(self, norm_box):\n",
    "        _, _, center_w, center_h = norm_box\n",
    "        shifted_box = np.array([0, 0, center_w, center_h])\n",
    "        return find_match_box(shifted_box, self._anchors)\n",
    "    \n",
    "    def _generate_y(self, best_anchor, obj_indx, box):\n",
    "        y = np.zeros(self._tensor_shape)\n",
    "        grid_x, grid_y, _, _ = box.astype(int)\n",
    "        y[grid_y, grid_x, best_anchor, 0:4] = box\n",
    "        y[grid_y, grid_x, best_anchor, 4  ] = 1.\n",
    "        y[grid_y, grid_x, best_anchor, 5+obj_indx] = 1\n",
    "        return y\n",
    "        \n",
    "from tensorflow.keras.utils import Sequence\n",
    "class BatchGenerator(Sequence):\n",
    "    def __init__(self,\n",
    "                 netin_gen,\n",
    "                 netout_gen,\n",
    "                 yolo_box,\n",
    "                 img_aug,\n",
    "                 annotations,\n",
    "                 batch_size,\n",
    "                 repeat_times):\n",
    "        \"\"\"\n",
    "        # Args\n",
    "            annotations : Annotations instance\n",
    "        \n",
    "        \"\"\"\n",
    "        self._netin_gen = netin_gen\n",
    "        self._netout_gen = netout_gen\n",
    "        self._img_aug = img_aug\n",
    "        self._yolo_box = yolo_box\n",
    "\n",
    "        self._batch_size = min(batch_size, len(annotations)*repeat_times)\n",
    "        self._repeat_times = repeat_times\n",
    "        self.annotations = annotations\n",
    "        self.counter = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(len(self.annotations) * self._repeat_times /self._batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        # Args\n",
    "            idx : batch index\n",
    "        \"\"\"\n",
    "        x_batch = []\n",
    "        y_batch= []\n",
    "        for i in range(self._batch_size):\n",
    "            # 1. get input file & its annotation\n",
    "            fname = self.annotations.fname(self._batch_size*idx + i)\n",
    "            boxes = self.annotations.boxes(self._batch_size*idx + i)\n",
    "            labels = self.annotations.code_labels(self._batch_size*idx + i)\n",
    "            \n",
    "            # 2. read image in fixed size\n",
    "            img, boxes = self._img_aug.imread(fname, boxes)\n",
    "\n",
    "            # 3. grid scaling centroid boxes\n",
    "            norm_boxes = self._yolo_box.trans(boxes)\n",
    "            \n",
    "            # 4. generate x_batch\n",
    "            x_batch.append(self._netin_gen.run(img))\n",
    "            y_batch.append(self._netout_gen.run(norm_boxes, labels))\n",
    "\n",
    "        x_batch = np.array(x_batch)\n",
    "        y_batch = np.array(y_batch)\n",
    "        self.counter += 1\n",
    "        return x_batch, y_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.annotations.shuffle()\n",
    "        self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch_generator(annotations, \n",
    "                           input_size=416,\n",
    "                           grid_size=13,\n",
    "                           batch_size=8,\n",
    "                           anchors=[0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828],\n",
    "                           repeat_times=1,\n",
    "                           jitter=True, \n",
    "                           norm=None):\n",
    "    \"\"\"\n",
    "    # Args\n",
    "        annotations : Annotations instance in utils.annotataion module\n",
    "    \n",
    "    # Return \n",
    "        worker : BatchGenerator instance\n",
    "    \"\"\"\n",
    "\n",
    "    img_aug = ImgAugment(input_size, input_size, jitter)\n",
    "    yolo_box = _YoloBox(input_size, grid_size)\n",
    "    netin_gen = _NetinGen(input_size, norm)\n",
    "    netout_gen = _NetoutGen(grid_size, annotations.n_classes(), anchors)\n",
    "    worker = BatchGenerator(netin_gen,\n",
    "                            netout_gen,\n",
    "                            yolo_box,\n",
    "                            img_aug,\n",
    "                            annotations,\n",
    "                            batch_size,\n",
    "                            repeat_times)\n",
    "    return worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO(object): \n",
    "    def __init__(self,\n",
    "                 yolo_network,#yolo_network->一个完整的yolo网络类\n",
    "                 yolo_loss,#yolo_loss->损失函数类\n",
    "                 yolo_decoder,#yolo_decoder->yolo网络解码类\n",
    "                 labels,#labels->标签列表\n",
    "                 input_size = 416#input_size->输入图片size\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        # Args\n",
    "            feature_extractor : BaseFeatureExtractor instance\n",
    "        \"\"\"\n",
    "        self._yolo_network = yolo_network#一个完整的yolo网络类\n",
    "        self._yolo_loss = yolo_loss#损失函数类\n",
    "        self._yolo_decoder = yolo_decoder#yolo网络解码类\n",
    "        \n",
    "        self._labels = labels           #标签列表\n",
    "        # Batch를 생성할 때만 사용한다.\n",
    "        self._input_size = input_size   #输入图片size\n",
    "\n",
    "    def load_weights(self, weight_path, by_name=False):\n",
    "        if os.path.exists(weight_path):\n",
    "            print(\"Loading pre-trained weights in\", weight_path)\n",
    "            self._yolo_network.load_weights(weight_path, by_name=by_name)\n",
    "        else:\n",
    "            print(\"Fail to load pre-trained weights. Make sure weight file path.\")\n",
    "\n",
    "    def predict(self, image, threshold=0.3):\n",
    "        \"\"\"\n",
    "        # Args\n",
    "            image : 3d-array (BGR ordered)\n",
    "        \n",
    "        # Returns\n",
    "            boxes : array, shape of (N, 4)\n",
    "            probs : array, shape of (N, nb_classes)\n",
    "        \"\"\"\n",
    "        def _to_original_scale(boxes):\n",
    "            height, width = image.shape[:2]\n",
    "            minmax_boxes = to_minmax(boxes)\n",
    "            minmax_boxes[:,0] *= width\n",
    "            minmax_boxes[:,2] *= width\n",
    "            minmax_boxes[:,1] *= height\n",
    "            minmax_boxes[:,3] *= height\n",
    "            return minmax_boxes.astype(np.int)\n",
    "\n",
    "        netout = self._yolo_network.forward(image)\n",
    "        boxes, probs = self._yolo_decoder.run(netout, threshold)\n",
    "        \n",
    "        if len(boxes) > 0:\n",
    "            boxes = _to_original_scale(boxes)\n",
    "            return boxes, probs\n",
    "        else:\n",
    "            return [], []\n",
    "\n",
    "    def train(self,\n",
    "              img_folder,#图片对应的文件夹\n",
    "              ann_folder,#xml标签对应的文件夹\n",
    "              nb_epoch,#训练的epoch\n",
    "              saved_weights_name,#保存.h5文件权重的文件夹  config['train']['saved_folder']/weights.h5\n",
    "              batch_size=8,#每次训练喂入网络的batch\n",
    "              jitter=True,#训练的抖动=1？\n",
    "              learning_rate=1e-4, #学习率=0.0005\n",
    "              train_times=1,#训练次数=5？\n",
    "              valid_times=1,#有效次数=5?\n",
    "              valid_img_folder=\"\",#图片对应的文件夹\n",
    "              valid_ann_folder=\"\",#xml标签对应的文件夹\n",
    "              first_trainable_layer=None,#\"\"\n",
    "              is_only_detect=False,#为0,不只只是检测\n",
    "              class_num=1,#5x(4+1+分类数),即yolo网络最后输出的大小\n",
    "              anchors=[0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828],#锚框列表\n",
    "              w_name=\"\",#算法名字=mobilenet\n",
    "              alpha=0.75,#mobilenet的学习率\n",
    "              lable=\"\"#标签列表\n",
    "              ):\n",
    "\n",
    "        # 1. get annotations        \n",
    "        train_annotations, valid_annotations = get_train_annotations(self._labels,#标签列表\n",
    "                                                                     img_folder,#图片对应的文件夹\n",
    "                                                                     ann_folder,#xml标签对应的文件夹\n",
    "                                                                     valid_img_folder,#图片对应的文件夹\n",
    "                                                                     valid_ann_folder,#xml标签对应的文件夹\n",
    "                                                                     is_only_detect)#为0,不只只是检测\n",
    "        #返回两个Annotations对象,将annotation成员添加至_components成员的列表中,_label_namings[]成员存放的是标签列表\n",
    "         #Annotation类的labels成员和boxes成员,labels为一个xml文件中每一个锚框对应得label,boxes的维度是[n,4]\n",
    "        #两个Annotations对象对应的分别是train_anns,train_anns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # 1. get batch generator\n",
    "        train_batch_generator = self._get_batch_generator(train_annotations, batch_size, train_times, jitter=jitter)\n",
    "        #train_annsAnnotations对象,每次训练喂入网络的batch,\n",
    "        valid_batch_generator = self._get_batch_generator(valid_annotations, batch_size, valid_times, jitter=False)\n",
    "        \n",
    "        # 2. To train model get keras model instance & loss function\n",
    "        model = self._yolo_network.get_model(first_trainable_layer)\n",
    "        loss = self._get_loss_func(batch_size)\n",
    "        \n",
    "        # 3. Run training loop\n",
    "        train(model,\n",
    "                loss,\n",
    "                train_batch_generator,\n",
    "                valid_batch_generator,\n",
    "                learning_rate      = learning_rate, \n",
    "                nb_epoch           = nb_epoch,\n",
    "                saved_weights_name = saved_weights_name,\n",
    "                class_num=class_num,\n",
    "                anchors=anchors,\n",
    "                w_name=w_name,\n",
    "                alpha=alpha,\n",
    "                lable=lable\n",
    "                )\n",
    "\n",
    "    def _get_loss_func(self, batch_size):\n",
    "        return self._yolo_loss.custom_loss(batch_size)\n",
    "\n",
    "    def _get_batch_generator(self, annotations, batch_size, repeat_times=1, jitter=True):\n",
    "        \"\"\"\n",
    "        # Args\n",
    "            annotations : Annotations instance\n",
    "            batch_size : int\n",
    "            jitter : bool\n",
    "        \n",
    "        # Returns\n",
    "            batch_generator : BatchGenerator instance\n",
    "        \"\"\"\n",
    "        batch_generator = create_batch_generator(annotations,\n",
    "                                                 self._input_size,\n",
    "                                                 self._yolo_network.get_grid_size(),\n",
    "                                                 batch_size,\n",
    "                                                 self._yolo_loss.anchors,\n",
    "                                                 repeat_times,\n",
    "                                                 jitter=jitter,\n",
    "                                                 norm=self._yolo_network.get_normalize_func())\n",
    "        return batch_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fail to load pre-trained weights. Make sure weight file path.\n",
      "[[ 66  13 157 151]]\n",
      "[[ 62  33 158 167]]\n",
      "[[ 48  55 178 214]]\n",
      "[[ 47  25 178 202]]\n",
      "[[ 57  30 167 168]]\n",
      "[[ 51  20 171 173]]\n",
      "[[ 69   1 159 120]]\n",
      "[[ 57  61 163 177]]\n",
      "[[ 77  34 154 141]]\n",
      "[[ 57   1 167 144]]\n",
      "[[ 47  15 173 198]]\n",
      "[[ 63  16 159 161]]\n",
      "[[ 53  23 175 197]]\n",
      "[[ 55   1 168 143]]\n",
      "[[ 62   1 160 145]]\n",
      "[[ 48  20 171 189]]\n",
      "[[ 64   1 170 146]]\n",
      "[[  1   5  33  59]\n",
      " [144  27 224 182]]\n",
      "[[ 70   1 166 124]]\n",
      "[[ 60   1 168 147]]\n",
      "[[ 54   2 167 161]]\n",
      "[[ 62  37 163 179]]\n",
      "[[ 56  15 172 175]]\n",
      "[[ 82  29 138 110]]\n",
      "[[ 56   3 166 159]]\n",
      "[[ 65  38 155 165]]\n",
      "[[ 53  16 170 183]]\n",
      "[[ 57   1 170 156]]\n",
      "[[  1  64  79 212]\n",
      " [152  54 224 151]]\n",
      "[[ 61  66 166 182]]\n",
      "[[ 57  22 164 176]]\n",
      "[[ 68  38 156 159]]\n",
      "[[ 53  39 168 175]]\n",
      "[[ 69  37 149 147]]\n",
      "[[ 50  38 174 211]]\n",
      "[[ 45  16 178 202]]\n",
      "[[  1  33  97 187]\n",
      " [142  32 224 165]]\n",
      "[[ 55  49 171 201]]\n",
      "[[ 58   1 154 116]]\n",
      "[[ 46  35 177 219]]\n",
      "[[ 61  20 161 160]]\n",
      "[[ 72  34 152 141]]\n",
      "[[ 49  12 155 168]]\n",
      "[[ 54  24 160 162]]\n",
      "[[ 66  17 162 150]]\n",
      "[[ 55  15 169 168]]\n",
      "[[ 75   8 154 113]]\n",
      "[[ 57  16 166 158]]\n",
      "[[ 57  26 161 166]]\n",
      "[[ 60  35 165 178]]\n",
      "[[ 55  42 170 186]]\n",
      "[[ 52  33 180 206]]\n",
      "[[ 58  74 178 224]]\n",
      "[[ 57   1 167 158]]\n",
      "[[ 63  45 168 156]]\n",
      "[[ 65   5 154 124]]\n",
      "[[ 26  56  93 155]\n",
      " [109  53 183 138]]\n",
      "[[ 73  38 134 123]]\n",
      "[[ 44  29 179 206]]\n",
      "[[ 63  40 160 140]]\n",
      "[[ 57  20 171 183]]\n",
      "[[ 56   1 170 151]]\n",
      "[[ 69  58 163 172]]\n",
      "[[ 47  35 174 203]]\n",
      "[[ 62  40 164 164]]\n",
      "[[ 51  13 167 167]]\n",
      "[[ 60  11 166 149]]\n",
      "[[ 42  36 178 213]]\n",
      "[[ 49  17 178 197]]\n",
      "[[ 60  46 169 179]]\n",
      "[[ 57  28 167 143]]\n",
      "[[ 99   1 151  59]]\n",
      "[[ 59   1 166 139]]\n",
      "[[ 54   1 165 160]]\n",
      "[[ 40  33 207 224]]\n",
      "[[ 64  10 160 138]]\n",
      "[[ 32   3 176 210]]\n",
      "[[ 64  27 158 164]]\n",
      "[[ 56  32 166 183]]\n",
      "[[ 62   7 151 131]]\n",
      "[[ 64  36 158 147]]\n",
      "[[ 48  22 177 220]]\n",
      "[[ 61  38 166 174]]\n",
      "[[ 48  41 175 174]]\n",
      "[[ 47  24 171 207]]\n",
      "[[ 34  73 179 224]]\n",
      "[[ 52  17 173 168]]\n",
      "[[ 52  33 169 183]]\n",
      "[[ 62   9 166 141]]\n",
      "[[ 48  22 176 196]]\n",
      "[[ 49  39 179 196]]\n",
      "[[ 60   1 157 129]]\n",
      "[[ 63  37 158 141]]\n",
      "[[ 54  17 171 175]]\n",
      "[[ 77  29 175 162]]\n",
      "[[ 63  16 147 138]]\n",
      "[[ 50  47 169 172]]\n",
      "[[ 66  31 157 167]]\n",
      "[[ 70  17 159 152]]\n",
      "[[ 75  22 160 143]]\n",
      "[[ 81  26 157 137]]\n",
      "[[ 63  29 166 177]]\n",
      "[[ 69  23 154 140]]\n",
      "[[ 59  22 166 166]]\n",
      "[[ 53  34 172 204]]\n",
      "[[ 61  24 164 161]]\n",
      "[[ 53  13 164 166]]\n",
      "[[ 52   1 171 152]]\n",
      "[[ 51  31 180 203]]\n",
      "[[ 79   5 174 140]\n",
      " [148 136 200 218]]\n",
      "[[ 47  35 177 204]]\n",
      "[[ 63   1 169 138]]\n",
      "[[ 61   1 159 148]]\n",
      "[[ 57   6 159 152]]\n",
      "[[ 65  14 161 131]]\n",
      "[[ 47  15 206 224]]\n",
      "[[ 65  18 160 159]]\n",
      "[[ 69  35 153 145]]\n",
      "[[ 56   7 165 160]]\n",
      "[[ 44  29  99 116]\n",
      " [105  23 161 102]]\n",
      "[[ 48  25 177 202]]\n",
      "[[ 59  17 165 158]]\n",
      "[[ 55  24 170 186]]\n",
      "[[ 51  12 174 182]]\n",
      "[[ 56   1 161 144]]\n",
      "[[ 76  26 157 154]]\n",
      "[[ 55  14 167 160]]\n",
      "[[ 54  16 166 169]]\n",
      "[[ 64  27 167 176]]\n",
      "[[ 55   1 177 169]]\n",
      "[[ 61  22 162 171]]\n",
      "[[ 36  26 174 223]]\n",
      "[[ 78  32 134 112]]\n",
      "[[ 49  17 178 201]]\n",
      "[[ 54   5 169 161]]\n",
      "[[ 21   1 205 198]]\n",
      "[[ 73   1 168 121]]\n",
      "[[  1  47  62 148]\n",
      " [161  40 224 141]]\n",
      "[[ 69  45 143 143]]\n",
      "[[ 42  57 185 224]]\n",
      "[[ 49  34 165 197]]\n",
      "[[ 79  38 143 124]]\n",
      "[[ 49  17 172 199]]\n",
      "[[ 53   1 174 160]]\n",
      "[[ 78  29 143 123]]\n",
      "[[ 45  29 176 205]]\n",
      "[[ 56   1 169 156]]\n",
      "[[ 63  28 162 161]]\n",
      "[[ 58  17 163 167]]\n",
      "[[ 67  13 151 125]]\n",
      "[[ 66  17 161 143]]\n",
      "[[ 67  30 152 154]]\n",
      "[[ 67   1 160 113]]\n",
      "[[ 60  11 171 148]]\n",
      "[[ 83   1 138  69]]\n",
      "[[ 65  28 159 149]]\n",
      "[[ 60   1 166 152]]\n",
      "[[107   1 163  71]]\n",
      "[[ 63  35 162 168]]\n",
      "[[ 72  38 159 155]]\n",
      "[[ 43  51 171 224]]\n",
      "[[  1  31  97 221]\n",
      " [157  15 224 203]]\n",
      "[[ 49  55 174 221]]\n",
      "[[ 55  27 174 188]]\n",
      "[[ 51  44 176 217]]\n",
      "[[ 50  36 178 214]]\n",
      "[[ 47  27 173 204]]\n",
      "[[ 54  16 161 174]]\n",
      "[[ 43  10 192 217]]\n",
      "[[ 81  30 155 133]]\n",
      "[[ 76  50 148 156]]\n",
      "[[ 62   9 167 161]]\n",
      "[[ 66  56 157 184]]\n",
      "[[ 57   5 164 151]]\n",
      "[[ 53   1 171 177]]\n",
      "[[ 50  14 170 193]]\n",
      "[[ 64   8 158 140]]\n",
      "[[ 52   8 177 166]]\n",
      "[[ 59   2 176 159]]\n",
      "[[ 48   6 181 199]]\n",
      "[[ 19  65  77 148]\n",
      " [124  38 192 121]]\n",
      "[[ 62   1 165 151]]\n",
      "[[ 59  36 172 190]]\n",
      "[[ 76   8 152 113]]\n",
      "[[ 75  35 145 125]]\n",
      "[[ 50  10 180 191]]\n",
      "[[ 66  26 158 161]]\n",
      "[[ 69  20 174 159]]\n",
      "[[ 43   1 130 126]]\n",
      "[[ 87  47 143 117]]\n",
      "[[ 64  11 122  77]]\n",
      "[[124  69 169 128]]\n",
      "[[ 59   6 154 143]]\n",
      "[[ 35  44 109 152]]\n",
      "[[112   4 152  54]]\n",
      "[[ 84  64 163 177]]\n",
      "[[ 50   3 155 131]]\n",
      "[[ 73   1 126  57]]\n",
      "[[ 92  26 143 116]]\n",
      "[[ 67  50 120 140]\n",
      " [134  40 178 118]]\n",
      "[[129  47 158  82]]\n",
      "[[ 86  42 143 112]\n",
      " [  1  34  47 119]]\n",
      "[[ 92  68 166 143]]\n",
      "[[ 75  22 113  71]]\n",
      "[[ 81  19 167 121]]\n",
      "[[112  57 157 141]]\n",
      "[[116  54 178 134]]\n",
      "[[ 76  10 144 121]]\n",
      "[[ 19  29  55  73]\n",
      " [153  32 182  71]]\n",
      "[[ 39  16 128 151]]\n",
      "[[ 34   1 136  99]]\n",
      "[[ 71  45 130 117]]\n",
      "[[ 76  63 141 153]]\n",
      "[[127  23 159  70]]\n",
      "[[ 46   1 133 122]]\n",
      "[[ 68  35 161 154]]\n",
      "[[ 93  38 182 152]]\n",
      "[[ 19  43  60  96]\n",
      " [159  57 203 108]]\n",
      "[[126  80 194 164]]\n",
      "[[110  25 133  56]]\n",
      "[[ 58  45 169 190]]\n",
      "[[ 26   1 150 119]]\n",
      "[[ 73  46 154 168]]\n",
      "[[54  5 87 35]]\n",
      "[[ 60   1 152 115]]\n",
      "[[101  32 172 116]]\n",
      "[[102   1 152  57]]\n",
      "[[ 69  35 141 135]]\n",
      "[[ 61  25 156 137]]\n",
      "[[ 93   1 152  59]]\n",
      "[[ 80  66 175 160]]\n",
      "[[ 71  63 198 192]]\n",
      "[[109  58 185 163]]\n",
      "[[ 64  52 124 137]]\n",
      "[[  9  40  99 160]\n",
      " [159  46 224 155]]\n",
      "[[ 65  42 171 189]]\n",
      "[[ 64  48 159 173]]\n",
      "[[107  21 224 198]]\n",
      "[[ 85   1 170 119]]\n",
      "[[ 44   1 166 173]]\n",
      "[[107  56 138  97]]\n",
      "[[123  28 182 100]\n",
      " [ 36  63  83 130]]\n",
      "[[172  50 208 101]\n",
      " [  1  28  23  69]]\n",
      "[[ 93  63 142 135]]\n",
      "[[ 98   1 151  54]]\n",
      "[[ 63   1 161 136]]\n",
      "[[141  62 158  85]\n",
      " [ 58  79  75  96]\n",
      " [ 15  83  32 103]]\n",
      "[[110  19 153  77]]\n",
      "[[102   6 224 196]]\n",
      "[[113  94 162 154]]\n",
      "[[33 23 90 93]]\n",
      "[[ 99  38 172 124]]\n",
      "[[ 53 102 123 174]]\n",
      "[[109  39 196 154]]\n",
      "[[ 63  29 165 165]]\n",
      "[[ 76  31 151 144]]\n",
      "[[ 70   1 122  73]]\n",
      "[[ 55  34 128 128]]\n",
      "[[ 68   1 145  95]]\n",
      "[[ 85  11 145 108]]\n",
      "[[ 53  49 133 166]]\n",
      "[[123  12 148  44]\n",
      " [ 74  20  99  51]]\n",
      "[[170  10 224  84]\n",
      " [  2  19  63 104]]\n",
      "[[41 58 61 84]]\n",
      "[[173  36 224 138]]\n",
      "[[ 87  21 128  79]]\n",
      "[[161  48 193  79]]\n",
      "[[109  51 125  72]\n",
      " [ 22  49  41  72]\n",
      " [ 80  52  95  72]\n",
      " [153  57 166  76]]\n",
      "[[ 45  18 166 173]]\n",
      "[[ 51  33 134 149]]\n",
      "[[171  27 224 118]]\n",
      "[[ 88  21 121  71]]\n",
      "[[ 72  21 112  74]]\n",
      "[[ 34   1 145 150]]\n",
      "[[68 33 98 76]]\n",
      "[[110  40 130  69]\n",
      " [ 42  40  66  72]\n",
      " [161  42 181  69]]\n",
      "[[141  73 169 109]\n",
      " [173  48 207  89]]\n",
      "[[ 89  46 144 125]]\n",
      "[[ 78  32 131 107]]\n",
      "[[ 92  14 134  74]]\n",
      "[[137  29 188  76]]\n",
      "[[ 79   1 153  78]]\n",
      "[[ 76   1 125  41]]\n",
      "[[ 94  39 153 154]]\n",
      "[[ 94 117 188 224]]\n",
      "[[ 64  39 142 170]]\n",
      "[[ 61   1 130  72]]\n",
      "[[ 67   1 135  68]]\n",
      "[[119  69 153 111]]\n",
      "[[ 98  56 130 100]]\n",
      "[[ 61  43 133 156]]\n",
      "[[ 86  45 111  72]\n",
      " [136  20 165  54]\n",
      " [ 25  63  50  92]]\n",
      "[[119   1 145  47]\n",
      " [ 46   1 106  32]]\n",
      "[[15 10 34 36]]\n",
      "[[  1   1 158 174]]\n",
      "[[ 43  35 134 154]]\n",
      "[[152   6 199  60]]\n",
      "[[119  43 154  93]]\n",
      "[[ 85  31 162 137]]\n",
      "[[ 75   5 105  44]\n",
      " [142  33 173  68]\n",
      " [196  22 224  60]\n",
      " [ 11  29  42  66]]\n",
      "[[ 64  49 143 147]]\n",
      "[[ 40  55 108 144]]\n",
      "[[ 92   1 145  50]]\n",
      "[[103  27 145  89]]\n",
      "[[ 56  12 153 160]]\n",
      "[[ 86   1 131  34]]\n",
      "[[ 89  24 174 103]]\n",
      "[[ 25  11  94 100]]\n",
      "[[ 77  39 166 165]]\n",
      "[[ 45  41 123 152]]\n",
      "[[ 54  29 116 117]]\n",
      "[[ 30   1 189 221]]\n",
      "[[130  21 216 145]]\n",
      "[[113  57 143  95]]\n",
      "[[ 71   6 131 111]]\n",
      "[[ 66   9 149 131]]\n",
      "[[  1   1 114 218]]\n",
      "[[  8  39  54 105]\n",
      " [160  75 207 147]]\n",
      "[[ 63   1 129  53]]\n",
      "[[47 44 80 90]]\n",
      "[[101  45 127  75]]\n",
      "[[102  62 129  92]]\n",
      "[[ 51  79  88 122]]\n",
      "[[ 82  30 140 126]]\n",
      "[[100  36 166 125]]\n",
      "[[103   1 134  30]\n",
      " [ 50   1  91  29]]\n",
      "[[ 59   1 151 127]]\n",
      "[[ 26  20 133 154]]\n",
      "[[ 52   5 180 177]]\n",
      "[[ 56  21 155 167]]\n",
      "[[ 86   8 138  77]]\n",
      "[[ 57   1 127  71]]\n",
      "[[ 86   1 168  80]]\n",
      "[[ 78  41 147 152]]\n",
      "[[ 57   1 135  81]]\n",
      "[[ 66   2 161 133]]\n",
      "[[ 84   1 143  60]]\n",
      "[[ 85   1 141  61]]\n",
      "[[ 30  44 105 150]]\n",
      "[[ 68  28 170 154]]\n",
      "[[121  80 137 102]\n",
      " [181  77 195  95]]\n",
      "[[162  11 224  90]]\n",
      "[[ 82  11 173 129]]\n",
      "[[ 70  54 173 153]]\n",
      "[[ 71  30  91  61]\n",
      " [137  18 160  49]]\n",
      "[[ 75   1 151 101]]\n",
      "[[ 85   2 132  54]]\n",
      "[[ 93  76 134 126]]\n",
      "[[ 18  32  56  85]\n",
      " [ 70  28 101  76]]\n",
      "[[ 43  41 136 142]]\n",
      "[[ 86  81 109 111]\n",
      " [  1   2  26  42]]\n",
      "[[ 31  31 104  98]]\n",
      "[[ 87   1 144  51]]\n",
      "[[ 67   1 168  65]]\n",
      "[[128  46 175 108]]\n",
      "[[ 95  38 178 138]]\n",
      "[[ 57  96 149 176]]\n",
      "[[ 66 100 141 183]]\n",
      "[[ 91  10 129  58]]\n",
      "[[ 36  88  87 169]\n",
      " [ 91 106 141 174]\n",
      " [164 119 204 177]\n",
      " [  8   1  44  38]]\n",
      "[[ 58  40 169 167]]\n",
      "[[ 81  26 170 149]]\n",
      "[[136  31 176  91]]\n",
      "[[ 60   1 190 156]]\n",
      "[[ 87   1 158  71]]\n",
      "[[ 52   1 163 130]]\n",
      "[[ 30  60 177 204]]\n",
      "[[ 52  44 177 212]]\n",
      "[[ 62   1 121  64]]\n",
      "[[ 39  86 175 215]]\n",
      "[[ 54  21 181 204]]\n",
      "[[ 63   1 142 103]]\n",
      "[[ 95   9 147  78]]\n",
      "[[ 81   1 141  49]]\n",
      "[[ 66   1 134  65]]\n",
      "[[ 37  26  56  58]\n",
      " [ 86  43 109  70]]\n",
      "[[  1  43  85 196]\n",
      " [116  84 224 224]]\n",
      "[[ 25   4 204 196]]\n",
      "[[  1  60 132 217]]\n",
      "[[ 75  50 118 100]]\n",
      "[[ 65  37 176 193]]\n",
      "[[ 89  13 140  83]]\n",
      "[[ 90   1 160  72]]\n",
      "[[ 56  34 161 179]]\n",
      "[[ 88   1 149  69]]\n",
      "[[ 71  59 179 192]]\n",
      "[[ 68  36 170 169]]\n",
      "[[ 90   1 121  26]]\n",
      "[[ 68  68 115 119]]\n",
      "[[116  27 224 152]]\n",
      "[[ 81  28 150 126]]\n",
      "[[ 24   1 208 129]]\n",
      "[[ 93  50 120  86]]\n",
      "[[ 79   1 109  13]]\n",
      "[[ 74  41 153 118]]\n",
      "[[ 97  42 148 107]]\n",
      "[[ 32  55 130 173]]\n",
      "[[ 66   1 107  43]]\n",
      "[[56 62 82 95]\n",
      " [ 4 63 29 92]]\n",
      "[[ 69  39 168 169]]\n",
      "[[ 86  10 166 121]]\n",
      "[[ 81  24 171 151]]\n",
      "[[ 89  75 121 116]\n",
      " [  1  71  31 108]\n",
      " [121  45 147  82]]\n",
      "[[ 96  29 178 145]]\n",
      "[[119   7 175  61]]\n",
      "[[ 59  61 167 168]]\n",
      "[[ 60   1 146 123]]\n",
      "[[106  48 162 101]\n",
      " [ 50  64  94 118]]\n",
      "[[ 24  32 192 193]]\n",
      "[[ 15  26 144 125]]\n",
      "[[ 82  46 178 181]]\n",
      "[[ 74   1 140  56]]\n",
      "[[ 87  85 108 111]\n",
      " [  1   7  26  43]]\n",
      "[[ 85  18 139  84]]\n",
      "[[ 53  44 182 212]]\n",
      "[[ 11   3 194 222]]\n",
      "[[110  30 133  62]]\n",
      "[[ 74   1 100  29]\n",
      " [144  10 169  38]\n",
      " [ 30   5  52  30]]\n",
      "[[ 60  44 165 173]]\n",
      "[[ 52  79 175 216]]\n",
      "[[110  59 158 114]]\n",
      "[[165  39 213 100]]\n",
      "[[104  50 166 115]\n",
      " [ 25  69  79 109]]\n",
      "[[ 93  21 176 134]]\n",
      "[[ 62  61 102 114]\n",
      " [166  83 198 126]]\n",
      "[[ 64  67 143 142]]\n",
      "[[ 37   1 164 118]]\n",
      "[[ 96  32 153 113]]\n",
      "[[ 78  54 160 157]]\n",
      "[[ 56  79  82 110]]\n",
      "[[138  53 177 106]]\n",
      "[[ 84 106 107 135]\n",
      " [ 27  74  50 110]\n",
      " [  1  68  22 103]]\n",
      "[[  2   1 211 127]]\n",
      "[[ 81  71 149 152]\n",
      " [157  30 203  87]]\n",
      "[[ 73  23 142 128]]\n",
      "[[ 19  55 100 163]]\n",
      "[[ 99  13 184 132]]\n",
      "[[  8  44 109 150]\n",
      " [169  35 210  77]]\n",
      "[[ 61  25 144 151]]\n",
      "[[ 81  17 178 130]]\n",
      "[[ 46  27 134 141]]\n",
      "[[ 75   1 146  78]]\n",
      "[[ 73   5 168 141]]\n",
      "[[ 63   1 140  65]]\n",
      "[[ 75  39 142 127]]\n",
      "[[ 71   5 166 141]]\n",
      "[[  1  30 170 224]]\n",
      "[[ 36  47 139 184]]\n",
      "[[119  25 171  82]\n",
      " [ 84 128 108 166]]\n",
      "[[  1  55 117 217]]\n",
      "[[ 58   1 224 153]]\n",
      "[[ 94  75 134 128]]\n",
      "[[ 45   1 173 163]]\n",
      "[[ 68   3 185 156]]\n",
      "[[ 56  17 224 223]]\n",
      "[[ 61   1 193 153]]\n",
      "[[108  31 164 113]\n",
      " [ 24  71  78 112]]\n",
      "[[ 25  71 102 159]]\n",
      "[[  9  85  88 192]]\n",
      "[[ 41  35  68  72]\n",
      " [132   5 167  44]]\n",
      "[[127 104 180 179]]\n",
      "[[121  48 193 134]]\n",
      "[[ 33  83  89 179]]\n",
      "[[ 66  13 157 151]]\n",
      "[[ 62  33 158 167]]\n",
      "[[ 48  55 178 214]]\n",
      "[[ 47  25 178 202]]\n",
      "[[ 57  30 167 168]]\n",
      "[[ 51  20 171 173]]\n",
      "[[ 69   1 159 120]]\n",
      "[[ 57  61 163 177]]\n",
      "[[ 77  34 154 141]]\n",
      "[[ 57   1 167 144]]\n",
      "[[ 47  15 173 198]]\n",
      "[[ 63  16 159 161]]\n",
      "[[ 53  23 175 197]]\n",
      "[[ 55   1 168 143]]\n",
      "[[ 62   1 160 145]]\n",
      "[[ 48  20 171 189]]\n",
      "[[ 64   1 170 146]]\n",
      "[[  1   5  33  59]\n",
      " [144  27 224 182]]\n",
      "[[ 70   1 166 124]]\n",
      "[[ 60   1 168 147]]\n",
      "[[ 54   2 167 161]]\n",
      "[[ 62  37 163 179]]\n",
      "[[ 56  15 172 175]]\n",
      "[[ 82  29 138 110]]\n",
      "[[ 56   3 166 159]]\n",
      "[[ 65  38 155 165]]\n",
      "[[ 53  16 170 183]]\n",
      "[[ 57   1 170 156]]\n",
      "[[  1  64  79 212]\n",
      " [152  54 224 151]]\n",
      "[[ 61  66 166 182]]\n",
      "[[ 57  22 164 176]]\n",
      "[[ 68  38 156 159]]\n",
      "[[ 53  39 168 175]]\n",
      "[[ 69  37 149 147]]\n",
      "[[ 50  38 174 211]]\n",
      "[[ 45  16 178 202]]\n",
      "[[  1  33  97 187]\n",
      " [142  32 224 165]]\n",
      "[[ 55  49 171 201]]\n",
      "[[ 58   1 154 116]]\n",
      "[[ 46  35 177 219]]\n",
      "[[ 61  20 161 160]]\n",
      "[[ 72  34 152 141]]\n",
      "[[ 49  12 155 168]]\n",
      "[[ 54  24 160 162]]\n",
      "[[ 66  17 162 150]]\n",
      "[[ 55  15 169 168]]\n",
      "[[ 75   8 154 113]]\n",
      "[[ 57  16 166 158]]\n",
      "[[ 57  26 161 166]]\n",
      "[[ 60  35 165 178]]\n",
      "[[ 55  42 170 186]]\n",
      "[[ 52  33 180 206]]\n",
      "[[ 58  74 178 224]]\n",
      "[[ 57   1 167 158]]\n",
      "[[ 63  45 168 156]]\n",
      "[[ 65   5 154 124]]\n",
      "[[ 26  56  93 155]\n",
      " [109  53 183 138]]\n",
      "[[ 73  38 134 123]]\n",
      "[[ 44  29 179 206]]\n",
      "[[ 63  40 160 140]]\n",
      "[[ 57  20 171 183]]\n",
      "[[ 56   1 170 151]]\n",
      "[[ 69  58 163 172]]\n",
      "[[ 47  35 174 203]]\n",
      "[[ 62  40 164 164]]\n",
      "[[ 51  13 167 167]]\n",
      "[[ 60  11 166 149]]\n",
      "[[ 42  36 178 213]]\n",
      "[[ 49  17 178 197]]\n",
      "[[ 60  46 169 179]]\n",
      "[[ 57  28 167 143]]\n",
      "[[ 99   1 151  59]]\n",
      "[[ 59   1 166 139]]\n",
      "[[ 54   1 165 160]]\n",
      "[[ 40  33 207 224]]\n",
      "[[ 64  10 160 138]]\n",
      "[[ 32   3 176 210]]\n",
      "[[ 64  27 158 164]]\n",
      "[[ 56  32 166 183]]\n",
      "[[ 62   7 151 131]]\n",
      "[[ 64  36 158 147]]\n",
      "[[ 48  22 177 220]]\n",
      "[[ 61  38 166 174]]\n",
      "[[ 48  41 175 174]]\n",
      "[[ 47  24 171 207]]\n",
      "[[ 34  73 179 224]]\n",
      "[[ 52  17 173 168]]\n",
      "[[ 52  33 169 183]]\n",
      "[[ 62   9 166 141]]\n",
      "[[ 48  22 176 196]]\n",
      "[[ 49  39 179 196]]\n",
      "[[ 60   1 157 129]]\n",
      "[[ 63  37 158 141]]\n",
      "[[ 54  17 171 175]]\n",
      "[[ 77  29 175 162]]\n",
      "[[ 63  16 147 138]]\n",
      "[[ 50  47 169 172]]\n",
      "[[ 66  31 157 167]]\n",
      "[[ 70  17 159 152]]\n",
      "[[ 75  22 160 143]]\n",
      "[[ 81  26 157 137]]\n",
      "[[ 63  29 166 177]]\n",
      "[[ 69  23 154 140]]\n",
      "[[ 59  22 166 166]]\n",
      "[[ 53  34 172 204]]\n",
      "[[ 61  24 164 161]]\n",
      "[[ 53  13 164 166]]\n",
      "[[ 52   1 171 152]]\n",
      "[[ 51  31 180 203]]\n",
      "[[ 79   5 174 140]\n",
      " [148 136 200 218]]\n",
      "[[ 47  35 177 204]]\n",
      "[[ 63   1 169 138]]\n",
      "[[ 61   1 159 148]]\n",
      "[[ 57   6 159 152]]\n",
      "[[ 65  14 161 131]]\n",
      "[[ 47  15 206 224]]\n",
      "[[ 65  18 160 159]]\n",
      "[[ 69  35 153 145]]\n",
      "[[ 56   7 165 160]]\n",
      "[[ 44  29  99 116]\n",
      " [105  23 161 102]]\n",
      "[[ 48  25 177 202]]\n",
      "[[ 59  17 165 158]]\n",
      "[[ 55  24 170 186]]\n",
      "[[ 51  12 174 182]]\n",
      "[[ 56   1 161 144]]\n",
      "[[ 76  26 157 154]]\n",
      "[[ 55  14 167 160]]\n",
      "[[ 54  16 166 169]]\n",
      "[[ 64  27 167 176]]\n",
      "[[ 55   1 177 169]]\n",
      "[[ 61  22 162 171]]\n",
      "[[ 36  26 174 223]]\n",
      "[[ 78  32 134 112]]\n",
      "[[ 49  17 178 201]]\n",
      "[[ 54   5 169 161]]\n",
      "[[ 21   1 205 198]]\n",
      "[[ 73   1 168 121]]\n",
      "[[  1  47  62 148]\n",
      " [161  40 224 141]]\n",
      "[[ 69  45 143 143]]\n",
      "[[ 42  57 185 224]]\n",
      "[[ 49  34 165 197]]\n",
      "[[ 79  38 143 124]]\n",
      "[[ 49  17 172 199]]\n",
      "[[ 53   1 174 160]]\n",
      "[[ 78  29 143 123]]\n",
      "[[ 45  29 176 205]]\n",
      "[[ 56   1 169 156]]\n",
      "[[ 63  28 162 161]]\n",
      "[[ 58  17 163 167]]\n",
      "[[ 67  13 151 125]]\n",
      "[[ 66  17 161 143]]\n",
      "[[ 67  30 152 154]]\n",
      "[[ 67   1 160 113]]\n",
      "[[ 60  11 171 148]]\n",
      "[[ 83   1 138  69]]\n",
      "[[ 65  28 159 149]]\n",
      "[[ 60   1 166 152]]\n",
      "[[107   1 163  71]]\n",
      "[[ 63  35 162 168]]\n",
      "[[ 72  38 159 155]]\n",
      "[[ 43  51 171 224]]\n",
      "[[  1  31  97 221]\n",
      " [157  15 224 203]]\n",
      "[[ 49  55 174 221]]\n",
      "[[ 55  27 174 188]]\n",
      "[[ 51  44 176 217]]\n",
      "[[ 50  36 178 214]]\n",
      "[[ 47  27 173 204]]\n",
      "[[ 54  16 161 174]]\n",
      "[[ 43  10 192 217]]\n",
      "[[ 81  30 155 133]]\n",
      "[[ 76  50 148 156]]\n",
      "[[ 62   9 167 161]]\n",
      "[[ 66  56 157 184]]\n",
      "[[ 57   5 164 151]]\n",
      "[[ 53   1 171 177]]\n",
      "[[ 50  14 170 193]]\n",
      "[[ 64   8 158 140]]\n",
      "[[ 52   8 177 166]]\n",
      "[[ 59   2 176 159]]\n",
      "[[ 48   6 181 199]]\n",
      "[[ 19  65  77 148]\n",
      " [124  38 192 121]]\n",
      "[[ 62   1 165 151]]\n",
      "[[ 59  36 172 190]]\n",
      "[[ 76   8 152 113]]\n",
      "[[ 75  35 145 125]]\n",
      "[[ 50  10 180 191]]\n",
      "[[ 66  26 158 161]]\n",
      "[[ 69  20 174 159]]\n",
      "[[ 43   1 130 126]]\n",
      "[[ 87  47 143 117]]\n",
      "[[ 64  11 122  77]]\n",
      "[[124  69 169 128]]\n",
      "[[ 59   6 154 143]]\n",
      "[[ 35  44 109 152]]\n",
      "[[112   4 152  54]]\n",
      "[[ 84  64 163 177]]\n",
      "[[ 50   3 155 131]]\n",
      "[[ 73   1 126  57]]\n",
      "[[ 92  26 143 116]]\n",
      "[[ 67  50 120 140]\n",
      " [134  40 178 118]]\n",
      "[[129  47 158  82]]\n",
      "[[ 86  42 143 112]\n",
      " [  1  34  47 119]]\n",
      "[[ 92  68 166 143]]\n",
      "[[ 75  22 113  71]]\n",
      "[[ 81  19 167 121]]\n",
      "[[112  57 157 141]]\n",
      "[[116  54 178 134]]\n",
      "[[ 76  10 144 121]]\n",
      "[[ 19  29  55  73]\n",
      " [153  32 182  71]]\n",
      "[[ 39  16 128 151]]\n",
      "[[ 34   1 136  99]]\n",
      "[[ 71  45 130 117]]\n",
      "[[ 76  63 141 153]]\n",
      "[[127  23 159  70]]\n",
      "[[ 46   1 133 122]]\n",
      "[[ 68  35 161 154]]\n",
      "[[ 93  38 182 152]]\n",
      "[[ 19  43  60  96]\n",
      " [159  57 203 108]]\n",
      "[[126  80 194 164]]\n",
      "[[110  25 133  56]]\n",
      "[[ 58  45 169 190]]\n",
      "[[ 26   1 150 119]]\n",
      "[[ 73  46 154 168]]\n",
      "[[54  5 87 35]]\n",
      "[[ 60   1 152 115]]\n",
      "[[101  32 172 116]]\n",
      "[[102   1 152  57]]\n",
      "[[ 69  35 141 135]]\n",
      "[[ 61  25 156 137]]\n",
      "[[ 93   1 152  59]]\n",
      "[[ 80  66 175 160]]\n",
      "[[ 71  63 198 192]]\n",
      "[[109  58 185 163]]\n",
      "[[ 64  52 124 137]]\n",
      "[[  9  40  99 160]\n",
      " [159  46 224 155]]\n",
      "[[ 65  42 171 189]]\n",
      "[[ 64  48 159 173]]\n",
      "[[107  21 224 198]]\n",
      "[[ 85   1 170 119]]\n",
      "[[ 44   1 166 173]]\n",
      "[[107  56 138  97]]\n",
      "[[123  28 182 100]\n",
      " [ 36  63  83 130]]\n",
      "[[172  50 208 101]\n",
      " [  1  28  23  69]]\n",
      "[[ 93  63 142 135]]\n",
      "[[ 98   1 151  54]]\n",
      "[[ 63   1 161 136]]\n",
      "[[141  62 158  85]\n",
      " [ 58  79  75  96]\n",
      " [ 15  83  32 103]]\n",
      "[[110  19 153  77]]\n",
      "[[102   6 224 196]]\n",
      "[[113  94 162 154]]\n",
      "[[33 23 90 93]]\n",
      "[[ 99  38 172 124]]\n",
      "[[ 53 102 123 174]]\n",
      "[[109  39 196 154]]\n",
      "[[ 63  29 165 165]]\n",
      "[[ 76  31 151 144]]\n",
      "[[ 70   1 122  73]]\n",
      "[[ 55  34 128 128]]\n",
      "[[ 68   1 145  95]]\n",
      "[[ 85  11 145 108]]\n",
      "[[ 53  49 133 166]]\n",
      "[[123  12 148  44]\n",
      " [ 74  20  99  51]]\n",
      "[[170  10 224  84]\n",
      " [  2  19  63 104]]\n",
      "[[41 58 61 84]]\n",
      "[[173  36 224 138]]\n",
      "[[ 87  21 128  79]]\n",
      "[[161  48 193  79]]\n",
      "[[109  51 125  72]\n",
      " [ 22  49  41  72]\n",
      " [ 80  52  95  72]\n",
      " [153  57 166  76]]\n",
      "[[ 45  18 166 173]]\n",
      "[[ 51  33 134 149]]\n",
      "[[171  27 224 118]]\n",
      "[[ 88  21 121  71]]\n",
      "[[ 72  21 112  74]]\n",
      "[[ 34   1 145 150]]\n",
      "[[68 33 98 76]]\n",
      "[[110  40 130  69]\n",
      " [ 42  40  66  72]\n",
      " [161  42 181  69]]\n",
      "[[141  73 169 109]\n",
      " [173  48 207  89]]\n",
      "[[ 89  46 144 125]]\n",
      "[[ 78  32 131 107]]\n",
      "[[ 92  14 134  74]]\n",
      "[[137  29 188  76]]\n",
      "[[ 79   1 153  78]]\n",
      "[[ 76   1 125  41]]\n",
      "[[ 94  39 153 154]]\n",
      "[[ 94 117 188 224]]\n",
      "[[ 64  39 142 170]]\n",
      "[[ 61   1 130  72]]\n",
      "[[ 67   1 135  68]]\n",
      "[[119  69 153 111]]\n",
      "[[ 98  56 130 100]]\n",
      "[[ 61  43 133 156]]\n",
      "[[ 86  45 111  72]\n",
      " [136  20 165  54]\n",
      " [ 25  63  50  92]]\n",
      "[[119   1 145  47]\n",
      " [ 46   1 106  32]]\n",
      "[[15 10 34 36]]\n",
      "[[  1   1 158 174]]\n",
      "[[ 43  35 134 154]]\n",
      "[[152   6 199  60]]\n",
      "[[119  43 154  93]]\n",
      "[[ 85  31 162 137]]\n",
      "[[ 75   5 105  44]\n",
      " [142  33 173  68]\n",
      " [196  22 224  60]\n",
      " [ 11  29  42  66]]\n",
      "[[ 64  49 143 147]]\n",
      "[[ 40  55 108 144]]\n",
      "[[ 92   1 145  50]]\n",
      "[[103  27 145  89]]\n",
      "[[ 56  12 153 160]]\n",
      "[[ 86   1 131  34]]\n",
      "[[ 89  24 174 103]]\n",
      "[[ 25  11  94 100]]\n",
      "[[ 77  39 166 165]]\n",
      "[[ 45  41 123 152]]\n",
      "[[ 54  29 116 117]]\n",
      "[[ 30   1 189 221]]\n",
      "[[130  21 216 145]]\n",
      "[[113  57 143  95]]\n",
      "[[ 71   6 131 111]]\n",
      "[[ 66   9 149 131]]\n",
      "[[  1   1 114 218]]\n",
      "[[  8  39  54 105]\n",
      " [160  75 207 147]]\n",
      "[[ 63   1 129  53]]\n",
      "[[47 44 80 90]]\n",
      "[[101  45 127  75]]\n",
      "[[102  62 129  92]]\n",
      "[[ 51  79  88 122]]\n",
      "[[ 82  30 140 126]]\n",
      "[[100  36 166 125]]\n",
      "[[103   1 134  30]\n",
      " [ 50   1  91  29]]\n",
      "[[ 59   1 151 127]]\n",
      "[[ 26  20 133 154]]\n",
      "[[ 52   5 180 177]]\n",
      "[[ 56  21 155 167]]\n",
      "[[ 86   8 138  77]]\n",
      "[[ 57   1 127  71]]\n",
      "[[ 86   1 168  80]]\n",
      "[[ 78  41 147 152]]\n",
      "[[ 57   1 135  81]]\n",
      "[[ 66   2 161 133]]\n",
      "[[ 84   1 143  60]]\n",
      "[[ 85   1 141  61]]\n",
      "[[ 30  44 105 150]]\n",
      "[[ 68  28 170 154]]\n",
      "[[121  80 137 102]\n",
      " [181  77 195  95]]\n",
      "[[162  11 224  90]]\n",
      "[[ 82  11 173 129]]\n",
      "[[ 70  54 173 153]]\n",
      "[[ 71  30  91  61]\n",
      " [137  18 160  49]]\n",
      "[[ 75   1 151 101]]\n",
      "[[ 85   2 132  54]]\n",
      "[[ 93  76 134 126]]\n",
      "[[ 18  32  56  85]\n",
      " [ 70  28 101  76]]\n",
      "[[ 43  41 136 142]]\n",
      "[[ 86  81 109 111]\n",
      " [  1   2  26  42]]\n",
      "[[ 31  31 104  98]]\n",
      "[[ 87   1 144  51]]\n",
      "[[ 67   1 168  65]]\n",
      "[[128  46 175 108]]\n",
      "[[ 95  38 178 138]]\n",
      "[[ 57  96 149 176]]\n",
      "[[ 66 100 141 183]]\n",
      "[[ 91  10 129  58]]\n",
      "[[ 36  88  87 169]\n",
      " [ 91 106 141 174]\n",
      " [164 119 204 177]\n",
      " [  8   1  44  38]]\n",
      "[[ 58  40 169 167]]\n",
      "[[ 81  26 170 149]]\n",
      "[[136  31 176  91]]\n",
      "[[ 60   1 190 156]]\n",
      "[[ 87   1 158  71]]\n",
      "[[ 52   1 163 130]]\n",
      "[[ 30  60 177 204]]\n",
      "[[ 52  44 177 212]]\n",
      "[[ 62   1 121  64]]\n",
      "[[ 39  86 175 215]]\n",
      "[[ 54  21 181 204]]\n",
      "[[ 63   1 142 103]]\n",
      "[[ 95   9 147  78]]\n",
      "[[ 81   1 141  49]]\n",
      "[[ 66   1 134  65]]\n",
      "[[ 37  26  56  58]\n",
      " [ 86  43 109  70]]\n",
      "[[  1  43  85 196]\n",
      " [116  84 224 224]]\n",
      "[[ 25   4 204 196]]\n",
      "[[  1  60 132 217]]\n",
      "[[ 75  50 118 100]]\n",
      "[[ 65  37 176 193]]\n",
      "[[ 89  13 140  83]]\n",
      "[[ 90   1 160  72]]\n",
      "[[ 56  34 161 179]]\n",
      "[[ 88   1 149  69]]\n",
      "[[ 71  59 179 192]]\n",
      "[[ 68  36 170 169]]\n",
      "[[ 90   1 121  26]]\n",
      "[[ 68  68 115 119]]\n",
      "[[116  27 224 152]]\n",
      "[[ 81  28 150 126]]\n",
      "[[ 24   1 208 129]]\n",
      "[[ 93  50 120  86]]\n",
      "[[ 79   1 109  13]]\n",
      "[[ 74  41 153 118]]\n",
      "[[ 97  42 148 107]]\n",
      "[[ 32  55 130 173]]\n",
      "[[ 66   1 107  43]]\n",
      "[[56 62 82 95]\n",
      " [ 4 63 29 92]]\n",
      "[[ 69  39 168 169]]\n",
      "[[ 86  10 166 121]]\n",
      "[[ 81  24 171 151]]\n",
      "[[ 89  75 121 116]\n",
      " [  1  71  31 108]\n",
      " [121  45 147  82]]\n",
      "[[ 96  29 178 145]]\n",
      "[[119   7 175  61]]\n",
      "[[ 59  61 167 168]]\n",
      "[[ 60   1 146 123]]\n",
      "[[106  48 162 101]\n",
      " [ 50  64  94 118]]\n",
      "[[ 24  32 192 193]]\n",
      "[[ 15  26 144 125]]\n",
      "[[ 82  46 178 181]]\n",
      "[[ 74   1 140  56]]\n",
      "[[ 87  85 108 111]\n",
      " [  1   7  26  43]]\n",
      "[[ 85  18 139  84]]\n",
      "[[ 53  44 182 212]]\n",
      "[[ 11   3 194 222]]\n",
      "[[110  30 133  62]]\n",
      "[[ 74   1 100  29]\n",
      " [144  10 169  38]\n",
      " [ 30   5  52  30]]\n",
      "[[ 60  44 165 173]]\n",
      "[[ 52  79 175 216]]\n",
      "[[110  59 158 114]]\n",
      "[[165  39 213 100]]\n",
      "[[104  50 166 115]\n",
      " [ 25  69  79 109]]\n",
      "[[ 93  21 176 134]]\n",
      "[[ 62  61 102 114]\n",
      " [166  83 198 126]]\n",
      "[[ 64  67 143 142]]\n",
      "[[ 37   1 164 118]]\n",
      "[[ 96  32 153 113]]\n",
      "[[ 78  54 160 157]]\n",
      "[[ 56  79  82 110]]\n",
      "[[138  53 177 106]]\n",
      "[[ 84 106 107 135]\n",
      " [ 27  74  50 110]\n",
      " [  1  68  22 103]]\n",
      "[[  2   1 211 127]]\n",
      "[[ 81  71 149 152]\n",
      " [157  30 203  87]]\n",
      "[[ 73  23 142 128]]\n",
      "[[ 19  55 100 163]]\n",
      "[[ 99  13 184 132]]\n",
      "[[  8  44 109 150]\n",
      " [169  35 210  77]]\n",
      "[[ 61  25 144 151]]\n",
      "[[ 81  17 178 130]]\n",
      "[[ 46  27 134 141]]\n",
      "[[ 75   1 146  78]]\n",
      "[[ 73   5 168 141]]\n",
      "[[ 63   1 140  65]]\n",
      "[[ 75  39 142 127]]\n",
      "[[ 71   5 166 141]]\n",
      "[[  1  30 170 224]]\n",
      "[[ 36  47 139 184]]\n",
      "[[119  25 171  82]\n",
      " [ 84 128 108 166]]\n",
      "[[  1  55 117 217]]\n",
      "[[ 58   1 224 153]]\n",
      "[[ 94  75 134 128]]\n",
      "[[ 45   1 173 163]]\n",
      "[[ 68   3 185 156]]\n",
      "[[ 56  17 224 223]]\n",
      "[[ 61   1 193 153]]\n",
      "[[108  31 164 113]\n",
      " [ 24  71  78 112]]\n",
      "[[ 25  71 102 159]]\n",
      "[[  9  85  88 192]]\n",
      "[[ 41  35  68  72]\n",
      " [132   5 167  44]]\n",
      "[[127 104 180 179]]\n",
      "[[121  48 193 134]]\n",
      "[[ 33  83  89 179]]\n",
      "WARNING:tensorflow:From C:\\Users\\WLX\\AppData\\Local\\Temp\\ipykernel_10192\\230536034.py:163: Model.fit_generator (from tensorflow.python.keras.engine.training_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\WLX\\AppData\\Local\\Temp\\ipykernel_10192\\230536034.py:163: Model.fit_generator (from tensorflow.python.keras.engine.training_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "289/289 [==============================] - 68s 234ms/step - batch: 144.0000 - size: 8.0000 - loss: 0.9291 - val_loss: 0.8632\n",
      "Epoch 2/2\n",
      "289/289 [==============================] - 68s 234ms/step - batch: 144.0000 - size: 8.0000 - loss: 0.8894 - val_loss: 0.8444\n",
      "{'loss': [0.9290585476634412, 0.8893606458568243], 'val_loss': [0.8632382317397834, 0.8443907025982352], 'lr': [0.0005, 0.0005]}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-mins to train\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\WLX\\AppData\\Local\\Temp\\tmpl6ea0898\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\WLX\\AppData\\Local\\Temp\\tmpl6ea0898\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\WLX\\AppData\\Local\\Temp\\tmpl6ea0898\\variables\\variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\WLX\\AppData\\Local\\Temp\\tmpl6ea0898\\variables\\variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default', '__saved_model_init_op'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default', '__saved_model_init_op'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input tensors info: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input tensors info: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: input_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: input_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: serving_default_input_2:0, shape: (-1, 224, 224, 3), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: serving_default_input_2:0, shape: (-1, 224, 224, 3), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:output tensors info: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:output tensors info: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: reshape_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: reshape_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: StatefulPartitionedCall:0, shape: (-1, 7, 7, 5, 7), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: StatefulPartitionedCall:0, shape: (-1, 7, 7, 5, 7), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\WLX\\AppData\\Local\\Temp\\tmpl6ea0898\\variables\\variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\WLX\\AppData\\Local\\Temp\\tmpl6ea0898\\variables\\variables\n"
     ]
    }
   ],
   "source": [
    "yolo = YOLO(yolo_net, yolo_loss, yolo_decoder, labels, input_size)#传入yolo_network->一个完整的yolo网络类 yolo_loss->损失函数类 yolo_decoder->yolo网络解码类 labels->标签列表 input_size->输入图片size\n",
    "   # 2. Load the pretrained weights (if any) \n",
    "if alpha==1.0:\n",
    "        weights='mobilenet_1_0_224_tf_no_top.h5'\n",
    "elif alpha==0.75:\n",
    "        weights='mobilenet_7_5_224_tf_no_top.h5'\n",
    "elif alpha==0.5:\n",
    "        weights='mobilenet_5_0_224_tf_no_top.h5'\n",
    "elif alpha==0.25:\n",
    "        weights='mobilenet_2_5_224_tf_no_top.h5'\n",
    "yolo.load_weights(weights, by_name=True)#传入权重文件的路径\n",
    "\n",
    "    #这时候yolo网络已经成功加载预权重\n",
    "\n",
    "with warnings.catch_warnings():#忽略下面部分的waring\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "        # 3. actual training \n",
    "    yolo.train(config['train']['train_image_folder'],#图片对应的文件夹\n",
    "                config['train']['train_annot_folder'],#xml标签对应的文件夹\n",
    "                config['train']['actual_epoch'],      #训练的epoch\n",
    "                weight_file,                          #保存.h5文件权重的文件夹  config['train']['saved_folder']/weights.h5\n",
    "                config[\"train\"][\"batch_size\"],        #每次训练喂入网络的batch\n",
    "                config[\"train\"][\"jitter\"],            #训练的抖动=1？\n",
    "                config['train']['learning_rate'],     #学习率=0.0005\n",
    "                config['train']['train_times'],       #训练次数=5？\n",
    "                config['train']['valid_times'],       #有效次数=5?\n",
    "                config['train']['train_image_folder'],#图片对应的文件夹\n",
    "                config['train']['train_annot_folder'],#xml标签对应的文件夹\n",
    "                config['train']['first_trainable_layer'],#\"\"\n",
    "                config['train']['is_only_detect'],      #为0,不只只是检测\n",
    "                (len(config['model'][\"labels\"])+5)*5, #5x(4+1+分类数),即yolo网络最后输出的大小\n",
    "                config['model']['anchors'],             #锚框列表\n",
    "                w_name=config['model']['architecture'], #算法名字=mobilenet\n",
    "                alpha=alpha,                           #mobilenet的学习率\n",
    "                lable=config['model']['labels']         #标签列表\n",
    "                )\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cf69bd2bff1868ea2575ae05d66f26a3bd574af473be1af5287e2ad3e28ce2c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
